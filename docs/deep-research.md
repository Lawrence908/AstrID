Machine Learning for Astronomy: Classification and Anomaly Detection

Introduction and Background

Modern astronomical surveys are generating unprecedented volumes of data, from wide-field imaging of billions of sources to nightly streams of transient alerts. For example, the upcoming Vera C. Rubin Observatory (LSST) will produce millions of transient alerts per night, making manual inspection infeasible. Machine learning (ML) has therefore become essential for classifying known celestial objects (e.g. stars, galaxies) and for detecting anomalies – unexpected events like supernovae or other rare phenomena. Supervised deep learning approaches (e.g. convolutional neural networks or CNNs) have already shown success in tasks like galaxy morphology classification and star/galaxy separation. However, truly novel discoveries require unsupervised or semi-supervised methods that can flag outliers without explicit training labels. This report surveys academic research, open-source tools, and production pipelines at the intersection of astronomy and ML, with emphasis on anomaly detection (e.g. supernovae, black hole-related events) and object classification. We focus on approaches compatible with Python (3.x) ecosystems – particularly those leveraging TensorFlow/Keras, popular architectures like U-Net, and modern ML Ops tools such as MLflow – and highlight their use in real-world astronomy projects.

Astronomical Data and Processing Pipelines

Astronomical imaging data typically comes in FITS format with associated World Coordinate System (WCS) metadata, enabling alignment and overlay of sky coordinates. Public survey datasets provide a rich foundation for ML:

SDSS (Sloan Digital Sky Survey) – optical images of millions of galaxies and stars, used in many ML classification studies.

Pan-STARRS – multi-epoch all-sky survey, source of static sky images for object catalogs.

ZTF (Zwicky Transient Facility) – time-domain survey producing difference images and transient alerts nightly.

HSC (Hyper Suprime-Cam) – deep survey with multi-band galaxy images; e.g. the GalaxiesML dataset aggregates 286k HSC galaxy images with morphology and redshifts.

LSST (Rubin Observatory’s Legacy Survey of Space and Time) – next-generation survey (planned) with ~10 million alerts per night, for which simulation data and precursor datasets are used to develop ML methods.

Real-world astronomy pipelines perform extensive preprocessing before ML is applied. Raw images are first calibrated (bias/flat corrections) and astrometrically aligned. To find time-variable events, new images are registered to a reference image using WCS and resampled (e.g. via SWarp) onto a common grid. A difference image is then computed by subtracting the reference from the new exposure. Modern surveys employ algorithms like ZOGY (Zackay, Ofek, Gal-Yam 2016) for optimal image subtraction. ZOGY performs PSF matching and optimal subtraction in Fourier space, yielding a difference image with whitened noise properties. This method enhances sensitivity to faint transients, enabling detection of supernovae even against bright galaxy backgrounds. Figure 1 illustrates typical galaxy images from a survey across multiple filters.

Figure 1: Examples of galaxy images from the GalaxiesML dataset (Hyper Suprime-Cam survey) in five optical filters. Each row shows the same galaxy observed in g, r, i, z, y bands (with redshift given). Such multi-band image sets are used for tasks like galaxy classification and redshift estimation.

After image differencing, source extraction tools identify candidate objects (both steady sources and transient residuals). Traditional astronomy software like SExtractor (Bertin & Arnouts 1996) has been foundational; today, Python libraries make these algorithms more accessible. SEP (Source Extractor in Python) provides SExtractor’s core functionality as an in-memory library – computing spatially variable backgrounds, convolving images with filters, detecting and deblending sources, and performing aperture photometry. Similarly, Photutils (an Astropy-affiliated package) offers high-level tools for source detection and photometry, including point-source finding, image segmentation for extended sources, and PSF fitting. These tools output catalogs of detected objects with features like positions, fluxes, shapes, etc. In transient surveys, detection is run on the difference images (often searching for >5σ peaks in the residual) to yield “candidates” for potential transients. Each candidate typically comes with cutout images (science image, reference image, and difference image) and a list of computed features (e.g. signal-to-noise, shape measures).

Critically, not every detection is a real astrophysical event – many are artifacts or “bogus” (e.g. subtraction residuals around bright stars, cosmic ray hits, noise fluctuations). This gave rise to the important step of real-bogus classification. A classifier (traditionally a machine learning model) examines each candidate’s data (pixel cutouts and/or extracted features) and determines whether it is likely a true astrophysical transient (“real”) or a false alarm (“bogus”). Early implementations used Random Forest classifiers on engineered features. For instance, the Palomar Transient Factory and Pan-STARRS surveys both adopted real-bogus classifiers to automatically filter out artifacts. More recently, deep learning has improved performance: the ZTF survey’s ML system, nicknamed Braai, is a convolutional neural network that operates directly on image cutouts. Braai achieved state-of-the-art performance with very low false positive and false negative rates, outperforming the older Random Forest approach. Notably, ZTF has deployed this model on Edge TPU hardware for cost-efficient, real-time inference without loss of accuracy. Thanks to robust differencing (ZOGY) and real/bogus filtering, surveys like ZTF can detect even faint supernovae in crowded fields while keeping false alerts manageable.

In summary, a typical image-processing pipeline for transient discovery consists of: calibration → image alignment (WCS) → image subtraction (e.g. ZOGY) → source detection on the diff image (via SEP/Photutils) → machine learning classification of candidates (real vs bogus). Meanwhile, for static sky surveys, pipelines focus on source extraction from stacked images and subsequent classification (e.g. identifying stars vs galaxies, classifying galaxy types, etc.). In both cases, the combination of classical astronomical algorithms and modern ML is key to handling data scale and complexity.

ML Approaches and Model Architectures in Astronomy

Once data are prepared, a variety of machine learning approaches are applied in astronomy, broadly falling into supervised learning (for known object classes) and unsupervised/anomaly detection (for novel or rare phenomena). We highlight architectures and techniques that have gained traction:

Convolutional Neural Networks (CNNs) – CNNs are the workhorse for image classification in astronomy. They have been used to recognize galaxy morphologies (e.g. distinguishing ellipticals from spirals, identifying bars or mergers) by training on large datasets like Galaxy Zoo. CNNs and their deeper variants (ResNets, DenseNets, etc.) have also been used to detect strong gravitational lenses, classify star vs galaxy vs quasar images, and estimate photometric redshifts from galaxy images. The success of CNNs is due to their ability to learn complex spatial features – for instance, Jacobs et al. (2017) used a CNN to classify SDSS galaxy images by morphology with accuracy rivaling human volunteers, and more recent models (e.g. Zoobot) have learned to identify subtle features from survey images using volunteer-provided labels. In transient detection, 2D CNNs are applied to image cutouts (science, reference, and difference image triplets) to decide if a transient is real. These CNN models are often built with TensorFlow/Keras or PyTorch and integrate well into Python-based pipelines. For example, the ZTF Braai model was implemented as a Keras/TensorFlow convolutional network and trained on millions of example cutouts.

Recurrent and Sequence Models (RNN, LSTM, TCN) – Many astronomical phenomena are captured as time series (light curves) rather than static images. Recurrent neural networks (RNNs) and their gated variants (LSTMs, GRUs) have been applied to classify variable stars and supernova light curves. A newer approach uses Temporal Convolutional Networks (TCN), which are CNNs specialized for sequence data. In a real-world example, Muthukrishna et al. (2022) built a probabilistic neural network using TCN layers to model multi-band supernova light curves and identify anomalies as deviations from the model. Recurrent models are also used for transient detection across image sequences – for instance, one could use a ConvLSTM (convolutional LSTM) that takes a series of image cutouts over time to decide if an object is emerging (this approach has been suggested for video astronomy data or consecutive difference images). Such sequence-based models can capture temporal context, like the rise and fade of a supernova, improving classification of transient vs artifact. Indeed, recurrent networks have been key in classifying supernovae from their light curves in real-time, as seen in the ANTARES and alert-broker systems that use LSTMs for early supernova identification from sparse data. In general, integrating temporal ML models (RNN/ConvLSTM/TCN) allows astronomy pipelines to utilize time-domain information rather than treating each detection independently.

Autoencoders and Generative Models (VAE, GAN, Diffusion) – Unsupervised deep learning is emerging as a powerful tool for anomaly detection in images. Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) learn to encode and reconstruct the distribution of “normal” data, and can flag deviations where reconstruction error is high. For example, Margalef-Bentabol et al. (2020) trained a generative model on images of isolated galaxies and showed it could detect ~90% of merging galaxies as outliers, by identifying poor reconstructions of those interacting systems. The key idea is that deep generative models (which can be implemented in TensorFlow/Keras) learn complex pixel-level representations, making them sensitive to subtle anomalies in morphology. VAEs have been used to detect unusual galaxies that don’t match simulations, and GAN-based models (like AnoGAN) have been adapted from medical imaging to astronomy for detecting instrument artifacts or rare sources. An advantage of GANs is their ability to create extremely realistic simulations; in astronomy they’ve been used to generate synthetic galaxies for data augmentation. Recently, diffusion models (DDPMs) were introduced to generate high-fidelity galaxy images conditioned on attributes, indicating the trend of using state-of-the-art generative AI in astronomy. These models also double as anomaly detectors: if a generated image fails to match the observed image, the object may be anomalous. However, a challenge noted in research is that very flexible models can sometimes over-fit the training distribution and reconstruct even oddballs well – reducing anomaly detection efficacy. Thus, some approaches impose constraints or use hybrid methods (see next section).

U-Net and Image Segmentation Models – U-Net is a convolutional network architecture originally developed for biomedical image segmentation, and it has found many uses in astronomy. U-Nets provide pixel-level classification, which is useful for tasks like source segmentation, deblending, and artifact removal. For instance, U-Nets have been used to deblend overlapping galaxy images by segmenting individual objects (separating superposed sources in crowded fields). They are also used in cosmic ray removal: a U-Net can learn to distinguish cosmic ray hits on CCD images and mask them out. In star/planetary science, U-Nets have been applied to detect stars in star-tracker images (treating bright objects as segmentation targets) in real time (Ricci et al., 2020). Another common use is image-to-image translation, e.g. enhancing image resolution or denoising. In fact, U-Nets and encoder-decoder models can be seen as a form of deterministic autoencoder; e.g. recent work used a U-Net-like model with residual blocks (instead of a latent bottleneck) to achieve state-of-the-art image denoising and deblurring for telescopic images. The appeal of U-Net in astronomy lies in its ability to incorporate multi-scale context (via downsampling path) and output a full image or mask, making it ideal for processing every pixel (like identifying all pixels belonging to a galaxy, or all variable sources in an image).

Table 1 (at the end of this report) provides a summary of these and other ML architectures used in astronomy, along with their typical applications. Notably, most of these models are implemented with open-source frameworks (TensorFlow/Keras or PyTorch) and can be trained on GPUs. Python 3 has become the lingua franca for such development, allowing integration with scientific libraries (NumPy, Astropy, Scikit-learn, etc.). Moreover, tools like MLflow are increasingly adopted to manage the machine learning lifecycle – tracking experiments, hyperparameters, and model versions for reproducibility. For example, the UCLA GalaxiesML project provides a Keras CNN example for galaxy classification with MLflow integration for experiment tracking. This shows that even in academic astrophysics settings, modern MLOps practices (logging metrics, packaging models) are being used to bridge research and production.

Open-Source Implementations and Production Systems

Several end-to-end systems and libraries have been developed to bring these techniques into operational use in astronomy:

ZTF Alert Pipeline (Production) – The Zwicky Transient Facility operates a fully automated real-time pipeline. As described earlier, it uses ZOGY image subtraction and a deep CNN (Braai) for candidate vetting. What makes ZTF notable is the ecosystem of open tools around it. The alert stream (with each event’s features and images) is distributed in Apache Avro packets through a Kafka stream. At Caltech, an open-source system called Kowalski ingests these alerts into a MongoDB database, providing a programmatic API for query. Kowalski (available on GitHub) lets users and brokers filter events, cross-match with catalogs, and retrieve light curves efficiently. Another tool, Zwickyverse, was developed to label alert images via citizen science, creating a database of labeled real/bogus examples for model training. These tools showcase a production-grade integration of ML: a deep learning model running on dedicated hardware (TPUs) and a scalable data infrastructure around it. Outcome: ZTF’s system reduces millions of subtractions to a manageable alert list each night, enabling rapid follow-up on candidates like supernovae and tidal disruption events. ZTF has open-sourced many components, so it serves as a template for future surveys.

Astronomaly (Open-Source Framework) – Astronomaly is a general framework for anomaly detection in astronomy, developed by Lochner & Bassett (2021) and available on GitHub. It is designed to be modular and extensible to different data types (images, light curves, spectra). Astronomaly combines unsupervised ML with an active learning loop involving the user. The Python backend can use various feature extraction methods and anomaly algorithms (one-class models, clustering, PCA, etc.) to generate an anomaly score for each object. A web front-end then allows a human to review the highest-scoring anomalies and provide feedback (labels or relevance rankings). This feedback is used to update the model (closing an active learning loop). The idea is to leverage ML to sift through data, but keep a human in the loop to guide what constitutes an “interesting” anomaly. Astronomaly is already being tested on datasets like MeerKAT radio images and optical survey data to find unusual objects. It exemplifies a flexible, research-oriented tool that astronomers can adapt and deploy on their own datasets, benefiting from built-in ML algorithms and the ability to incorporate domain expertise via active learning.

Other Notable Tools: Source extraction libraries like SEP and Photutils (discussed above) are open-source and widely used in research pipelines for object detection and photometry. Astropy provides core I/O (FITS) and WCS handling, and affiliated packages like reproject handle image alignment to common WCS grids (useful for stacking images or making color composites). For hyperspectral data (e.g. IFU cubes) or other 3D data, there are emerging ML tools (e.g. AstroCNN3D, though less common than 2D). The transient discovery community has also developed open brokers (e.g. LASAIR, ANTARES) that use ML classifiers to prioritize events – these systems often incorporate Python ML models to rapidly classify incoming alerts (such as identifying likely supernovae vs moving objects vs bogus). In addition, the WFST (Wide-Field Survey Telescope in China) is building an alert system where a deep learning real-bogus classifier is trained with limited labels by using active learning and semi-supervised learning, demonstrating how new surveys are adopting advanced ML to minimize manual labeling.

MLflow and Reproducibility: Within research groups, tools like MLflow are being used to streamline experiment tracking for astronomy ML projects. The GalaxiesML example (UCLA Data Lab) mentioned earlier logs training runs and model artifacts for a galaxy classification network. This is indicative of a broader trend: as datasets and models grow, astronomers are embracing MLOps practices. Some are using containerization (Docker) and workflow managers (Airflow, as promoted by astronomer.io) to reliably run pipelines that include steps like data prep, training, and inference. The ultimate aim is to ensure that models can transition from the lab to the observatory – for instance, an ML model trained on archival data can be packaged and deployed to process new observations in real time, with MLflow handling versioning and deployment.

Table 2 summarizes a few key open-source tools and systems, along with their purpose and usage in the astronomy ML ecosystem.

Evaluation Methods and Challenges in Astronomical ML

Building effective ML systems for astronomy comes with unique challenges, and careful evaluation is crucial:

Class Imbalance and Metrics: Anomalies (e.g. rare transients) are vastly outnumbered by normal events or artifacts. This extreme class imbalance means evaluation must go beyond overall accuracy. Precision-Recall metrics are favored: specifically, Precision, Recall, and the Area Under the Precision-Recall Curve (AUCPR) give a better sense of performance on the rare class than ROC AUC. For example, an anomaly detection method was judged by its AUCPR in identifying rare transient classes (kilonovae, etc.), achieving AUCPR > 0.79 for those classes. A high AUCPR indicates the model can catch most anomalies (high recall) while keeping false positives low – important because follow-up resources (telescopes, astronomers’ time) are limited. Another common metric in classification is the F1-score (harmonic mean of precision and recall) for the “real” class in real-bogus classification. ZTF’s deep learning classifier was optimized to minimize false negatives in particular – missing a real supernova is more costly than momentarily flagging a false one. In practice, astronomers often tune models to reach a desired recall (completeness) and then report the precision at that operating point, or vice versa, depending on science goals.

False Positives vs False Negatives: As alluded, there is a trade-off in setting detection thresholds. Many pipelines implement an alert scoring system (0.0 to 1.0 for bogus→real) and choose a cutoff. It’s common to allow a higher false positive rate if it means catching virtually all true events (high recall). The downstream human or automated systems can tolerate some false alerts but do not want to miss genuine events. In anomaly detection studies, a similar logic applies – one may prefer an algorithm that flags a broader set of candidates (including some false alarms) for human inspection, rather than one that misses novel phenomena. That said, if false positives are too numerous, important anomalies might be drowned out. Techniques like Active Anomaly Detection (as in Astronomaly) aim to mitigate this by learning from user feedback which types of outliers are uninteresting (e.g. artifacts) so the system can focus on likely-real anomalies.

Domain Shifts and Generalization: A model trained on one dataset may perform poorly on another due to different noise characteristics, instruments, or observing conditions. This is a big challenge for surveys like LSST, which will observe a wide range of sky regions and conditions. Ensuring the training data is representative is essential. In the ZTF real-bogus classifier, the training set had to include examples across different filters, CCD chips, and artifact types to generalize well. Cross-domain validation (e.g. training on one telescope’s data, testing on another’s) is increasingly done in ML astronomy papers to demonstrate robustness. Some teams use simulation to augment training – e.g. injecting fake supernova signals into images to bolster the training set of reals – but simulations can introduce biases if not perfectly representative.

Interpretability and Human-in-the-Loop: Unlike some commercial ML applications, scientific ML places a premium on interpretability. Researchers want to understand why the model flagged something as anomalous. Tools like t-SNE/UMAP plots of latent embeddings are used to visualize clusters of “weird” objects. The classifier-based anomaly detection approach (Emerick et al. 2022) explicitly uses the latent space of a supervised classifier as a feature space for novelty detection – effectively trying to get the best of both worlds (leveraging known classes to define a feature space, then finding outliers in it). Human oversight is also a form of interpretation: frameworks like Astronomaly allow astronomers to iteratively label what the model finds, which not only improves the model but provides insight into the nature of anomalies found (are they all satellite glints? unusual supernova lightcurves? etc.). One lesson from these approaches is that automation must be coupled with expert validation. Many projects, such as the SNAD (Supernova Anomaly Detection) team, found that combining ML scores with domain knowledge (e.g. cross-matching an anomaly with known catalogs) yields the best results.

Performance and Scalability: Processing petabytes of image data and streaming millions of events require scalable solutions. This is a practical challenge: models must not only be accurate but also computationally efficient. ZTF’s deployment of the braai CNN on Edge TPUs (small, efficient hardware accelerators) shows one solution. Others are exploring GPU-accelerated inference on streaming data or using distributed computing for training on huge datasets (e.g. using TensorFlow with Horovod on HPC clusters for galaxy image analysis). MLOps tools (like MLflow, Kubernetes deployments of models, etc.) will likely play a growing role in maintaining these models over the decade-long survey operations (ensuring models can be retrained periodically as new labeled data comes in, monitoring model drift, etc.). Already, prototypes like LSST’s alert brokers plan to incorporate ML classifiers that update as new events are confirmed by spectroscopy.

Common challenges notwithstanding, the field has made significant strides. For example, one study demonstrated that a simple physics-based model outperformed a complex neural network in identifying unusual transients, highlighting that more complexity isn’t always better for anomaly detection. The lesson is to choose model complexity appropriate to the data volume and problem understanding. Another lesson is the importance of evaluation on real-world discovery outcomes: an ML system in astronomy is ultimately judged by whether it leads to new discoveries or more efficient observations. Thus, beyond metrics, teams often report how many new objects were found or how early a supernova was identified compared to traditional methods.

From Single-Class Detection to Anomaly Detection – Recommendations

A recurring scenario is expanding a system that reliably detects one class of object (say, stars or known variable sources) into an anomaly detection system that can catch anything unusual (e.g. a new kind of transient). This requires rethinking the ML approach:

Leverage Your Existing Model’s Knowledge: If you have a classifier for known classes, one approach is the “open set” or classifier-head anomaly approach. Use the features learned by your model (the penultimate layer of a neural network) as a representation of “normal” objects. Anything that falls far in this feature space from known classes can be flagged as a candidate anomaly. This can be done by measuring distances in the latent space or training a one-class model on those features. For example, if your model classifies stars, galaxies, and quasars, an object that does not fit well into any of those categories (low softmax score, or high entropy in the output distribution) might be an unknown type – effectively an anomaly. Research in 2024 applied this idea to multi-class transient classification, treating the network’s latent space as an input to an outlier detector.

One-Class Classification and Autoencoders: If only one class (say “normal star”) was originally of interest, you can repurpose the problem as a one-class anomaly detection. Train an autoencoder or VAE solely on those normal stars. At inference, any input that the autoencoder reconstructs poorly (i.e. high error) is likely not a normal star (could be a supernova or artifact). Margalef-Bentabol et al.’s galaxy merger detection is a prime example of training on one class (isolated galaxies) and successfully identifying departures (merging galaxies) by reconstruction error. In practice, you might use a TensorFlow/Keras implementation of a VAE or a convolutional autoencoder for this. Ensure to evaluate the reconstruction error against known anomalies (if available) to set a threshold.

Synthetic Anomalies and Data Augmentation: In some cases, you can simulate anomalies to help train or tune your system. For instance, insert fake supernovae into star images to expand the training set for an anomaly detector. This was done in some alert systems to train real-bogus classifiers – injecting fake transients helped the model learn to distinguish real transients from artifacts by providing positive examples. With tools like PhoSim or other simulators, one can generate a variety of “unknown” events (like supernova at various brightness, or moving objects) and explicitly train a model to detect anything that looks like those or anything not like the normal class. This blends supervised and unsupervised strategies (sometimes called semi-supervised anomaly detection).

Active Learning and Human Vetting: Expanding into anomaly discovery often means you’ll encounter objects that the model is unsure about. An effective strategy is to use active learning – have the model flag uncertain objects and then have an expert label them (or mark them as interesting vs not). The active learning real-bogus classifier for WFST is a case in point: it started with only 1000 labeled examples and iteratively improved by querying an oracle for the most informative new labels. By focusing labeling effort on boundary cases, you can rapidly expand the model’s ability to recognize new phenomena. Over time, this process can transform a single-class detector into a rich multi-class or anomaly-aware classifier. In an observatory setting, this might involve periodically retraining the model on all confirmed events plus the accumulated feedback on anomalies (similar to how spam filters get better by user marking of spam/ham).

Ensemble of Models / Hybrid Approaches: You don’t have to choose one method – often a combination works best. For example, one could run a simple physics-based model alongside a neural network, as Muthukrishna et al. did. The neural net might catch certain weirdos that the parametric model misses, and vice versa. In practice, an ensemble or a two-stage system (first stage: catch anything that deviates from a parametric light curve fit; second stage: use a deep model to verify or categorize it) can be very powerful. Many current brokers use an ensemble of classifiers – some based on ML, some on human-defined rules – to ensure rare events don’t slip by.

In moving from a single-class focus to anomaly detection, the key is to define “normal” and “anomalous” in a way the model can learn. Since anomalies by nature have few or no examples, focus on characterizing normality (via generative models, one-class learners, or multi-class proxies) and on mechanisms to update the model as new anomalies are discovered (continuous learning). It’s also crucial to validate anomaly detections: one should inject or use known unusual events (if available) to test that the system can indeed detect them and doesn’t get swamped by false positives. In astronomy, this often means performing retrospective searches – e.g., take archival data where a supernova occurred, remove that supernova from training data, then see if the anomaly detector would have found it. Such tests build confidence that expanding to anomaly detection is yielding real scientific gains.

Finally, fostering a collaborative approach between domain scientists and ML systems is important. The anomalies flagged by an AI should be fed back into improving scientific knowledge – for instance, leading to new object classes or refining data reduction methods if many “anomalies” turn out to be systematics. The experience from projects like Astronomaly suggests that a tight human-ML feedback loop is one of the most effective ways to safely broaden the horizons of a single-class detector into a discovery engine for the unexpected.

Conclusion

Machine learning has become integral to modern astronomy, enabling both classification of known celestial objects at scale and the detection of anomalies that could herald new discoveries. From segmentation of telescope images with U-Nets to real-time transient filtering with CNNs on edge devices, ML techniques are deeply embedded in survey pipelines. At the same time, the community places emphasis on open-source tools (such as SEP for source extraction and Astronomaly for anomaly detection) and rigorous evaluation using appropriate metrics (like AUCPR for rare-event detection). The synergy of advanced algorithms (deep neural networks, generative models) with classic astronomical techniques (image differencing, photometry) has proven powerful – e.g., ZTF’s adoption of a deep learning filter reduced false alerts and enabled the discovery of numerous supernovae and even more exotic transients.

Looking ahead, upcoming projects like LSST will push these methods to new limits, handling data streams of 10 million alerts per night. This will likely spur further development in ML Ops for astronomy (to retrain and serve models continuously), and in hybrid human-AI systems to keep scientists in the loop for vetting truly novel phenomena. There is also a trend toward multi-modal learning – combining imaging data with spectra, time-series, and contextual information (e.g. cross-matches) to improve classification and anomaly detection. Tools such as MLflow are helping to make these workflows reproducible and shareable across the community.

In summary, the intersection of machine learning and astronomy is a vibrant and rapidly evolving field. By building on the lessons learned – the importance of balanced metrics, the value of simulation and active learning, and the need for interpretability – astronomers are expanding single-class detectors into sophisticated systems capable of uncovering the unexpected quirks of our universe. The following tables provide a comparative glance at some of the tools, datasets, and model architectures discussed, serving as a quick reference for practitioners entering this domain.

Comparison Tables

Table 1. Selected Tools and Pipelines in Astronomical ML

Tool/PipelinePurposeKey Features and UsageSource/ReferenceZOGY (Image Subtraction)Optimal image differencing for transient detection.Uses FFT-based PSF matching; produces a difference image with uncorrelated noise (whitened) for robust transient identification. Widely used in ZTF and other surveys for detecting faint SN in crowded fields.Zackay, Ofek & Gal-Yam 2016; Implementations in Python (e.g. ZOGY in Parallel).SEP (Source Extractor in Python)Source extraction & photometry library.In-memory C library (via Python) derived from SExtractor. Performs background estimation, convolution filtering, threshold detection, deblending, aperture photometry. Fast (C-optimized) and easy to integrate in Python pipelines. Used for cataloging sources in images or finding transient candidates on diff images.Barbary (2016) JOSS; SEP docs.Photutils (Astropy)Source detection, photometry, segmentation.High-level Python library for finding stars/galaxies and measuring their properties. Offers PSF photometry, centroiding, segmentation maps for extended sources, etc. Integrates with Astropy WCS for coordinate handling. Often used in survey data reduction and analysis pipelines.Photutils documentation.Kowalski (ZTF alert DB)Alert archiving and query system.Ingests ZTF alert stream (Avro packets via Kafka) into a MongoDB NoSQL database. Provides API for querying alerts/lightcurves and cross-matching with catalogs. Open-source (Python). Facilitates rapid filtering of transients by the community.Duev et al. 2019 (ZTF); GitHub dmitryduev/kowalski.Braai (ZTF real-bogus CNN)Real-time transient classifier.Convolutional NN (TensorFlow) that classifies candidates as real or bogus using image triplets. Deployed on Edge TPU for speed. Achieved low false positive/negative rates, improving upon older RF classifier. Not publicly released, but described in literature.Duev et al. 2019.Astronomaly (Framework)Unsupervised anomaly detection with active learning.Modular Python backend + JS frontend. Can ingest various data types. Uses user-in-the-loop: ML ranks anomalies, user feedback refines the model. Extendable with custom feature extractors or algorithms. Aimed at discovering novel objects in big datasets.Lochner & Bassett 2021; GitHub MichelleLochner/astronomaly.WFST Real/Bogus (Active)Semi-supervised transient filter.Deep learning classifier for the upcoming WFST survey. Uses only 1000 labeled examples initially; active learning selects most uncertain detections for labeling, and semi-supervised learning leverages unlabeled data to improve performance. Efficiently achieves high accuracy with few labels.Liu et al. 2025 (A&A).LSST Alert Brokers (e.g. Lasair, ANTARES)Event stream classification and annotation.Distributed systems that receive LSST alerts and apply ML models plus rules to categorize events (e.g. likely SN, variable star, artifact). Typically use Python and have multiple classifiers (some trained on ZTF data). Provide public event feeds with scores.LSST Community Brokers docs; Lasair/ANTARES papers (2020–2022). 

Table 2. Example Public Datasets and Surveys for ML

Dataset/SurveyDescription & ScalePublic AvailabilityNotes on ML UsageSDSS (optical imaging)~300 million celestial objects imaged in five bands (u,g,r,i,z). Medium-depth, ~1 arcsec resolution.Public data releases (images and catalogs online).Used for galaxy morphology classification, star/galaxy/QSO separation (early CNN experiments). Galaxy Zoo project provided labels for morphologies.Pan-STARRS (3$\pi$ survey)All-sky multi-epoch optical survey (g,r,i,z,y bands). Stacked static sky images + transient detections.Data releases available (Pan-STARRS1 DR2 images via MAST).Catalogs used for training star/galaxy classifiers. Difference imaging pipeline used Random Forest real-bogus; provides training data for ML (artifacts vs real).ZTF (time-domain)Nightly survey of Northern sky in g,r (and i) bands. 47 sq.deg. camera, 1k+ exposures/night; alerts for variable/transient sources.Alert stream public via brokers (with 6-month delay); image data partly public (some via IRSA).Has labeled datasets for real vs bogus (from Zooniverse and spectroscopic follow-up) used to train deep CNN. Also used for anomaly search studies (e.g. looking for unusual transients).HSC (Hyper Suprime-Cam) & GalaxiesMLDeep optical survey (sub-arcsec) covering ~1200 sq.deg. in 5 bands. The GalaxiesML dataset draws 286k galaxy images from HSC with spectroscopic redshifts.HSC Public Data Release (PDR2) available. GalaxiesML dataset on Zenodo.Provides high-quality data for training morphology and photometric redshift models. E.g., used to train CNN for galaxy classification with MLflow logging.LSST (Simulated)Simulated LSST images and alert stream data (pre-operations). LSST will cover ~18k sq.deg., visit each area ~1000× in 10 years (ugrizy).Simulations (e.g. LSST DESC Data Challenge) are publicly available; future real data will be public after proprietary period.Simulated multi-band images used to train models in advance (e.g. the PLAsTiCC transient classification challenge used simulated LSST light curves). ML research for LSST focuses on scaling and early anomaly detection.Others: DES, Gaia, JWST...DES (Dark Energy Survey) 5-band images, 300 million objects. Gaia (all-sky astrometric survey) – time-series for 1+ billion stars. JWST (infrared space telescope) – high-res images, smaller sky areas.DES DRs public (NOIRLab); Gaia data fully public; JWST archive public.DES difference imaging pipeline outputs used to train ML classifiers for transients. Gaia’s variable star labels used to train light curve classifiers. JWST anomaly detection (e.g. identifying instrumental anomalies in images) explored with GANs. 

Table 3. Model Architectures and Their Applications in Astronomy

Model ArchitectureTypical Use Cases in AstronomyNotes on Implementation and ExamplesCNN (Convolutional Neural Network)Image-based classification and regression: galaxy morphology (E/S/Irr), star/galaxy distinction, gravitational lens detection, photometric redshift estimation. Also transient real/bogus classification using image cutouts.Usually implemented in Keras or PyTorch. Often a custom CNN or adapted architectures (ResNet, VGG) are used. E.g., DeepGalaxy (Domínguez Sánchez 2018) used Inception-ResNet for SDSS galaxy morphology; ZTF’s Braai is a small custom CNN. Transfer learning sometimes employed (e.g. using ImageNet-pretrained models for galaxy images).ResNet / DenseNet (Deep CNN variants)Advanced image classification; has seen use in finding subtle features (like identifying galaxy mergers, or detecting strong lensing arcs amidst noise). DenseNets used for strong lens finding achieved lower false positive rates than ResNets.Implemented via deep learning frameworks. Provide very deep networks that can learn complex features. In astronomy, often need to be fine-tuned due to difference in data scale (e.g. greyscale images, different noise characteristics).U-Net (Encoder-Decoder CNN)Image segmentation and pixel-level predictions: detecting sources and separating overlapping objects (deblending), flagging cosmic rays, creating masks for astrophysical structures (e.g. H II regions in galaxies), denoising images. Also used for enhancing images (e.g. deconvolution).Many astronomy U-Nets are implemented in Keras/TensorFlow. E.g., Astronomical U-Net (George 2017) for cosmic ray removal on HST images. Often trained on simulated data (for known “truth” masks). U-Nets can incorporate multi-band images as multiple input channels.RNN / LSTM (Recurrent Nets)Time-series classification: identifying variable star types, classifying supernova light curves, detecting exoplanet transits in light curve data. Also used in multi-epoch survey data to classify objects based on their variability patterns.Implemented in TensorFlow/Keras (using LSTM layers) or PyTorch. Often sequence models are combined with CNNs (e.g. 1D CNN + LSTM) for feature extraction from light curves. Example: the ANTARES alert broker uses an LSTM to classify transient lightcurves in real-time.ConvLSTM / 3D-CNNSpatio-temporal data analysis: e.g. analyzing a sequence of images (3D: two spatial dims + time) to detect a transient appearing/moving. Used in research for video-like data (solar flare videos, meteor detection on all-sky cameras). Could be applied to a series of difference images to confirm a transient’s consistent appearance across nights.Both ConvLSTM and 3D CNN are supported in Keras/PyTorch. In practice, these are computationally heavy. One challenge is limited labeled “video” data in astronomy; thus they are not as common, but conceptually powerful. For instance, a ConvLSTM was tested to detect astrophysical jets in simulations.VAE (Variational Autoencoder)Unsupervised anomaly detection and data generation: detecting unusual galaxies or image artifacts by reconstruction error; generating synthetic images of galaxies for augmentation. Also used for dimensionality reduction of spectra or light curves with anomaly detection on the latent space.Implemented in TensorFlow/PyTorch. Typically trained on a large set of “normal” data. E.g., a VAE trained on smooth galaxy images will flag galaxies with odd features (e.g. mergers, lens arcs) whose reconstructions are poor. Needs careful tuning (latent size, loss weighting) to avoid trivial solutions.GAN (Generative Adversarial Network)Data simulation and anomaly detection: creating realistic galaxies or supernova light curves to supplement training; detecting anomalies via GAN-based methods like AnoGAN (which finds anomalies by how well GAN can reconstruct an image). Also used in up-sampling (super-resolution of telescope images).GANs (e.g. using PyTorch) have been used to generate high-res galaxy images that look real. In anomaly mode, one trains a GAN on normal data and then finds anomalies by optimization in latent space to best reconstruct a given image (if reconstruction error high, it’s anomalous). Schlegl et al. 2017’s approach applied to astronomy is an example. GAN training can be unstable; newer variants (WGAN, cGAN) often used.Bayesian/Physics Model + ML HybridModels that incorporate astrophysical equations or simulators within ML. For anomaly detection, a parametric model (e.g. template fitting for supernova lightcurves) can flag deviations, possibly augmented by an ML model for residuals. Also Bayesian Neural Networks used to get uncertainty estimates on classifications (helpful to gauge when a detection might be novel).Example: Interpretable Bayesian model vs TCN was tested for anomaly detection in transients. The Bayesian model (with astrophysical parameters) achieved high precision/recall on weird transients. Implementation can be via probabilistic programming (TensorFlow Probability, pyro) or simply combining least-squares fits with ML triggers. Such hybrid approaches ensure physical consistency and interpretability, at cost of flexibility. 