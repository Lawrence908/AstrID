# ASTR-114: Real Data Ingestion Service & Worker Orchestration

- Project: ASTRID-API, ASTRID-WORK, ASTRID-CORE
- Priority: P2 (High)
- Labels: api, workflow, data-pipeline, ingestion
- Status: Planned
- Owner: Chris Lawrence
- Created: 2025-09-23
- Estimate: 3-5 days
- Dependencies: ASTR-73 (Observations), ASTR-76 (Preprocessing), ASTR-88 (MLflow), ASTR-91 (Workflow)

## Goal
Implement a thin ingestion layer and background worker that fetches real survey imagery (SkyView/MAST), saves FITS to Cloudflare R2, and persists Observation records and a simple manifest consumable by the training pipeline.

## Motivation
Notebooks currently call low-level adapters directly for prototyping. A service + worker flow provides:
- Validated inputs and consistent metadata
- Durable, retryable execution
- Clear lineage (DB + manifest) for training datasets
- Decoupling from notebook environments

## Scope
- REST endpoint to enqueue ingestion jobs
- Service that composes existing adapters: `SkyViewClient` / `MASTClient`, `FITSProcessor`, `R2StorageClient`
- Worker task with retries and idempotency
- Manifest generation for training (`real_data_manifest.json` structure)
- Minimal integration into existing `training/datasets/collect`

## Deliverables
1. API Endpoint
   - POST `/observations/ingest/position`
   - Body: `{ ra: float, dec: float, survey?: string, fov_deg?: float, pixels?: int, mission?: string, metadata?: object }`
   - Response: `{ job_id, accepted: true }`

2. Service Layer
   - `ObservationIngestionService` (sync orchestration, thin)
   - Steps: validate → fetch image (HiPS2FITS/SkyView or MAST) → save FITS via `FITSProcessor` → upload via `R2StorageClient` → persist Observation metadata → emit manifest entry

3. Worker Task
   - `ingest_position_task(ra, dec, survey, fov_deg, pixels, mission, metadata)`
   - Retries with backoff, idempotency key on `(ra, dec, survey, fov)`
   - Structured logs and metrics

4. Manifest
   - Append JSON lines to `references/manifest/real_data_manifest.json` in R2 and local cache
   - Entry: `{ bucket, key, ra, dec, survey, created_at, meta }`

5. Training Dataset Builder Integration
   - Extend `POST /training/datasets/collect` to accept `use_manifest: true` or region/time query that resolves to manifest entries

6. Documentation
   - Update `notebooks/ml_training_data/real_data_loading.ipynb` to call API instead of direct clients
   - Add usage to `docs/training-data-pipeline.md`

## Non-Goals
- Full-blown ingestion of all missions; start with SkyView DSS2 Red and optional MAST PS1 cutouts
- Preprocessing/differencing; those are separate domains already implemented

## Implementation Plan
- [ ] API: Add router `POST /observations/ingest/position` → enqueue job
- [ ] Service: `ObservationIngestionService` in `src/adapters/ingestion/service.py`
- [ ] Worker: task in `src/adapters/workers/ingestion/ingest_position.py`
- [ ] R2 Paths: `references/skyview/{survey}/{ra}_{dec}.fits`
- [ ] Manifest writer util shared by service + worker
- [ ] Extend dataset builder endpoint to read manifest entries
- [ ] Docs + notebook updates

## Acceptance Criteria
- Calling the API with a valid RA/Dec returns a `job_id` and creates an R2 FITS at the expected prefix
- A manifest entry is written and visible via a GET to the dataset builder or by listing the manifest file
- Training notebook can consume the manifest-based dataset and run at least one epoch with logged artifacts to MLflow

## Risks & Mitigations
- External service failures → retries with exponential backoff
- SSL/CA issues → use certifi inside containers and document env vars
- R2 permissions → verify bucket policy and keys inside worker container

## Testing
- Unit tests for service orchestration (mock external clients)
- Integration test hitting the endpoint and asserting R2 object and manifest entry
- Notebook smoke test exercises the flow end-to-end

## Tracking
- Links: `src/adapters/external/skyview.py`, `src/adapters/external/mast.py`, `src/adapters/external/r2.py`, `src/adapters/imaging/fits_io.py`
- Follow-ups: scale to multiple surveys/missions, add batch/region ingestion, add Prefect flow wrapper


