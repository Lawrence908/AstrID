## **ASTR-106: Training Notebook for Model Training and MLflow Logging (P2) - ML Infrastructure**

### **Context & Current State**
MLflow integration is complete (ASTR-88 ✅), providing comprehensive experiment tracking and model management capabilities. This ticket creates a Jupyter notebook for initial model training that integrates with the existing MLflow infrastructure to enable proper experiment tracking, metric logging, and model validation for the U-Net anomaly detection model.

### **Technical Requirements**

**Dependencies**: ASTR-88 (MLflow Integration) - ✅ Complete
**Domain**: ML Infrastructure (Model Training)
**Estimated Time**: 2 days

### **Implementation Tasks**

1. **Set Up Training Notebook Structure**
   - Create `notebooks/training/model_training.ipynb`
   - Implement clear section organization:
     - Data Loading & Preprocessing
     - Model Architecture Setup
     - Training Loop Implementation
     - MLflow Integration
     - Validation & Testing
     - Troubleshooting & Debugging
   - Add comprehensive markdown documentation
   - Include setup and environment configuration
   - Add clear instructions for running the notebook

2. **Implement Data Loading and Preprocessing**
   - Create data loading utilities for astronomical images
   - Implement preprocessing pipeline integration:
     - Use existing preprocessing services from ASTR-76
     - Apply image normalization and scaling
     - Handle different image formats and sizes
     - Implement data augmentation strategies
   - Add data validation and quality checks
   - Create data visualization for inspection
   - Implement train/validation/test split logic

3. **Set Up Model Architecture and Training Loop**
   - Integrate with existing U-Net model from ASTR-80
   - Implement training loop with proper error handling
   - Add support for different loss functions:
     - Binary cross-entropy for anomaly detection
     - Dice loss for segmentation tasks
     - Focal loss for imbalanced datasets
   - Implement optimizer configuration:
     - Adam optimizer with learning rate scheduling
     - Support for different learning rates
     - Gradient clipping and regularization
   - Add early stopping and checkpointing

4. **Integrate MLflow Logging and Tracking**
   - Connect to existing MLflow server from ASTR-88
   - Implement comprehensive experiment tracking:
     - Log hyperparameters (learning rate, batch size, epochs)
     - Track training metrics (loss, accuracy, precision, recall)
     - Log validation metrics and model performance
     - Record training time and resource usage
   - Add model artifact logging:
     - Save model checkpoints
     - Log model architecture and weights
     - Store preprocessing parameters
   - Implement experiment comparison and analysis

5. **Add Metric Tracking and Validation**
   - Implement comprehensive metric calculation:
     - Training and validation loss curves
     - Accuracy, precision, recall, F1-score
     - ROC curves and AUC scores
     - Confusion matrices and classification reports
   - Add real-time metric visualization
   - Implement model performance validation
   - Create metric export functionality for analysis

6. **Create Troubleshooting and Debugging Tools**
   - Add data inspection utilities:
     - Image visualization with annotations
     - Data distribution analysis
     - Preprocessing result inspection
   - Implement training monitoring:
     - Loss curve visualization
     - Gradient flow analysis
     - Learning rate scheduling visualization
   - Add debugging utilities:
     - Model prediction visualization
     - Error case analysis
     - Performance profiling tools

### **Integration Points**

- **MLflow Integration**: Use existing MLflow server and tracking from ASTR-88
- **Model Integration**: Leverage U-Net model from ASTR-80
- **Preprocessing**: Integrate with preprocessing services from ASTR-76
- **Storage**: Use existing cloud storage for data and artifacts
- **Database**: Connect to existing database for metadata storage

### **Notebook Structure**
```python
# 1. Setup and Imports
import mlflow
import torch
import numpy as np
from src.domains.ml.mlflow_integration import MLflowTracker
from src.domains.ml.models.unet_model import UNetModel
from src.domains.preprocessing.services import PreprocessingService

# 2. Configuration
@dataclass
class TrainingConfig:
    experiment_name: str
    model_name: str
    batch_size: int
    learning_rate: float
    num_epochs: int
    validation_split: float
    early_stopping_patience: int
    checkpoint_frequency: int

# 3. Data Loading
class DataLoader:
    def load_astronomical_data(self, survey_id: str) -> Dataset
    def preprocess_images(self, images: List[ndarray]) -> List[ndarray]
    def create_data_splits(self, dataset: Dataset) -> Tuple[Dataset, Dataset, Dataset]

# 4. Training Loop
class TrainingManager:
    def train_model(self, model: UNetModel, config: TrainingConfig) -> dict
    def validate_model(self, model: UNetModel, val_loader: DataLoader) -> dict
    def log_metrics(self, metrics: dict, epoch: int) -> None
    def save_checkpoint(self, model: UNetModel, epoch: int) -> str
```

### **MLflow Integration**
```python
class MLflowTrainingTracker:
    def __init__(self, experiment_name: str):
        self.tracker = MLflowTracker()
        self.experiment_id = self.tracker.create_experiment(experiment_name)
    
    def start_run(self, run_name: str, tags: dict) -> str:
        return self.tracker.start_run(self.experiment_id, run_name, tags)
    
    def log_hyperparameters(self, params: dict) -> None:
        self.tracker.log_params(params)
    
    def log_metrics(self, metrics: dict, step: int) -> None:
        self.tracker.log_metrics(metrics, step)
    
    def log_model(self, model: UNetModel, model_name: str) -> str:
        return self.tracker.log_model(model, model_name)
    
    def log_artifacts(self, artifacts: dict) -> None:
        self.tracker.log_artifacts(artifacts)
```

### **Training Configuration**
```python
@dataclass
class TrainingParameters:
    # Model parameters
    model_architecture: str = "unet"
    input_channels: int = 1
    output_channels: int = 1
    initial_filters: int = 64
    depth: int = 4
    
    # Training parameters
    batch_size: int = 16
    learning_rate: float = 0.001
    num_epochs: int = 100
    weight_decay: float = 1e-4
    
    # Data parameters
    image_size: tuple = (256, 256)
    validation_split: float = 0.2
    test_split: float = 0.1
    
    # Training strategy
    early_stopping_patience: int = 10
    checkpoint_frequency: int = 5
    gradient_clip_norm: float = 1.0
    
    # MLflow parameters
    experiment_name: str = "unet_anomaly_detection"
    run_name: str = "initial_training"
    tags: dict = field(default_factory=lambda: {
        "model_type": "unet",
        "task": "anomaly_detection",
        "dataset": "astronomical_images"
    })
```

### **Data Processing Pipeline**
```python
class AstronomicalDataProcessor:
    def __init__(self, preprocessing_service: PreprocessingService):
        self.preprocessing = preprocessing_service
    
    def load_survey_data(self, survey_id: str) -> List[dict]:
        # Load observation data from database
        pass
    
    def preprocess_images(self, observations: List[dict]) -> List[ndarray]:
        # Apply preprocessing pipeline
        pass
    
    def create_annotations(self, observations: List[dict]) -> List[ndarray]:
        # Create ground truth annotations
        pass
    
    def augment_data(self, images: List[ndarray], annotations: List[ndarray]) -> Tuple[List[ndarray], List[ndarray]]:
        # Apply data augmentation
        pass
```

### **Visualization and Analysis**
```python
class TrainingVisualizer:
    def plot_training_curves(self, history: dict) -> None:
        # Plot loss and accuracy curves
        pass
    
    def plot_validation_metrics(self, metrics: dict) -> None:
        # Plot validation metrics
        pass
    
    def visualize_predictions(self, model: UNetModel, test_data: Dataset) -> None:
        # Visualize model predictions
        pass
    
    def plot_confusion_matrix(self, y_true: ndarray, y_pred: ndarray) -> None:
        # Plot confusion matrix
        pass
    
    def plot_roc_curve(self, y_true: ndarray, y_scores: ndarray) -> None:
        # Plot ROC curve
        pass
```

### **Error Handling and Validation**
- Data loading error handling and recovery
- Model training failure detection and logging
- MLflow connection error handling
- Memory management for large datasets
- Training interruption and resumption
- Comprehensive error logging and reporting

### **Testing Strategy**
- Notebook execution tests with sample data
- MLflow integration validation tests
- Model training convergence tests
- Metric calculation accuracy tests
- Error handling and recovery tests

### **Documentation Requirements**
- Clear setup and installation instructions
- Step-by-step execution guide
- Parameter configuration documentation
- Troubleshooting guide for common issues
- Best practices for model training
- Integration with existing AstrID infrastructure

### **Performance Considerations**
- Memory-efficient data loading for large datasets
- GPU utilization optimization
- Batch processing for multiple experiments
- Progress tracking for long training runs
- Resource monitoring and optimization

### **Expected Deliverables**
1. **`notebooks/training/model_training.ipynb`** - Complete training notebook
2. **`notebooks/training/utils/`** - Supporting utility modules
3. **`notebooks/training/config/`** - Configuration files and templates
4. **`notebooks/training/docs/`** - Documentation and guides
5. **Integration tests** - Validation of MLflow integration
6. **Sample experiments** - Example training runs with results

### **Success Criteria**
- Notebook runs successfully with sample data
- MLflow integration logs all required metrics and artifacts
- Model training converges and shows improvement
- All visualizations and analysis tools work correctly
- Documentation is clear and comprehensive
- Integration with existing AstrID infrastructure is seamless
