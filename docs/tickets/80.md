## **ASTR-80: U-Net Model Integration (P2) - ML model integration**

### **Context & Current State**
The U-Net model architecture exists in `src/adapters/ml/unet.py` but needs integration with the new domain-driven architecture. This ticket focuses on porting the existing model to work with the detection pipeline and implementing proper model management.

### **Technical Requirements**

**Dependencies**: ASTR-79 (Source Extraction) - Pending
**Domain**: ML Domain (Detection)
**Estimated Time**: 3 days

### **Implementation Tasks**

1. **Port Existing U-Net Model to New Architecture**
   - Refactor `src/adapters/ml/unet.py` to follow domain patterns
   - Create `src/domains/detection/models/unet_model.py` for domain logic
   - Implement `UNetModel` domain entity with:
     - Model metadata (version, training date, performance metrics)
     - Input/output specifications
     - Confidence threshold configuration
   - Add model validation and health checks

2. **Implement Model Loading and Inference**
   - Create `src/domains/detection/services/model_inference.py`
   - Implement `ModelInferenceService` with:
     - Model loading from MLflow registry
     - Batch inference processing
     - Input preprocessing (normalization, resizing)
     - Output postprocessing (thresholding, NMS)
   - Add model caching and warm-up functionality

3. **Add Confidence Scoring**
   - Implement confidence calculation based on:
     - Model output probability
     - Input image quality metrics
     - Source extraction quality
   - Create confidence calibration system
   - Add uncertainty quantification methods

4. **Create Model Performance Tracking**
   - Integrate with MLflow for experiment tracking
   - Add performance metrics collection:
     - Inference latency
     - Memory usage
     - Accuracy on validation set
   - Implement model drift detection
   - Create performance monitoring dashboard

### **Integration Points**

- **Input**: Candidate sources from ASTR-79
- **Output**: Scored detections stored in `detections` table
- **Events**: Emit `detection.scored` events
- **Storage**: Model artifacts in R2, metadata in PostgreSQL

### **API Endpoints to Add**
```python
POST /detections/infer
GET /detections/{detection_id}/confidence
GET /models/{model_id}/performance
POST /models/{model_id}/validate
```

### **MLflow Integration**
```python
# Model registry integration
model_uri = f"models:/unet_astronomical/{model_version}"
model = mlflow.keras.load_model(model_uri)

# Experiment tracking
with mlflow.start_run():
    mlflow.log_params(inference_params)
    mlflow.log_metrics(performance_metrics)
```

### **Configuration Requirements**
Add to `src/core/config.py`:
```python
class ModelConfig:
    model_name: str = "unet_astronomical"
    model_version: str = "latest"
    confidence_threshold: float = 0.5
    batch_size: int = 32
    input_size: tuple[int, int] = (512, 512)
    enable_gpu: bool = True
```

### **Testing Strategy**
- Unit tests for model loading and inference
- Integration tests with real candidate data
- Performance benchmarks for different input sizes
- Model validation against ground truth data