{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ASTR-80 Testing: U-Net Inference + Persistence + MLflow\n",
        "This notebook validates the end-to-end path: candidates (ASTR-79) -> UNet inference -> detections persist -> optional MLflow logging.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, sys\n",
        "sys.path.insert(0, os.path.abspath('..'))\n",
        "import numpy as np\n",
        "from uuid import uuid4\n",
        "from sqlalchemy.ext.asyncio import AsyncSession\n",
        "from src.core.db.session import AsyncSessionLocal\n",
        "from src.domains.detection.services.model_inference import ModelInferenceService\n",
        "from src.domains.detection.config import ModelConfig\n",
        "print('âœ… Imports OK')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Synthetic difference image and candidates\n",
        "H, W = 512, 512\n",
        "D = np.zeros((H, W), dtype=np.float32)\n",
        "candidates = [{\"pixel_x\": 256, \"pixel_y\": 256}]\n",
        "observation_id = str(uuid4())\n",
        "model_run_id = str(uuid4())\n",
        "print('Obs:', observation_id, 'Run:', model_run_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://localhost:5000\"  # not 0.0.0.0\n",
        "os.environ[\"MLFLOW_TRACING_ENABLED\"] = \"false\"\n",
        "print(\"MLFLOW_TRACKING_URI=\", os.environ[\"MLFLOW_TRACKING_URI\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mlflow, requests\n",
        "mlflow.set_tracking_uri(os.environ[\"MLFLOW_TRACKING_URI\"])  # reuse env\n",
        "# Quick health check\n",
        "try:\n",
        "    r = requests.get(os.environ[\"MLFLOW_TRACKING_URI\"].rstrip(\"/\") + \"/health\", timeout=5)\n",
        "    print(\"MLflow /health:\", r.status_code)\n",
        "except Exception as e:\n",
        "    print(\"MLflow health check failed:\", e)\n",
        "\n",
        "with mlflow.start_run() as run:\n",
        "    mlflow.log_param(\"ping\", \"ok\")\n",
        "    print(\"run_id:\", run.info.run_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio, mlflow\n",
        "async def run_infer():\n",
        "    async with AsyncSessionLocal() as db:  # type: ignore\n",
        "        svc = ModelInferenceService(ModelConfig())\n",
        "        return await svc.infer_and_persist_candidates(db, observation_id, D, candidates, model_run_id=model_run_id)\n",
        "\n",
        "# Run and print run link if possible\n",
        "res = await run_infer()\n",
        "print(res)\n",
        "# We started our own run earlier (ping cell). No active run may be present here.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
