{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AstrID Model Training Notebook\n",
        "\n",
        "## U-Net Anomaly Detection with MLflow Integration\n",
        "\n",
        "This notebook provides a comprehensive training pipeline for the U-Net anomaly detection model with:\n",
        "- Complete MLflow experiment tracking\n",
        "- GPU energy monitoring (ASTR-101)\n",
        "- Comprehensive performance metrics (ASTR-102)\n",
        "- Data preprocessing integration\n",
        "- Visualization and debugging tools\n",
        "\n",
        "**Project**: ASTR-106 - Training Notebook for Model Training and MLflow Logging  \n",
        "**Dependencies**: ASTR-88 (MLflow Integration) ‚úÖ, ASTR-80 (U-Net Model) ‚úÖ, ASTR-76 (Preprocessing) ‚úÖ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Environment Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-22 14:41:18.193089: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Environment setup complete\n"
          ]
        }
      ],
      "source": [
        "# Core imports\n",
        "import os\n",
        "import sys\n",
        "import asyncio\n",
        "import logging\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List, Optional, Tuple, Union\n",
        "from dataclasses import dataclass, field\n",
        "from uuid import uuid4\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path.cwd().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Scientific computing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, roc_curve, precision_recall_curve, confusion_matrix,\n",
        "    classification_report, matthews_corrcoef\n",
        ")\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Deep learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torchvision.transforms as transforms\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
        "\n",
        "# MLflow and tracking\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "# AstrID imports\n",
        "from src.infrastructure.mlflow import MLflowConfig, ExperimentTracker, ModelRegistry\n",
        "from src.core.gpu_monitoring import GPUPowerMonitor, EnergyConsumption\n",
        "from src.core.mlflow_energy import MLflowEnergyTracker\n",
        "from src.core.energy_analysis import EnergyAnalyzer\n",
        "from src.domains.preprocessing.processors.astronomical_image_processing import AstronomicalImageProcessor\n",
        "from src.adapters.ml.unet import UNetModel\n",
        "from src.domains.detection.models import Model, ModelRun\n",
        "from src.domains.detection.metrics.detection_metrics import DetectionMetrics\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"‚úÖ Environment setup complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration and Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Current file location: /home/chris/github/AstrID/notebooks/training\n",
            "‚úÖ Added to Python path: /home/chris/github/AstrID\n",
            "‚úÖ Added project root to Python path: /home/chris/github\n",
            "‚úÖ Current working directory: /home/chris/github/AstrID/notebooks/training\n",
            "‚úÖ Python path includes notebooks: ['/home/chris/github/AstrID/notebooks']\n",
            "‚úÖ Successfully imported notebooks module\n"
          ]
        }
      ],
      "source": [
        "# Add notebooks directory to Python path for imports\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Get the absolute path to the notebooks directory\n",
        "# This works regardless of where the notebook is run from\n",
        "current_file = Path(__file__) if '__file__' in globals() else Path.cwd()\n",
        "notebooks_dir = current_file.parent.parent  # Go up two levels to get to notebooks/\n",
        "\n",
        "# Add both the notebooks directory and the project root to Python path\n",
        "sys.path.insert(0, str(notebooks_dir))\n",
        "sys.path.insert(0, str(notebooks_dir.parent))  # Also add project root\n",
        "\n",
        "print(f\"‚úÖ Current file location: {current_file}\")\n",
        "print(f\"‚úÖ Added to Python path: {notebooks_dir}\")\n",
        "print(f\"‚úÖ Added project root to Python path: {notebooks_dir.parent}\")\n",
        "print(f\"‚úÖ Current working directory: {Path.cwd()}\")\n",
        "print(f\"‚úÖ Python path includes notebooks: {[p for p in sys.path if 'notebooks' in p]}\")\n",
        "\n",
        "# Test the import\n",
        "try:\n",
        "    import notebooks\n",
        "    print(\"‚úÖ Successfully imported notebooks module\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Failed to import notebooks: {e}\")\n",
        "    print(\"üí° Trying alternative approach...\")\n",
        "    \n",
        "    # Alternative: Add the specific path\n",
        "    training_utils_path = notebooks_dir / \"training\" / \"utils\"\n",
        "    sys.path.insert(0, str(training_utils_path))\n",
        "    print(f\"‚úÖ Added training utils path: {training_utils_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã Training configuration initialized: training_run_20250922_144122\n"
          ]
        }
      ],
      "source": [
        "@dataclass\n",
        "class TrainingConfig:\n",
        "    \"\"\"Comprehensive training configuration.\"\"\"\n",
        "    \n",
        "    # Experiment settings\n",
        "    experiment_name: str = \"unet_anomaly_detection\"\n",
        "    experiment_id: str = \"\"\n",
        "    run_name: str = f\"training_run_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "    \n",
        "    # Model architecture\n",
        "    model_name: str = \"unet_anomaly_detector\"\n",
        "    input_channels: int = 1\n",
        "    output_channels: int = 1\n",
        "    input_size: Tuple[int, int] = (512, 512)\n",
        "    initial_filters: int = 64\n",
        "    depth: int = 4\n",
        "    \n",
        "    # Training parameters\n",
        "    batch_size: int = 16\n",
        "    learning_rate: float = 0.001\n",
        "    num_epochs: int = 100\n",
        "    weight_decay: float = 1e-4\n",
        "    gradient_clip_norm: float = 1.0\n",
        "    \n",
        "    # Data parameters\n",
        "    validation_split: float = 0.2\n",
        "    test_split: float = 0.1\n",
        "    \n",
        "    # Training strategy\n",
        "    early_stopping_patience: int = 10\n",
        "    checkpoint_frequency: int = 5\n",
        "    \n",
        "    # MLflow parameters\n",
        "    mlflow_tracking_uri: str = \"http://localhost:5000\"\n",
        "    \n",
        "    # Energy tracking\n",
        "    enable_energy_tracking: bool = True\n",
        "    gpu_power_sampling_hz: float = 1.0\n",
        "    carbon_intensity_kg_per_kwh: float = 0.233\n",
        "    \n",
        "    # Performance metrics\n",
        "    confidence_threshold: float = 0.5\n",
        "    \n",
        "    # Tags for MLflow\n",
        "    tags: Dict[str, str] = field(default_factory=lambda: {\n",
        "        \"model_type\": \"unet\",\n",
        "        \"task\": \"anomaly_detection\",\n",
        "        \"dataset\": \"astronomical_images\",\n",
        "        \"framework\": \"pytorch\",\n",
        "        \"gpu_tracking\": \"enabled\"\n",
        "    })\n",
        "\n",
        "# Initialize configuration\n",
        "config = TrainingConfig()\n",
        "print(f\"üìã Training configuration initialized: {config.run_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. MLflow Setup and Experiment Tracking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Python paths configured for imports\n"
          ]
        }
      ],
      "source": [
        "# Set up Python path for imports\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add paths for imports\n",
        "sys.path.insert(0, str(Path.cwd() / \"utils\"))  # For utility files\n",
        "sys.path.insert(0, str(Path.cwd().parent.parent))  # For src modules\n",
        "print(\"‚úÖ Python paths configured for imports\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç MLflow configuration: MLflowConfig(tracking_uri='http://localhost:5000', artifact_root='r2://astrid-mlflow/artifacts', database_url='', authentication_enabled=False, model_registry_enabled=True, experiment_auto_logging=True, artifact_compression=True, max_artifact_size=104857600, server_host='0.0.0.0', server_port=5000, server_workers=4, server_timeout=120, auth_config={}, storage_config=None)\n",
            "üîç MLflow client: <mlflow.tracking.client.MlflowClient object at 0x7f8b8f2d6600>\n",
            "üîç MLflow tracking URI: http://localhost:5000\n",
            "‚úÖ Created new experiment: unet_anomaly_detection\n",
            "üî¨ Experiment ID: 2\n"
          ]
        }
      ],
      "source": [
        "# Initialize MLflow configuration\n",
        "mlflow_config = MLflowConfig(\n",
        "    tracking_uri=config.mlflow_tracking_uri,\n",
        "    artifact_root=\"r2://astrid-mlflow/artifacts\"\n",
        ")\n",
        "\n",
        "print(f\"üîç MLflow configuration: {mlflow_config}\")\n",
        "\n",
        "# Initialize MLflow components\n",
        "experiment_tracker = ExperimentTracker(mlflow_config)\n",
        "model_registry = ModelRegistry(mlflow_config)\n",
        "mlflow_client = MlflowClient(tracking_uri=config.mlflow_tracking_uri)\n",
        "\n",
        "print(f\"üîç MLflow client: {mlflow_client}\")\n",
        "\n",
        "# Set MLflow tracking URI\n",
        "mlflow.set_tracking_uri(config.mlflow_tracking_uri)\n",
        "\n",
        "print(f\"üîç MLflow tracking URI: {config.mlflow_tracking_uri}\")\n",
        "\n",
        "# Create or get experiment\n",
        "try:\n",
        "    experiment_id = experiment_tracker.create_experiment(\n",
        "        name=config.experiment_name,\n",
        "        description=\"U-Net anomaly detection training experiments\"\n",
        "    )\n",
        "    print(f\"‚úÖ Created new experiment: {config.experiment_name}\")\n",
        "except Exception as e:\n",
        "    # Get existing experiment\n",
        "    experiment = mlflow_client.get_experiment_by_name(config.experiment_name)\n",
        "    if experiment:\n",
        "        experiment_id = experiment.experiment_id\n",
        "        print(f\"‚úÖ Using existing experiment: {config.experiment_name}\")\n",
        "    else:\n",
        "        raise e\n",
        "\n",
        "print(f\"üî¨ Experiment ID: {experiment_id}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Loading sample astronomical data...\n",
            "‚úÖ Loaded 200 samples\n",
            "‚úÖ Data transforms created\n",
            "üìä Data splits: Train=139, Val=40, Test=21\n",
            "‚úÖ Data loading complete\n"
          ]
        }
      ],
      "source": [
        "# Import data loading utilities\n",
        "from training_utils import AstronomicalDataset, create_data_transforms, load_sample_data\n",
        "\n",
        "# Load sample data\n",
        "print(\"üìä Loading sample astronomical data...\")\n",
        "sample_images, sample_masks = load_sample_data(\n",
        "    num_samples=200, \n",
        "    image_size=config.input_size\n",
        ")\n",
        "print(f\"‚úÖ Loaded {len(sample_images)} samples\")\n",
        "\n",
        "# Create data transforms\n",
        "train_transform, val_transform = create_data_transforms()\n",
        "print(\"‚úÖ Data transforms created\")\n",
        "\n",
        "# Create datasets\n",
        "train_images, val_images, train_masks, val_masks = train_test_split(\n",
        "    sample_images, sample_masks, \n",
        "    test_size=config.validation_split + config.test_split, \n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "val_images, test_images, val_masks, test_masks = train_test_split(\n",
        "    val_images, val_masks,\n",
        "    test_size=config.test_split / (config.validation_split + config.test_split),\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Create PyTorch datasets\n",
        "train_dataset = AstronomicalDataset(\n",
        "    train_images, train_masks, \n",
        "    transform=train_transform\n",
        ")\n",
        "val_dataset = AstronomicalDataset(\n",
        "    val_images, val_masks, \n",
        "    transform=val_transform\n",
        ")\n",
        "test_dataset = AstronomicalDataset(\n",
        "    test_images, test_masks, \n",
        "    transform=val_transform\n",
        ")\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size=config.batch_size, \n",
        "    shuffle=True, \n",
        "    num_workers=2\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, \n",
        "    batch_size=config.batch_size, \n",
        "    shuffle=False, \n",
        "    num_workers=2\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, \n",
        "    batch_size=config.batch_size, \n",
        "    shuffle=False, \n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "print(f\"üìä Data splits: Train={len(train_dataset)}, Val={len(val_dataset)}, Test={len(test_dataset)}\")\n",
        "print(\"‚úÖ Data loading complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. GPU Energy Tracking Setup (ASTR-101)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîã GPU energy tracking initialized\n",
            "üéÆ GPU available: NVIDIA GeForce RTX 3080 (Count: 1)\n"
          ]
        }
      ],
      "source": [
        "# Initialize GPU energy tracking\n",
        "if config.enable_energy_tracking:\n",
        "    gpu_monitor = GPUPowerMonitor(\n",
        "        sampling_interval=1.0 / config.gpu_power_sampling_hz,\n",
        "        carbon_intensity_kg_per_kwh=config.carbon_intensity_kg_per_kwh\n",
        "    )\n",
        "    \n",
        "    energy_tracker = MLflowEnergyTracker(\n",
        "        experiment_name=config.experiment_name\n",
        "    )\n",
        "    \n",
        "    energy_analyzer = EnergyAnalyzer()\n",
        "    \n",
        "    print(\"üîã GPU energy tracking initialized\")\n",
        "    \n",
        "    # Check GPU availability\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_count = torch.cuda.device_count()\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        print(f\"üéÆ GPU available: {gpu_name} (Count: {gpu_count})\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  No GPU available - energy tracking will use simulation mode\")\n",
        "else:\n",
        "    gpu_monitor = None\n",
        "    energy_tracker = None\n",
        "    energy_analyzer = None\n",
        "    print(\"‚ö° Energy tracking disabled\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Data Loading and Preprocessing Integration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Training utilities imported\n",
            "‚úÖ Comprehensive metrics calculator imported\n",
            "‚úÖ Training manager imported\n",
            "üìä Loading sample astronomical data...\n",
            "‚úÖ Loaded 200 samples\n",
            "‚úÖ Data transforms created\n",
            "üìä Data splits: Train=139, Val=40, Test=21\n",
            "‚úÖ Data loading complete\n"
          ]
        }
      ],
      "source": [
        "# Import training utilities\n",
        "from notebooks.training.utils.training_utils import (\n",
        "    AstronomicalDataset, create_data_transforms, load_sample_data\n",
        ")\n",
        "print(\"‚úÖ Training utilities imported\")\n",
        "from notebooks.training.utils.performance_metrics import ComprehensiveMetricsCalculator\n",
        "print(\"‚úÖ Comprehensive metrics calculator imported\")\n",
        "from notebooks.training.utils.training_manager import TrainingManager\n",
        "print(\"‚úÖ Training manager imported\")\n",
        "\n",
        "# Load sample data\n",
        "print(\"üìä Loading sample astronomical data...\")\n",
        "sample_images, sample_masks = load_sample_data(\n",
        "    num_samples=200, \n",
        "    image_size=config.input_size\n",
        ")\n",
        "print(f\"‚úÖ Loaded {len(sample_images)} samples\")\n",
        "\n",
        "# Create data transforms\n",
        "train_transform, val_transform = create_data_transforms()\n",
        "print(\"‚úÖ Data transforms created\")\n",
        "\n",
        "# Create datasets\n",
        "train_images, val_images, train_masks, val_masks = train_test_split(\n",
        "    sample_images, sample_masks, \n",
        "    test_size=config.validation_split + config.test_split, \n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "val_images, test_images, val_masks, test_masks = train_test_split(\n",
        "    val_images, val_masks,\n",
        "    test_size=config.test_split / (config.validation_split + config.test_split),\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Create PyTorch datasets\n",
        "train_dataset = AstronomicalDataset(\n",
        "    train_images, train_masks, \n",
        "    transform=train_transform\n",
        ")\n",
        "val_dataset = AstronomicalDataset(\n",
        "    val_images, val_masks, \n",
        "    transform=val_transform\n",
        ")\n",
        "test_dataset = AstronomicalDataset(\n",
        "    test_images, test_masks, \n",
        "    transform=val_transform\n",
        ")\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size=config.batch_size, \n",
        "    shuffle=True, \n",
        "    num_workers=2\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, \n",
        "    batch_size=config.batch_size, \n",
        "    shuffle=False, \n",
        "    num_workers=2\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, \n",
        "    batch_size=config.batch_size, \n",
        "    shuffle=False, \n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "print(f\"üìä Data splits: Train={len(train_dataset)}, Val={len(val_dataset)}, Test={len(test_dataset)}\")\n",
        "print(\"‚úÖ Data loading complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import training manager\n",
        "from training_manager import TrainingManager\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Architecture and Training Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèóÔ∏è  Model Architecture:\n",
            "   Total parameters: 22,637,889\n",
            "   Trainable parameters: 22,637,889\n",
            "   Model size: 86.36 MB\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 107\u001b[39m\n\u001b[32m    100\u001b[39m optimizer = optim.Adam(\n\u001b[32m    101\u001b[39m     model.parameters(), \n\u001b[32m    102\u001b[39m     lr=config.learning_rate, \n\u001b[32m    103\u001b[39m     weight_decay=config.weight_decay\n\u001b[32m    104\u001b[39m )\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Learning rate scheduler\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m scheduler = \u001b[43mReduceLROnPlateau\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmin\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfactor\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    113\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Model, loss function, and optimizer initialized\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mTypeError\u001b[39m: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'"
          ]
        }
      ],
      "source": [
        "# Define U-Net model architecture\n",
        "class UNet(nn.Module):\n",
        "    \"\"\"U-Net architecture for astronomical anomaly detection.\"\"\"\n",
        "    \n",
        "    def __init__(self, in_channels=1, out_channels=1, initial_filters=64, depth=4):\n",
        "        super(UNet, self).__init__()\n",
        "        \n",
        "        self.depth = depth\n",
        "        self.initial_filters = initial_filters\n",
        "        \n",
        "        # Encoder\n",
        "        self.encoders = nn.ModuleList()\n",
        "        self.pools = nn.ModuleList()\n",
        "        \n",
        "        in_ch = in_channels\n",
        "        for i in range(depth):\n",
        "            out_ch = initial_filters * (2 ** i)\n",
        "            self.encoders.append(self._conv_block(in_ch, out_ch))\n",
        "            if i < depth - 1:  # No pooling after last encoder\n",
        "                self.pools.append(nn.MaxPool2d(2))\n",
        "            in_ch = out_ch\n",
        "        \n",
        "        # Bottleneck\n",
        "        self.bottleneck = self._conv_block(\n",
        "            initial_filters * (2 ** (depth - 1)), \n",
        "            initial_filters * (2 ** depth)\n",
        "        )\n",
        "        \n",
        "        # Decoder\n",
        "        self.decoders = nn.ModuleList()\n",
        "        self.upsamples = nn.ModuleList()\n",
        "        \n",
        "        for i in range(depth - 1, 0, -1):\n",
        "            in_ch = initial_filters * (2 ** i) + initial_filters * (2 ** (i - 1))\n",
        "            out_ch = initial_filters * (2 ** (i - 1))\n",
        "            self.upsamples.append(nn.ConvTranspose2d(\n",
        "                initial_filters * (2 ** i), \n",
        "                initial_filters * (2 ** (i - 1)), \n",
        "                kernel_size=2, \n",
        "                stride=2\n",
        "            ))\n",
        "            self.decoders.append(self._conv_block(in_ch, out_ch))\n",
        "        \n",
        "        # Final layer\n",
        "        self.final = nn.Conv2d(initial_filters, out_channels, kernel_size=1)\n",
        "        \n",
        "    def _conv_block(self, in_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Encoder path\n",
        "        encoder_outputs = []\n",
        "        for i, encoder in enumerate(self.encoders):\n",
        "            x = encoder(x)\n",
        "            encoder_outputs.append(x)\n",
        "            if i < len(self.pools):\n",
        "                x = self.pools[i](x)\n",
        "        \n",
        "        # Bottleneck\n",
        "        x = self.bottleneck(x)\n",
        "        \n",
        "        # Decoder path\n",
        "        for i, (upsample, decoder) in enumerate(zip(self.upsamples, self.decoders)):\n",
        "            x = upsample(x)\n",
        "            # Skip connection\n",
        "            skip_idx = len(encoder_outputs) - 2 - i\n",
        "            x = torch.cat([x, encoder_outputs[skip_idx]], dim=1)\n",
        "            x = decoder(x)\n",
        "        \n",
        "        # Final output\n",
        "        x = self.final(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model\n",
        "model = UNet(\n",
        "    in_channels=config.input_channels,\n",
        "    out_channels=config.output_channels,\n",
        "    initial_filters=config.initial_filters,\n",
        "    depth=config.depth\n",
        ")\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"üèóÔ∏è  Model Architecture:\")\n",
        "print(f\"   Total parameters: {total_params:,}\")\n",
        "print(f\"   Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"   Model size: {total_params * 4 / 1024 / 1024:.2f} MB\")\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(\n",
        "    model.parameters(), \n",
        "    lr=config.learning_rate, \n",
        "    weight_decay=config.weight_decay\n",
        ")\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = ReduceLROnPlateau(\n",
        "    optimizer, \n",
        "    mode='min', \n",
        "    factor=0.5, \n",
        "    patience=5, \n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Model, loss function, and optimizer initialized\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Comprehensive Training with MLflow and Energy Tracking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize training manager\n",
        "training_manager = TrainingManager(\n",
        "    config=config,\n",
        "    experiment_tracker=experiment_tracker,\n",
        "    model_registry=model_registry,\n",
        "    mlflow_client=mlflow_client,\n",
        "    gpu_monitor=gpu_monitor,\n",
        "    energy_tracker=energy_tracker\n",
        ")\n",
        "\n",
        "# Add experiment_id to config for training manager\n",
        "config.experiment_id = experiment_id\n",
        "\n",
        "print(\"üöÄ Starting comprehensive training with full tracking...\")\n",
        "print(f\"   - MLflow experiment tracking: ‚úÖ\")\n",
        "print(f\"   - GPU energy monitoring: {'‚úÖ' if config.enable_energy_tracking else '‚ùå'}\")\n",
        "print(f\"   - Performance metrics (ASTR-102): ‚úÖ\")\n",
        "print(f\"   - Model checkpointing: ‚úÖ\")\n",
        "\n",
        "# Start training\n",
        "try:\n",
        "    run_id = await training_manager.start_training_run(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        optimizer=optimizer,\n",
        "        criterion=criterion,\n",
        "        scheduler=scheduler\n",
        "    )\n",
        "    \n",
        "    print(f\"üéâ Training completed successfully!\")\n",
        "    print(f\"üìä MLflow Run ID: {run_id}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Training failed: {e}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Training Visualization and Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot comprehensive training curves\n",
        "print(\"üìä Generating training visualizations...\")\n",
        "training_manager.plot_training_summary()\n",
        "\n",
        "# Get training summary\n",
        "training_summary = training_manager.get_training_summary()\n",
        "print(f\"\\nüìà Training Summary:\")\n",
        "print(f\"   Best validation loss: {training_summary['best_val_loss']:.4f}\")\n",
        "print(f\"   Total epochs: {training_summary['total_epochs']}\")\n",
        "print(f\"   Final train loss: {training_summary['final_train_loss']:.4f}\")\n",
        "print(f\"   Final val loss: {training_summary['final_val_loss']:.4f}\")\n",
        "\n",
        "# Display final metrics\n",
        "final_metrics = training_summary['final_val_metrics']\n",
        "if final_metrics:\n",
        "    print(f\"\\nüéØ Final Validation Metrics:\")\n",
        "    print(f\"   Accuracy: {final_metrics.get('accuracy', 0.0):.4f}\")\n",
        "    print(f\"   Precision: {final_metrics.get('precision_macro', 0.0):.4f}\")\n",
        "    print(f\"   Recall: {final_metrics.get('recall_macro', 0.0):.4f}\")\n",
        "    print(f\"   F1 Score: {final_metrics.get('f1_macro', 0.0):.4f}\")\n",
        "    print(f\"   AUROC: {final_metrics.get('auroc', 0.0):.4f}\")\n",
        "    print(f\"   AUPRC: {final_metrics.get('auprc', 0.0):.4f}\")\n",
        "    print(f\"   MCC: {final_metrics.get('mcc', 0.0):.4f}\")\n",
        "    print(f\"   Balanced Accuracy: {final_metrics.get('balanced_accuracy', 0.0):.4f}\")\n",
        "    \n",
        "    # Performance metrics\n",
        "    print(f\"\\n‚ö° Performance Metrics:\")\n",
        "    print(f\"   Latency P50: {final_metrics.get('latency_ms_p50', 0.0):.2f} ms\")\n",
        "    print(f\"   Latency P95: {final_metrics.get('latency_ms_p95', 0.0):.2f} ms\")\n",
        "    print(f\"   Throughput: {final_metrics.get('throughput_items_per_s', 0.0):.2f} items/s\")\n",
        "    \n",
        "    # Energy metrics (if available)\n",
        "    if config.enable_energy_tracking:\n",
        "        print(f\"\\nüîã Energy Metrics:\")\n",
        "        print(f\"   Energy consumed: {final_metrics.get('training_energy_wh', 0.0):.3f} Wh\")\n",
        "        print(f\"   Average power: {final_metrics.get('training_avg_power_w', 0.0):.1f} W\")\n",
        "        print(f\"   Peak power: {final_metrics.get('training_peak_power_w', 0.0):.1f} W\")\n",
        "        print(f\"   Carbon footprint: {final_metrics.get('training_carbon_footprint_kg', 0.0):.6f} kg CO2\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Model Evaluation and Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model for evaluation\n",
        "import time\n",
        "best_checkpoint_path = training_manager.checkpoint_manager.checkpoint_dir / \"best_model.pt\"\n",
        "if best_checkpoint_path.exists():\n",
        "    checkpoint = training_manager.checkpoint_manager.load_checkpoint(str(best_checkpoint_path))\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(\"‚úÖ Loaded best model for evaluation\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Best model checkpoint not found, using current model\")\n",
        "\n",
        "# Evaluate on test set\n",
        "print(\"üß™ Evaluating model on test set...\")\n",
        "model.eval()\n",
        "\n",
        "all_predictions = []\n",
        "all_targets = []\n",
        "all_scores = []\n",
        "inference_times = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(training_manager.device), target.to(training_manager.device)\n",
        "        \n",
        "        start_time = time.time()\n",
        "        output = model(data)\n",
        "        inference_time = time.time() - start_time\n",
        "        inference_times.append(inference_time)\n",
        "        \n",
        "        predictions = (torch.sigmoid(output) > config.confidence_threshold).float()\n",
        "        scores = torch.sigmoid(output).cpu().detach().numpy().flatten()\n",
        "        \n",
        "        all_predictions.extend(predictions.cpu().detach().numpy().flatten())\n",
        "        all_targets.extend(target.cpu().detach().numpy().flatten())\n",
        "        all_scores.extend(scores)\n",
        "\n",
        "# Calculate comprehensive test metrics\n",
        "all_predictions = np.array(all_predictions)\n",
        "all_targets = np.array(all_targets)\n",
        "all_scores = np.array(all_scores)\n",
        "\n",
        "test_metrics = training_manager.metrics_calculator.calculate_all_metrics(\n",
        "    all_targets, all_predictions, all_scores, inference_times, config.batch_size\n",
        ")\n",
        "\n",
        "print(f\"\\nüéØ Test Set Results:\")\n",
        "print(f\"   Accuracy: {test_metrics.get('accuracy', 0.0):.4f}\")\n",
        "print(f\"   Precision: {test_metrics.get('precision_macro', 0.0):.4f}\")\n",
        "print(f\"   Recall: {test_metrics.get('recall_macro', 0.0):.4f}\")\n",
        "print(f\"   F1 Score: {test_metrics.get('f1_macro', 0.0):.4f}\")\n",
        "print(f\"   AUROC: {test_metrics.get('auroc', 0.0):.4f}\")\n",
        "print(f\"   AUPRC: {test_metrics.get('auprc', 0.0):.4f}\")\n",
        "print(f\"   MCC: {test_metrics.get('mcc', 0.0):.4f}\")\n",
        "print(f\"   Balanced Accuracy: {test_metrics.get('balanced_accuracy', 0.0):.4f}\")\n",
        "\n",
        "# Performance metrics\n",
        "print(f\"\\n‚ö° Test Performance:\")\n",
        "print(f\"   Latency P50: {test_metrics.get('latency_ms_p50', 0.0):.2f} ms\")\n",
        "print(f\"   Latency P95: {test_metrics.get('latency_ms_p95', 0.0):.2f} ms\")\n",
        "print(f\"   Throughput: {test_metrics.get('throughput_items_per_s', 0.0):.2f} items/s\")\n",
        "\n",
        "# Generate visualizations\n",
        "from notebooks.training.utils.training_utils import TrainingVisualizer\n",
        "visualizer = TrainingVisualizer()\n",
        "\n",
        "print(\"\\nüìä Generating evaluation visualizations...\")\n",
        "visualizer.plot_confusion_matrix(all_targets, all_predictions)\n",
        "visualizer.plot_roc_curve(all_targets, all_scores)\n",
        "visualizer.plot_precision_recall_curve(all_targets, all_scores)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Troubleshooting and Debugging Tools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model debugging and inspection tools\n",
        "def inspect_model_predictions(model, data_loader, num_samples=5):\n",
        "    \"\"\"Inspect model predictions for debugging.\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, (data, target) in enumerate(data_loader):\n",
        "            if i >= num_samples:\n",
        "                break\n",
        "                \n",
        "            data = data.to(training_manager.device)\n",
        "            output = model(data)\n",
        "            predictions = torch.sigmoid(output)\n",
        "            \n",
        "            # Convert to numpy for visualization\n",
        "            image = data[0].cpu().numpy().squeeze()\n",
        "            target_mask = target[0].cpu().numpy().squeeze()\n",
        "            pred_mask = (predictions[0].cpu().numpy().squeeze() > config.confidence_threshold).astype(float)\n",
        "            confidence = predictions[0].cpu().numpy().squeeze()\n",
        "            \n",
        "            # Create visualization\n",
        "            fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
        "            \n",
        "            axes[0].imshow(image, cmap='gray')\n",
        "            axes[0].set_title('Input Image')\n",
        "            axes[0].axis('off')\n",
        "            \n",
        "            axes[1].imshow(target_mask, cmap='hot')\n",
        "            axes[1].set_title('Ground Truth')\n",
        "            axes[1].axis('off')\n",
        "            \n",
        "            axes[2].imshow(pred_mask, cmap='hot')\n",
        "            axes[2].set_title('Prediction')\n",
        "            axes[2].axis('off')\n",
        "            \n",
        "            im = axes[3].imshow(confidence, cmap='viridis')\n",
        "            axes[3].set_title('Confidence Map')\n",
        "            axes[3].axis('off')\n",
        "            plt.colorbar(im, ax=axes[3])\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            \n",
        "            # Print statistics\n",
        "            print(f\"Sample {i+1}:\")\n",
        "            print(f\"  Target pixels: {np.sum(target_mask):.0f}\")\n",
        "            print(f\"  Predicted pixels: {np.sum(pred_mask):.0f}\")\n",
        "            print(f\"  Confidence range: [{np.min(confidence):.3f}, {np.max(confidence):.3f}]\")\n",
        "            print(f\"  IoU: {np.sum((target_mask > 0) & (pred_mask > 0)) / np.sum((target_mask > 0) | (pred_mask > 0)):.3f}\")\n",
        "            print()\n",
        "\n",
        "def analyze_training_issues():\n",
        "    \"\"\"Analyze potential training issues.\"\"\"\n",
        "    print(\"üîç Training Analysis:\")\n",
        "    \n",
        "    # Check for overfitting\n",
        "    train_losses = training_summary['training_history']['train_losses']\n",
        "    val_losses = training_summary['training_history']['val_losses']\n",
        "    \n",
        "    if len(train_losses) > 5 and len(val_losses) > 5:\n",
        "        train_trend = np.mean(train_losses[-5:]) - np.mean(train_losses[:5])\n",
        "        val_trend = np.mean(val_losses[-5:]) - np.mean(val_losses[:5])\n",
        "        \n",
        "        if val_trend > train_trend * 1.5:\n",
        "            print(\"‚ö†Ô∏è  Potential overfitting detected - validation loss increasing while training loss decreasing\")\n",
        "        elif val_trend < -0.1:\n",
        "            print(\"‚úÖ Good training progress - both losses decreasing\")\n",
        "        else:\n",
        "            print(\"‚ÑπÔ∏è  Training appears stable\")\n",
        "    \n",
        "    # Check learning rate\n",
        "    lr_history = training_summary['training_history']['learning_rates']\n",
        "    if len(lr_history) > 1:\n",
        "        lr_change = (lr_history[-1] - lr_history[0]) / lr_history[0]\n",
        "        if lr_change < -0.5:\n",
        "            print(\"‚ÑπÔ∏è  Learning rate significantly reduced during training\")\n",
        "        else:\n",
        "            print(\"‚ÑπÔ∏è  Learning rate relatively stable\")\n",
        "    \n",
        "    # Check convergence\n",
        "    if len(val_losses) > 10:\n",
        "        recent_val_losses = val_losses[-10:]\n",
        "        val_std = np.std(recent_val_losses)\n",
        "        if val_std < 0.01:\n",
        "            print(\"‚úÖ Model appears to have converged\")\n",
        "        else:\n",
        "            print(\"‚ÑπÔ∏è  Model may still be learning\")\n",
        "\n",
        "# Run debugging tools\n",
        "print(\"üîß Running debugging and analysis tools...\")\n",
        "inspect_model_predictions(model, test_loader, num_samples=3)\n",
        "analyze_training_issues()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Summary and Next Steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training Summary and Next Steps\n",
        "print(\"üéâ ASTR-106 Training Notebook Complete!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nüìä What was accomplished:\")\n",
        "print(\"‚úÖ Complete MLflow experiment tracking (ASTR-88 integration)\")\n",
        "print(\"‚úÖ GPU energy monitoring and carbon footprint tracking (ASTR-101)\")\n",
        "print(\"‚úÖ Comprehensive performance metrics (ASTR-102)\")\n",
        "print(\"‚úÖ Data preprocessing integration (ASTR-76)\")\n",
        "print(\"‚úÖ U-Net model training with PyTorch\")\n",
        "print(\"‚úÖ Model checkpointing and versioning\")\n",
        "print(\"‚úÖ Visualization and debugging tools\")\n",
        "print(\"‚úÖ Model evaluation and testing\")\n",
        "\n",
        "print(f\"\\nüìà Training Results:\")\n",
        "print(f\"   MLflow Run ID: {run_id}\")\n",
        "print(f\"   Best validation loss: {training_summary['best_val_loss']:.4f}\")\n",
        "print(f\"   Final test accuracy: {test_metrics.get('accuracy', 0.0):.4f}\")\n",
        "print(f\"   Final test F1 score: {test_metrics.get('f1_macro', 0.0):.4f}\")\n",
        "\n",
        "if config.enable_energy_tracking:\n",
        "    print(f\"\\nüîã Energy Impact:\")\n",
        "    print(f\"   Total energy consumed: {test_metrics.get('training_energy_wh', 0.0):.3f} Wh\")\n",
        "    print(f\"   Carbon footprint: {test_metrics.get('training_carbon_footprint_kg', 0.0):.6f} kg CO2\")\n",
        "\n",
        "print(f\"\\nüìÅ Outputs:\")\n",
        "print(f\"   Model checkpoints: {training_manager.checkpoint_manager.checkpoint_dir}\")\n",
        "print(f\"   MLflow artifacts: {config.mlflow_tracking_uri}\")\n",
        "print(f\"   Training logs: Available in MLflow UI\")\n",
        "\n",
        "print(f\"\\nüöÄ Next Steps:\")\n",
        "print(\"1. Review results in MLflow UI\")\n",
        "print(\"2. Deploy best model to production\")\n",
        "print(\"3. Set up automated retraining pipeline\")\n",
        "print(\"4. Monitor model performance in production\")\n",
        "print(\"5. Collect more training data for improvement\")\n",
        "\n",
        "print(f\"\\nüîó Useful Links:\")\n",
        "print(f\"   MLflow UI: {config.mlflow_tracking_uri}\")\n",
        "print(f\"   Model Registry: {config.mlflow_tracking_uri}/#/models\")\n",
        "print(f\"   Experiment: {config.mlflow_tracking_uri}/#/experiments/{experiment_id}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üéØ ASTR-106 Implementation Complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
