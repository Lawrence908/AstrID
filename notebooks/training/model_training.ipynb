{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AstrID Model Training Notebook\n",
        "\n",
        "## U-Net Anomaly Detection with MLflow Integration\n",
        "\n",
        "This notebook provides a comprehensive training pipeline for the U-Net anomaly detection model with:\n",
        "- Complete MLflow experiment tracking\n",
        "- GPU energy monitoring (ASTR-101)\n",
        "- Comprehensive performance metrics (ASTR-102)\n",
        "- Data preprocessing integration\n",
        "- Visualization and debugging tools\n",
        "\n",
        "**Project**: ASTR-106 - Training Notebook for Model Training and MLflow Logging  \n",
        "**Dependencies**: ASTR-88 (MLflow Integration) ‚úÖ, ASTR-80 (U-Net Model) ‚úÖ, ASTR-76 (Preprocessing) ‚úÖ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Environment Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-18 22:57:24.676931: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Project root: /home/chris/github/AstrID/notebooks\n",
            "‚úÖ Environment setup complete\n"
          ]
        }
      ],
      "source": [
        "# Core imports\n",
        "import os\n",
        "import sys\n",
        "import asyncio\n",
        "import logging\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List, Optional, Tuple, Union\n",
        "from dataclasses import dataclass, field\n",
        "from uuid import uuid4\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path.cwd().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Scientific computing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, roc_curve, precision_recall_curve, confusion_matrix,\n",
        "    classification_report, matthews_corrcoef\n",
        ")\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Deep learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torchvision.transforms as transforms\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
        "\n",
        "# MLflow and tracking\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "# AstrID imports\n",
        "from src.infrastructure.mlflow import MLflowConfig, ExperimentTracker, ModelRegistry\n",
        "from src.core.gpu_monitoring import GPUPowerMonitor, EnergyConsumption\n",
        "from src.core.mlflow_energy import MLflowEnergyTracker\n",
        "from src.core.energy_analysis import EnergyAnalyzer\n",
        "from src.domains.preprocessing.processors.astronomical_image_processing import AstronomicalImageProcessor\n",
        "from src.adapters.ml.unet import UNetModel\n",
        "from src.domains.detection.models import Model, ModelRun\n",
        "from src.domains.detection.metrics.detection_metrics import DetectionMetrics\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "project_root = Path.cwd().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "print(f\"‚úÖ Project root: {project_root}\")\n",
        "\n",
        "\n",
        "print(\"‚úÖ Environment setup complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.core.constants import TRAINING_PIPELINE_API_KEY\n",
        "\n",
        "global AUTH_HEADERS\n",
        "AUTH_HEADERS = {\n",
        "    \"X-API-Key\": TRAINING_PIPELINE_API_KEY,\n",
        "    \"Content-Type\": \"application/json\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç MLflow tracking URI: postgresql+asyncpg://postgres.piqpfeytatilqmzgpaei:****@aws-1-us-west-1.pooler.supabase.com/postgres\n",
            "üîç MLflow environment variables:\n",
            "   MLFLOW_SUPABASE_HOST: aws-1-us-west-1.pooler.supabase.com\n",
            "   MLFLOW_SUPABASE_PROJECT_REF: piqpfeytatilqmzgpaei\n",
            "   MLFLOW_SUPABASE_PASSWORD: Set\n"
          ]
        }
      ],
      "source": [
        "# Debug: Check MLflow configuration\n",
        "import os\n",
        "import re\n",
        "from src.core.constants import get_mlflow_tracking_uri\n",
        "\n",
        "# Mask password in tracking URI before printing\n",
        "def mask_uri_password(uri):\n",
        "    \"\"\"Mask password in database URI for safe logging.\"\"\"\n",
        "    if not uri or '@' not in uri:\n",
        "        return uri\n",
        "    # Pattern: postgresql+asyncpg://user:password@host/db\n",
        "    # Replace password with ****\n",
        "    return re.sub(r'://([^:]+):([^@]+)@', r'://\\1:****@', uri)\n",
        "\n",
        "tracking_uri = get_mlflow_tracking_uri()\n",
        "masked_uri = mask_uri_password(tracking_uri)\n",
        "\n",
        "print(f\"üîç MLflow tracking URI: {masked_uri}\")\n",
        "print(f\"üîç MLflow environment variables:\")\n",
        "print(f\"   MLFLOW_SUPABASE_HOST: {os.getenv('MLFLOW_SUPABASE_HOST', 'Not set')}\")\n",
        "print(f\"   MLFLOW_SUPABASE_PROJECT_REF: {os.getenv('MLFLOW_SUPABASE_PROJECT_REF', 'Not set')}\")\n",
        "print(f\"   MLFLOW_SUPABASE_PASSWORD: {'Set' if os.getenv('MLFLOW_SUPABASE_PASSWORD') else 'Not set'}\")\n",
        "\n",
        "# Check if we should use a different approach\n",
        "if not tracking_uri or 'None' in tracking_uri:\n",
        "    print(\"‚ö†Ô∏è  MLflow environment variables not set, using local SQLite backend\")\n",
        "    print(\"üí° Consider setting MLFLOW_SUPABASE_* environment variables for production\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration and Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Current file location: /home/chris/github/AstrID/notebooks/training\n",
            "‚úÖ Added to Python path: /home/chris/github/AstrID\n",
            "‚úÖ Added project root to Python path: /home/chris/github\n",
            "‚úÖ Current working directory: /home/chris/github/AstrID/notebooks/training\n",
            "‚úÖ Python path includes notebooks: ['/home/chris/github/AstrID/notebooks', '/home/chris/github/AstrID/notebooks']\n",
            "‚úÖ Successfully imported notebooks module\n"
          ]
        }
      ],
      "source": [
        "# Add notebooks directory to Python path for imports\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Get the absolute path to the notebooks directory\n",
        "# This works regardless of where the notebook is run from\n",
        "current_file = Path(__file__) if '__file__' in globals() else Path.cwd()\n",
        "notebooks_dir = current_file.parent.parent  # Go up two levels to get to notebooks/\n",
        "\n",
        "# Add both the notebooks directory and the project root to Python path\n",
        "sys.path.insert(0, str(notebooks_dir))\n",
        "sys.path.insert(0, str(notebooks_dir.parent))  # Also add project root\n",
        "\n",
        "print(f\"‚úÖ Current file location: {current_file}\")\n",
        "print(f\"‚úÖ Added to Python path: {notebooks_dir}\")\n",
        "print(f\"‚úÖ Added project root to Python path: {notebooks_dir.parent}\")\n",
        "print(f\"‚úÖ Current working directory: {Path.cwd()}\")\n",
        "print(f\"‚úÖ Python path includes notebooks: {[p for p in sys.path if 'notebooks' in p]}\")\n",
        "\n",
        "# Test the import\n",
        "try:\n",
        "    import notebooks\n",
        "    print(\"‚úÖ Successfully imported notebooks module\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Failed to import notebooks: {e}\")\n",
        "    print(\"üí° Trying alternative approach...\")\n",
        "    \n",
        "    # Alternative: Add the specific path\n",
        "    training_utils_path = notebooks_dir / \"training\" / \"utils\"\n",
        "    sys.path.insert(0, str(training_utils_path))\n",
        "    print(f\"‚úÖ Added training utils path: {training_utils_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã Training configuration initialized: training_run_20251118_225727\n"
          ]
        }
      ],
      "source": [
        "from src.core.constants import get_mlflow_tracking_uri, MLFLOW_S3_ENDPOINT_URL, MLFLOW_BUCKET_NAME, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_DEFAULT_REGION\n",
        "\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TrainingConfig:\n",
        "    \"\"\"Comprehensive training configuration.\"\"\"\n",
        "    \n",
        "    # Experiment settings\n",
        "    experiment_name: str = \"unet_anomaly_detection\"\n",
        "    experiment_id: str = \"\"\n",
        "    run_name: str = f\"training_run_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "    \n",
        "    # Model architecture\n",
        "    model_name: str = \"unet_anomaly_detector\"\n",
        "    input_channels: int = 1\n",
        "    output_channels: int = 1\n",
        "    input_size: Tuple[int, int] = (512, 512)\n",
        "    initial_filters: int = 64\n",
        "    depth: int = 4\n",
        "    \n",
        "    # Training parameters\n",
        "    batch_size: int = 2\n",
        "    learning_rate: float = 0.001\n",
        "    num_epochs: int = 100\n",
        "    weight_decay: float = 1e-4\n",
        "    gradient_clip_norm: float = 1.0\n",
        "    \n",
        "    # Data parameters\n",
        "    validation_split: float = 0.2\n",
        "    test_split: float = 0.1\n",
        "    \n",
        "    # Training strategy\n",
        "    early_stopping_patience: int = 10\n",
        "    checkpoint_frequency: int = 5\n",
        "    \n",
        "    # MLflow parameters\n",
        "    mlflow_tracking_uri: str = \"http://localhost:9003\"\n",
        "    database_url: str = get_mlflow_tracking_uri()\n",
        "    mlflow_bucket_name: str = (MLFLOW_BUCKET_NAME or \"astrid-models\")\n",
        "    mlflow_endpoint_url: str = (MLFLOW_S3_ENDPOINT_URL or \"\")\n",
        "    mlflow_access_key_id: str = (AWS_ACCESS_KEY_ID or \"\")\n",
        "    mlflow_secret_access_key: str = (AWS_SECRET_ACCESS_KEY or \"\")\n",
        "    mlflow_region: str = (AWS_DEFAULT_REGION or \"auto\")\n",
        "    \n",
        "    # Artifact root\n",
        "    artifact_root: str = f\"s3://{mlflow_bucket_name}\"\n",
        "    \n",
        "    \n",
        "    # Energy tracking\n",
        "    enable_energy_tracking: bool = True\n",
        "    gpu_power_sampling_hz: float = 1.0\n",
        "    carbon_intensity_kg_per_kwh: float = 0.233\n",
        "    \n",
        "    # Performance metrics\n",
        "    confidence_threshold: float = 0.5\n",
        "    \n",
        "    # Tags for MLflow\n",
        "    tags: Dict[str, str] = field(default_factory=lambda: {\n",
        "        \"model_type\": \"unet\",\n",
        "        \"task\": \"anomaly_detection\",\n",
        "        \"dataset\": \"astronomical_images\",\n",
        "        \"framework\": \"pytorch\",\n",
        "        \"gpu_tracking\": \"enabled\"\n",
        "    })\n",
        "\n",
        "# Initialize configuration\n",
        "config = TrainingConfig()\n",
        "print(f\"üìã Training configuration initialized: {config.run_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. MLflow Setup and Experiment Tracking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Python paths configured for imports\n"
          ]
        }
      ],
      "source": [
        "# Set up Python path for imports\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add paths for imports\n",
        "sys.path.insert(0, str(Path.cwd() / \"utils\"))  # For utility files\n",
        "sys.path.insert(0, str(Path.cwd().parent.parent))  # For src modules\n",
        "print(\"‚úÖ Python paths configured for imports\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç MLflow configuration: MLflowConfig(tracking_uri='http://localhost:9003', artifact_root='s3://astrid-models', database_url='postgresql+asyncpg://postgres.piqpfeytatilqmzgpaei:SPXQgzx4xwuBVFmJ@aws-1-us-west-1.pooler.supabase.com/postgres', authentication_enabled=False, model_registry_enabled=True, experiment_auto_logging=True, artifact_compression=True, max_artifact_size=104857600, server_host='0.0.0.0', server_port=5000, server_workers=4, server_timeout=120, auth_config={}, storage_config=None)\n",
            "üîç MLflow client: <mlflow.tracking.client.MlflowClient object at 0x74d5f892ba10>\n",
            "üîç MLflow tracking URI: http://localhost:9003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:src.infrastructure.mlflow.experiment_tracker:Failed to create experiment 'unet_anomaly_detection': API request to http://localhost:9003/api/2.0/mlflow/experiments/create failed with exception HTTPConnectionPool(host='localhost', port=9003): Max retries exceeded with url: /api/2.0/mlflow/experiments/create (Caused by ReadTimeoutError(\"HTTPConnectionPool(host='localhost', port=9003): Read timed out. (read timeout=120)\"))\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTimeoutError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:1428\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1427\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1428\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1429\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    706\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
            "\u001b[31mTimeoutError\u001b[39m: timed out",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mReadTimeoutError\u001b[39m                          Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:536\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:367\u001b[39m, in \u001b[36mHTTPConnectionPool._raise_timeout\u001b[39m\u001b[34m(self, err, url, timeout_value)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[32m    368\u001b[39m         \u001b[38;5;28mself\u001b[39m, url, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    369\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3.\u001b[39;00m\n",
            "\u001b[31mReadTimeoutError\u001b[39m: HTTPConnectionPool(host='localhost', port=9003): Read timed out. (read timeout=120)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mMaxRetryError\u001b[39m                             Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/requests/adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:871\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    868\u001b[39m     log.warning(\n\u001b[32m    869\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) after connection broken by \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, retries, err, url\n\u001b[32m    870\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:871\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    868\u001b[39m     log.warning(\n\u001b[32m    869\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) after connection broken by \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, retries, err, url\n\u001b[32m    870\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
            "    \u001b[31m[... skipping similar frames: HTTPConnectionPool.urlopen at line 871 (4 times)]\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:871\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    868\u001b[39m     log.warning(\n\u001b[32m    869\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) after connection broken by \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, retries, err, url\n\u001b[32m    870\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/urllib3/util/retry.py:519\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    518\u001b[39m     reason = error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    521\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mIncremented Retry for (url=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, url, new_retry)\n",
            "\u001b[31mMaxRetryError\u001b[39m: HTTPConnectionPool(host='localhost', port=9003): Max retries exceeded with url: /api/2.0/mlflow/experiments/create (Caused by ReadTimeoutError(\"HTTPConnectionPool(host='localhost', port=9003): Read timed out. (read timeout=120)\"))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/mlflow/utils/rest_utils.py:230\u001b[39m, in \u001b[36mhttp_request\u001b[39m\u001b[34m(host_creds, endpoint, method, max_retries, backoff_factor, backoff_jitter, extra_headers, retry_codes, timeout, raise_on_status, respect_retry_after_header, retry_timeout_seconds, **kwargs)\u001b[39m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_http_response_with_retries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackoff_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackoff_jitter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_codes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mraise_on_status\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhost_creds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrespect_retry_after_header\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrespect_retry_after_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.exceptions.Timeout \u001b[38;5;28;01mas\u001b[39;00m to:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/mlflow/utils/request_utils.py:237\u001b[39m, in \u001b[36m_get_http_response_with_retries\u001b[39m\u001b[34m(method, url, max_retries, backoff_factor, backoff_jitter, retry_codes, raise_on_status, allow_redirects, respect_retry_after_header, **kwargs)\u001b[39m\n\u001b[32m    235\u001b[39m allow_redirects = env_value \u001b[38;5;28;01mif\u001b[39;00m allow_redirects \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m allow_redirects\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/requests/adapters.py:677\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    675\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request=request)\n\u001b[32m    679\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[31mConnectionError\u001b[39m: HTTPConnectionPool(host='localhost', port=9003): Max retries exceeded with url: /api/2.0/mlflow/experiments/create (Caused by ReadTimeoutError(\"HTTPConnectionPool(host='localhost', port=9003): Read timed out. (read timeout=120)\"))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mMlflowException\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/src/infrastructure/mlflow/experiment_tracker.py:118\u001b[39m, in \u001b[36mExperimentTracker.create_experiment\u001b[39m\u001b[34m(self, name, description)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# Create new experiment\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m experiment_id = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m    \u001b[49m\u001b[43martifact_location\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43martifact_root\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdescription\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[38;5;28mself\u001b[39m.logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCreated experiment \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m with ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/mlflow/tracking/client.py:1792\u001b[39m, in \u001b[36mMlflowClient.create_experiment\u001b[39m\u001b[34m(self, name, artifact_location, tags)\u001b[39m\n\u001b[32m   1746\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create an experiment.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \n\u001b[32m   1748\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1790\u001b[39m \n\u001b[32m   1791\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1792\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tracking_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/mlflow/telemetry/track.py:23\u001b[39m, in \u001b[36mrecord_usage_event.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_telemetry_disabled() \u001b[38;5;129;01mor\u001b[39;00m _is_telemetry_disabled_for_event(event):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m success = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/mlflow/tracking/_tracking_service/client.py:288\u001b[39m, in \u001b[36mTrackingServiceClient.create_experiment\u001b[39m\u001b[34m(self, name, artifact_location, tags)\u001b[39m\n\u001b[32m    287\u001b[39m _validate_experiment_artifact_location(artifact_location)\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[43martifact_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifact_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mExperimentTag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/mlflow/store/tracking/rest_store.py:185\u001b[39m, in \u001b[36mRestStore.create_experiment\u001b[39m\u001b[34m(self, name, artifact_location, tags)\u001b[39m\n\u001b[32m    182\u001b[39m req_body = message_to_json(\n\u001b[32m    183\u001b[39m     CreateExperiment(name=name, artifact_location=artifact_location, tags=tag_protos)\n\u001b[32m    184\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m response_proto = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCreateExperiment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response_proto.experiment_id\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/mlflow/store/tracking/rest_store.py:134\u001b[39m, in \u001b[36mRestStore._call_endpoint\u001b[39m\u001b[34m(self, api, json_body, endpoint, retry_timeout_seconds)\u001b[39m\n\u001b[32m    133\u001b[39m response_proto = api.Response()\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_timeout_seconds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_timeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/mlflow/utils/rest_utils.py:552\u001b[39m, in \u001b[36mcall_endpoint\u001b[39m\u001b[34m(host_creds, endpoint, method, json_body, response_proto, extra_headers, retry_timeout_seconds)\u001b[39m\n\u001b[32m    551\u001b[39m     call_kwargs[\u001b[33m\"\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m\"\u001b[39m] = json_body\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m     response = \u001b[43mhttp_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    554\u001b[39m response = verify_rest_response(response, endpoint)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/mlflow/utils/rest_utils.py:253\u001b[39m, in \u001b[36mhttp_request\u001b[39m\u001b[34m(host_creds, endpoint, method, max_retries, backoff_factor, backoff_jitter, extra_headers, retry_codes, timeout, raise_on_status, respect_retry_after_header, retry_timeout_seconds, **kwargs)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAPI request to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m failed with exception \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mMlflowException\u001b[39m: API request to http://localhost:9003/api/2.0/mlflow/experiments/create failed with exception HTTPConnectionPool(host='localhost', port=9003): Max retries exceeded with url: /api/2.0/mlflow/experiments/create (Caused by ReadTimeoutError(\"HTTPConnectionPool(host='localhost', port=9003): Read timed out. (read timeout=120)\"))",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mMlflowException\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     experiment_id = \u001b[43mexperiment_tracker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mU-Net anomaly detection training experiments\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Created new experiment: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.experiment_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/src/infrastructure/mlflow/experiment_tracker.py:130\u001b[39m, in \u001b[36mExperimentTracker.create_experiment\u001b[39m\u001b[34m(self, name, description)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28mself\u001b[39m.logger.error(error_msg)\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(error_msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
            "\u001b[31mMlflowException\u001b[39m: Failed to create experiment 'unet_anomaly_detection': API request to http://localhost:9003/api/2.0/mlflow/experiments/create failed with exception HTTPConnectionPool(host='localhost', port=9003): Max retries exceeded with url: /api/2.0/mlflow/experiments/create (Caused by ReadTimeoutError(\"HTTPConnectionPool(host='localhost', port=9003): Read timed out. (read timeout=120)\"))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Created new experiment: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.experiment_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     30\u001b[39m     \u001b[38;5;66;03m# Get existing experiment\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     experiment = \u001b[43mmlflow_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m experiment:\n\u001b[32m     33\u001b[39m         experiment_id = experiment.experiment_id\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/mlflow/tracking/client.py:1738\u001b[39m, in \u001b[36mMlflowClient.get_experiment_by_name\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1706\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_experiment_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) -> Experiment | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1707\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Retrieve an experiment by experiment name from the backend store\u001b[39;00m\n\u001b[32m   1708\u001b[39m \n\u001b[32m   1709\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1736\u001b[39m \u001b[33;03m        Lifecycle_stage: active\u001b[39;00m\n\u001b[32m   1737\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1738\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tracking_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/mlflow/tracking/_tracking_service/client.py:270\u001b[39m, in \u001b[36mTrackingServiceClient.get_experiment_by_name\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_experiment_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[32m    263\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    264\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[33;03m        name: The experiment name.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    268\u001b[39m \u001b[33;03m        :py:class:`mlflow.entities.Experiment`\u001b[39;00m\n\u001b[32m    269\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/mlflow/store/tracking/rest_store.py:757\u001b[39m, in \u001b[36mRestStore.get_experiment_by_name\u001b[39m\u001b[34m(self, experiment_name)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    756\u001b[39m     req_body = message_to_json(GetExperimentByName(experiment_name=experiment_name))\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     response_proto = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGetExperimentByName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Experiment.from_proto(response_proto.experiment)\n\u001b[32m    759\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MlflowException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/mlflow/store/tracking/rest_store.py:134\u001b[39m, in \u001b[36mRestStore._call_endpoint\u001b[39m\u001b[34m(self, api, json_body, endpoint, retry_timeout_seconds)\u001b[39m\n\u001b[32m    132\u001b[39m     endpoint, method = _METHOD_TO_INFO[api]\n\u001b[32m    133\u001b[39m response_proto = api.Response()\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_timeout_seconds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_timeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/mlflow/utils/rest_utils.py:549\u001b[39m, in \u001b[36mcall_endpoint\u001b[39m\u001b[34m(host_creds, endpoint, method, json_body, response_proto, extra_headers, retry_timeout_seconds)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33mGET\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    548\u001b[39m     call_kwargs[\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m] = json_body\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m     response = \u001b[43mhttp_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    551\u001b[39m     call_kwargs[\u001b[33m\"\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m\"\u001b[39m] = json_body\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/mlflow/utils/rest_utils.py:230\u001b[39m, in \u001b[36mhttp_request\u001b[39m\u001b[34m(host_creds, endpoint, method, max_retries, backoff_factor, backoff_jitter, extra_headers, retry_codes, timeout, raise_on_status, respect_retry_after_header, retry_timeout_seconds, **kwargs)\u001b[39m\n\u001b[32m    227\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mauth\u001b[39m\u001b[33m\"\u001b[39m] = fetch_auth(host_creds.auth)\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_http_response_with_retries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackoff_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackoff_jitter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_codes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mraise_on_status\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhost_creds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrespect_retry_after_header\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrespect_retry_after_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.exceptions.Timeout \u001b[38;5;28;01mas\u001b[39;00m to:\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m    246\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAPI request to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m failed with timeout exception \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mto\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    247\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m To increase the timeout, set the environment variable \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMLFLOW_HTTP_REQUEST_TIMEOUT\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[33m to a larger value.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    249\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mto\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/mlflow/utils/request_utils.py:237\u001b[39m, in \u001b[36m_get_http_response_with_retries\u001b[39m\u001b[34m(method, url, max_retries, backoff_factor, backoff_jitter, retry_codes, raise_on_status, allow_redirects, respect_retry_after_header, **kwargs)\u001b[39m\n\u001b[32m    234\u001b[39m env_value = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mMLFLOW_ALLOW_HTTP_REDIRECTS\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m).lower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    235\u001b[39m allow_redirects = env_value \u001b[38;5;28;01mif\u001b[39;00m allow_redirects \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m allow_redirects\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/requests/adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:871\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    866\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[32m    867\u001b[39m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[32m    868\u001b[39m     log.warning(\n\u001b[32m    869\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) after connection broken by \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, retries, err, url\n\u001b[32m    870\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[32m    890\u001b[39m redirect_location = redirect \u001b[38;5;129;01mand\u001b[39;00m response.get_redirect_location()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:871\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    866\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[32m    867\u001b[39m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[32m    868\u001b[39m     log.warning(\n\u001b[32m    869\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) after connection broken by \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, retries, err, url\n\u001b[32m    870\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[32m    890\u001b[39m redirect_location = redirect \u001b[38;5;129;01mand\u001b[39;00m response.get_redirect_location()\n",
            "    \u001b[31m[... skipping similar frames: HTTPConnectionPool.urlopen at line 871 (2 times)]\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:871\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    866\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[32m    867\u001b[39m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[32m    868\u001b[39m     log.warning(\n\u001b[32m    869\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) after connection broken by \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, retries, err, url\n\u001b[32m    870\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[32m    890\u001b[39m redirect_location = redirect \u001b[38;5;129;01mand\u001b[39;00m response.get_redirect_location()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:1428\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1426\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1427\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1428\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1430\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    709\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Initialize MLflow configuration\n",
        "mlflow_config = MLflowConfig(\n",
        "    tracking_uri=config.mlflow_tracking_uri,\n",
        "    artifact_root=config.artifact_root,\n",
        "    database_url=config.database_url\n",
        ")\n",
        "\n",
        "print(f\"üîç MLflow configuration: {mlflow_config}\")\n",
        "\n",
        "# Initialize MLflow components\n",
        "experiment_tracker = ExperimentTracker(mlflow_config)\n",
        "model_registry = ModelRegistry(mlflow_config)\n",
        "mlflow_client = MlflowClient(tracking_uri=config.mlflow_tracking_uri)\n",
        "\n",
        "print(f\"üîç MLflow client: {mlflow_client}\")\n",
        "\n",
        "# Set MLflow tracking URI\n",
        "mlflow.set_tracking_uri(config.mlflow_tracking_uri)\n",
        "\n",
        "print(f\"üîç MLflow tracking URI: {config.mlflow_tracking_uri}\")\n",
        "\n",
        "# Create or get experiment\n",
        "try:\n",
        "    experiment_id = experiment_tracker.create_experiment(\n",
        "        name=config.experiment_name,\n",
        "        description=\"U-Net anomaly detection training experiments\"\n",
        "    )\n",
        "    print(f\"‚úÖ Created new experiment: {config.experiment_name}\")\n",
        "except Exception as e:\n",
        "    # Get existing experiment\n",
        "    experiment = mlflow_client.get_experiment_by_name(config.experiment_name)\n",
        "    if experiment:\n",
        "        experiment_id = experiment.experiment_id\n",
        "        print(f\"‚úÖ Using existing experiment: {config.experiment_name}\")\n",
        "    else:\n",
        "        raise e\n",
        "\n",
        "print(f\"üî¨ Experiment ID: {experiment_id}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import both real data utilities and fallback synthetic data\n",
        "from notebooks.training.utils.real_data_utils import (\n",
        "    RealDataConfig, \n",
        "    load_real_training_data, \n",
        "    create_real_data_loaders,\n",
        "    get_real_training_data\n",
        ")\n",
        "from notebooks.training.utils.training_utils import AstronomicalDataset, create_data_transforms, load_sample_data\n",
        "\n",
        "# Configure real data collection\n",
        "real_data_config = RealDataConfig(\n",
        "    survey_ids=[\"hst\", \"jwst\", \"skyview\"],  # Multiple survey sources\n",
        "    confidence_threshold=0.6,  # Lower threshold to get more samples\n",
        "    max_samples=config.batch_size * 50,  # Reasonable size for demo\n",
        "    date_range_days=365,  # Last year of data\n",
        "    validation_status=\"validated\",  # Prefer validated detections\n",
        "    anomaly_types=None,  # Include all anomaly types\n",
        ")\n",
        "\n",
        "print(f\"üìä Real Data Configuration:\")\n",
        "print(f\"   Survey IDs: {real_data_config.survey_ids}\")\n",
        "print(f\"   Confidence threshold: {real_data_config.confidence_threshold}\")\n",
        "print(f\"   Max samples: {real_data_config.max_samples}\")\n",
        "print(f\"   Date range: {real_data_config.date_range_days} days\")\n",
        "print()\n",
        "\n",
        "# Try to load real astronomical data\n",
        "try:\n",
        "    print(\"üîç Attempting to load real astronomical data...\")\n",
        "    \n",
        "    # Load real datasets\n",
        "    train_dataset, val_dataset, test_dataset = await load_real_training_data(\n",
        "        config=real_data_config,\n",
        "        dataset_name=f\"real_training_{config.run_name}\",\n",
        "        created_by=\"training_notebook\"\n",
        "    )\n",
        "    \n",
        "    # Create data loaders\n",
        "    train_loader, val_loader, test_loader = create_real_data_loaders(\n",
        "        train_dataset, val_dataset, test_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        num_workers=2\n",
        "    )\n",
        "    \n",
        "    # Create a test dataset\n",
        "    test_dataset = get_real_training_data(\n",
        "        config=real_data_config,\n",
        "        dataset_name=f\"real_training_{config.run_name}\",\n",
        "        created_by=\"training_notebook\"\n",
        "    )\n",
        "    \n",
        "    print(\"‚úÖ SUCCESS: Real data loaded successfully!\")\n",
        "    print(f\"   üìä Data splits: Train={len(train_dataset)}, Val={len(val_dataset)}, Test={len(test_dataset)}\")\n",
        "    \n",
        "    # Verify real data by sampling a batch\n",
        "    sample_batch = next(iter(train_loader))\n",
        "    sample_images, sample_masks = sample_batch\n",
        "    print(f\"   üî¨ Sample batch shape: {sample_images.shape}\")\n",
        "    print(f\"   üìà Value range: [{sample_images.min():.3f}, {sample_images.max():.3f}]\")\n",
        "    print(f\"   üéØ Mask coverage: {sample_masks.sum().item():.0f} positive pixels\")\n",
        "    \n",
        "    # Set flag for real data usage\n",
        "    USING_REAL_DATA = True\n",
        "    real_data_info = {\n",
        "        \"dataset_config\": real_data_config.__dict__,\n",
        "        \"train_samples\": len(train_dataset),\n",
        "        \"val_samples\": len(val_dataset),\n",
        "        \"test_samples\": len(test_dataset),\n",
        "    }\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Real data loading failed: {e}\")\n",
        "    print(\"üìã Falling back to synthetic data generation...\")\n",
        "    \n",
        "    # Fallback to synthetic data\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    \n",
        "    sample_images, sample_masks = load_sample_data(\n",
        "        num_samples=200, \n",
        "        image_size=config.input_size\n",
        "    )\n",
        "    \n",
        "    train_transform, val_transform = create_data_transforms()\n",
        "    \n",
        "    train_images, val_images, train_masks, val_masks = train_test_split(\n",
        "        sample_images, sample_masks, \n",
        "        test_size=config.validation_split + config.test_split, \n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    val_images, test_images, val_masks, test_masks = train_test_split(\n",
        "        val_images, val_masks,\n",
        "        test_size=config.test_split / (config.validation_split + config.test_split),\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    train_dataset = AstronomicalDataset(train_images, train_masks, transform=train_transform)\n",
        "    val_dataset = AstronomicalDataset(val_images, val_masks, transform=val_transform)\n",
        "    test_dataset = AstronomicalDataset(test_images, test_masks, transform=val_transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2)\n",
        "    \n",
        "    print(f\"üìä Synthetic data splits: Train={len(train_dataset)}, Val={len(val_dataset)}, Test={len(test_dataset)}\")\n",
        "    \n",
        "    USING_REAL_DATA = False\n",
        "    real_data_info = None\n",
        "\n",
        "print()\n",
        "print(\"‚úÖ Data loading complete!\")\n",
        "if USING_REAL_DATA:\n",
        "    print(\"üéâ Training will use REAL astronomical observations!\")\n",
        "    print(\"   - GPU utilization should reach ~80-100%\")\n",
        "    print(\"   - Energy tracking will show meaningful consumption\")\n",
        "    print(\"   - Training on validated astronomical detections\")\n",
        "else:\n",
        "    print(\"üîÑ Training will use synthetic data (fallback mode)\")\n",
        "    print(\"   - Consider checking database connectivity\")\n",
        "    print(\"   - Or add some real observations to the database\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. GPU Energy Tracking Setup (ASTR-101)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize GPU energy tracking\n",
        "if config.enable_energy_tracking:\n",
        "    gpu_monitor = GPUPowerMonitor(\n",
        "        sampling_interval=1.0 / config.gpu_power_sampling_hz,\n",
        "        carbon_intensity_kg_per_kwh=config.carbon_intensity_kg_per_kwh\n",
        "    )\n",
        "    \n",
        "    energy_tracker = MLflowEnergyTracker(\n",
        "        experiment_name=config.experiment_name\n",
        "    )\n",
        "    \n",
        "    energy_analyzer = EnergyAnalyzer()\n",
        "    \n",
        "    print(\"üîã GPU energy tracking initialized\")\n",
        "    \n",
        "    # Check GPU availability\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_count = torch.cuda.device_count()\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        print(f\"üéÆ GPU available: {gpu_name} (Count: {gpu_count})\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  No GPU available - energy tracking will use simulation mode\")\n",
        "else:\n",
        "    gpu_monitor = None\n",
        "    energy_tracker = None\n",
        "    energy_analyzer = None\n",
        "    print(\"‚ö° Energy tracking disabled\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Data Loading and Preprocessing Integration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import training utilities\n",
        "from notebooks.training.utils.training_utils import (\n",
        "    AstronomicalDataset, create_data_transforms, load_sample_data\n",
        ")\n",
        "print(\"‚úÖ Training utilities imported\")\n",
        "from notebooks.training.utils.performance_metrics import ComprehensiveMetricsCalculator\n",
        "print(\"‚úÖ Comprehensive metrics calculator imported\")\n",
        "from notebooks.training.utils.training_manager import TrainingManager\n",
        "print(\"‚úÖ Training manager imported\")\n",
        "\n",
        "# Load sample data\n",
        "print(\"üìä Loading sample astronomical data...\")\n",
        "sample_images, sample_masks = load_sample_data(\n",
        "    num_samples=200, \n",
        "    image_size=config.input_size\n",
        ")\n",
        "print(f\"‚úÖ Loaded {len(sample_images)} samples\")\n",
        "\n",
        "# Create data transforms\n",
        "train_transform, val_transform = create_data_transforms()\n",
        "print(\"‚úÖ Data transforms created\")\n",
        "\n",
        "# Create datasets\n",
        "train_images, val_images, train_masks, val_masks = train_test_split(\n",
        "    sample_images, sample_masks, \n",
        "    test_size=config.validation_split + config.test_split, \n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "val_images, test_images, val_masks, test_masks = train_test_split(\n",
        "    val_images, val_masks,\n",
        "    test_size=config.test_split / (config.validation_split + config.test_split),\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Create PyTorch datasets\n",
        "train_dataset = AstronomicalDataset(\n",
        "    train_images, train_masks, \n",
        "    transform=train_transform\n",
        ")\n",
        "val_dataset = AstronomicalDataset(\n",
        "    val_images, val_masks, \n",
        "    transform=val_transform\n",
        ")\n",
        "test_dataset = AstronomicalDataset(\n",
        "    test_images, test_masks, \n",
        "    transform=val_transform\n",
        ")\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size=config.batch_size, \n",
        "    shuffle=True, \n",
        "    num_workers=2\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, \n",
        "    batch_size=config.batch_size, \n",
        "    shuffle=False, \n",
        "    num_workers=2\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, \n",
        "    batch_size=config.batch_size, \n",
        "    shuffle=False, \n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "print(f\"üìä Data splits: Train={len(train_dataset)}, Val={len(val_dataset)}, Test={len(test_dataset)}\")\n",
        "print(\"‚úÖ Data loading complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Architecture and Training Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define U-Net model architecture\n",
        "from src.domains.detection.architectures.unet_torch import UNet\n",
        "\n",
        "model = UNet(\n",
        "    in_channels=config.input_channels,\n",
        "    out_channels=config.output_channels,\n",
        "    initial_filters=config.initial_filters,\n",
        "    depth=config.depth,\n",
        ")\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"  Model Architecture:\")\n",
        "print(f\"   Total parameters: {total_params:,}\")\n",
        "print(f\"   Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"   Model size: {total_params * 4 / 1024 / 1024:.2f} MB\")\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(\n",
        "    model.parameters(), \n",
        "    lr=config.learning_rate, \n",
        "    weight_decay=config.weight_decay\n",
        ")\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = ReduceLROnPlateau(\n",
        "    optimizer, \n",
        "    mode='min', \n",
        "    factor=0.5, \n",
        "    patience=5\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Model, loss function, and optimizer initialized\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Comprehensive Training with MLflow and Energy Tracking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize training manager\n",
        "training_manager = TrainingManager(\n",
        "    config=config,\n",
        "    experiment_tracker=experiment_tracker,\n",
        "    model_registry=model_registry,\n",
        "    mlflow_client=mlflow_client,\n",
        "    gpu_monitor=gpu_monitor,\n",
        "    energy_tracker=energy_tracker\n",
        ")\n",
        "\n",
        "# Add experiment_id to config for training manager\n",
        "config.experiment_id = experiment_id\n",
        "\n",
        "# Add real data information to config for tracking\n",
        "if USING_REAL_DATA and real_data_info:\n",
        "    config.tags.update({\n",
        "        \"data_type\": \"real_astronomical_data\",\n",
        "        \"real_data_enabled\": \"true\",\n",
        "        \"train_samples\": str(real_data_info[\"train_samples\"]),\n",
        "        \"dataset_source\": \"astrid_validated_detections\"\n",
        "    })\n",
        "else:\n",
        "    config.tags.update({\n",
        "        \"data_type\": \"synthetic_data\",\n",
        "        \"real_data_enabled\": \"false\",\n",
        "        \"dataset_source\": \"synthetic_generation\"\n",
        "    })\n",
        "\n",
        "print(\"üöÄ Starting comprehensive training with full tracking...\")\n",
        "print(f\"   - MLflow experiment tracking: ‚úÖ\")\n",
        "print(f\"   - GPU energy monitoring: {'‚úÖ' if config.enable_energy_tracking else '‚ùå'}\")\n",
        "print(f\"   - Performance metrics (ASTR-102): ‚úÖ\")\n",
        "print(f\"   - Model checkpointing: ‚úÖ\")\n",
        "print(f\"   - Real data integration: {'‚úÖ' if USING_REAL_DATA else '‚ùå'}\")\n",
        "\n",
        "if USING_REAL_DATA:\n",
        "    print(\"   üåü REAL DATA FEATURES ENABLED:\")\n",
        "    print(\"      ‚Ä¢ Training on validated astronomical detections\")\n",
        "    print(\"      ‚Ä¢ Meaningful GPU utilization expected\")\n",
        "    print(\"      ‚Ä¢ Real energy consumption tracking\")\n",
        "    print(\"      ‚Ä¢ Authentic astronomical image patches\")\n",
        "\n",
        "# Start training\n",
        "try:\n",
        "    run_id = await training_manager.start_training_run(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        optimizer=optimizer,\n",
        "        criterion=criterion,\n",
        "        scheduler=scheduler\n",
        "    )\n",
        "    \n",
        "    print(f\"üéâ Training completed successfully!\")\n",
        "    print(f\"üìä MLflow Run ID: {run_id}\")\n",
        "    \n",
        "    if USING_REAL_DATA:\n",
        "        print(\"üåü REAL DATA TRAINING IMPACT:\")\n",
        "        print(\"   ‚Ä¢ Check MLflow for actual GPU energy consumption\")\n",
        "        print(\"   ‚Ä¢ Training metrics reflect real astronomical data performance\")\n",
        "        print(\"   ‚Ä¢ Model learned from validated astronomical detections\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Training failed: {e}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Training Visualization and Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot comprehensive training curves\n",
        "print(\"üìä Generating training visualizations...\")\n",
        "training_manager.plot_training_summary()\n",
        "\n",
        "# Get training summary\n",
        "training_summary = training_manager.get_training_summary()\n",
        "print(f\"\\nüìà Training Summary:\")\n",
        "print(f\"   Best validation loss: {training_summary['best_val_loss']:.4f}\")\n",
        "print(f\"   Total epochs: {training_summary['total_epochs']}\")\n",
        "print(f\"   Final train loss: {training_summary['final_train_loss']:.4f}\")\n",
        "print(f\"   Final val loss: {training_summary['final_val_loss']:.4f}\")\n",
        "\n",
        "# Display final metrics\n",
        "final_metrics = training_summary['final_val_metrics']\n",
        "if final_metrics:\n",
        "    print(f\"\\nüéØ Final Validation Metrics:\")\n",
        "    print(f\"   Accuracy: {final_metrics.get('accuracy', 0.0):.4f}\")\n",
        "    print(f\"   Precision: {final_metrics.get('precision_macro', 0.0):.4f}\")\n",
        "    print(f\"   Recall: {final_metrics.get('recall_macro', 0.0):.4f}\")\n",
        "    print(f\"   F1 Score: {final_metrics.get('f1_macro', 0.0):.4f}\")\n",
        "    print(f\"   AUROC: {final_metrics.get('auroc', 0.0):.4f}\")\n",
        "    print(f\"   AUPRC: {final_metrics.get('auprc', 0.0):.4f}\")\n",
        "    print(f\"   MCC: {final_metrics.get('mcc', 0.0):.4f}\")\n",
        "    print(f\"   Balanced Accuracy: {final_metrics.get('balanced_accuracy', 0.0):.4f}\")\n",
        "    \n",
        "    # Performance metrics\n",
        "    print(f\"\\n‚ö° Performance Metrics:\")\n",
        "    print(f\"   Latency P50: {final_metrics.get('latency_ms_p50', 0.0):.2f} ms\")\n",
        "    print(f\"   Latency P95: {final_metrics.get('latency_ms_p95', 0.0):.2f} ms\")\n",
        "    print(f\"   Throughput: {final_metrics.get('throughput_items_per_s', 0.0):.2f} items/s\")\n",
        "    \n",
        "    # Energy metrics (if available)\n",
        "    if config.enable_energy_tracking:\n",
        "        print(f\"\\nüîã Energy Metrics:\")\n",
        "        print(f\"   Energy consumed: {final_metrics.get('training_energy_wh', 0.0):.3f} Wh\")\n",
        "        print(f\"   Average power: {final_metrics.get('training_avg_power_w', 0.0):.1f} W\")\n",
        "        print(f\"   Peak power: {final_metrics.get('training_peak_power_w', 0.0):.1f} W\")\n",
        "        print(f\"   Carbon footprint: {final_metrics.get('training_carbon_footprint_kg', 0.0):.6f} kg CO2\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Model Evaluation and Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model for evaluation\n",
        "import time\n",
        "best_checkpoint_path = training_manager.checkpoint_manager.checkpoint_dir / \"best_model.pt\"\n",
        "if best_checkpoint_path.exists():\n",
        "    checkpoint = training_manager.checkpoint_manager.load_checkpoint(str(best_checkpoint_path))\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(\"‚úÖ Loaded best model for evaluation\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Best model checkpoint not found, using current model\")\n",
        "\n",
        "# Evaluate on test set\n",
        "print(\"üß™ Evaluating model on test set...\")\n",
        "model.eval()\n",
        "\n",
        "all_predictions = []\n",
        "all_targets = []\n",
        "all_scores = []\n",
        "inference_times = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(training_manager.device), target.to(training_manager.device)\n",
        "        \n",
        "        start_time = time.time()\n",
        "        output = model(data)\n",
        "        inference_time = time.time() - start_time\n",
        "        inference_times.append(inference_time)\n",
        "        \n",
        "        predictions = (torch.sigmoid(output) > config.confidence_threshold).float()\n",
        "        scores = torch.sigmoid(output).cpu().detach().numpy().flatten()\n",
        "        \n",
        "        all_predictions.extend(predictions.cpu().detach().numpy().flatten())\n",
        "        all_targets.extend(target.cpu().detach().numpy().flatten())\n",
        "        all_scores.extend(scores)\n",
        "\n",
        "# Calculate comprehensive test metrics\n",
        "all_predictions = np.array(all_predictions)\n",
        "all_targets = np.array(all_targets)\n",
        "all_scores = np.array(all_scores)\n",
        "\n",
        "test_metrics = training_manager.metrics_calculator.calculate_all_metrics(\n",
        "    all_targets, all_predictions, all_scores, inference_times, config.batch_size\n",
        ")\n",
        "\n",
        "print(f\"\\nüéØ Test Set Results:\")\n",
        "print(f\"   Accuracy: {test_metrics.get('accuracy', 0.0):.4f}\")\n",
        "print(f\"   Precision: {test_metrics.get('precision_macro', 0.0):.4f}\")\n",
        "print(f\"   Recall: {test_metrics.get('recall_macro', 0.0):.4f}\")\n",
        "print(f\"   F1 Score: {test_metrics.get('f1_macro', 0.0):.4f}\")\n",
        "print(f\"   AUROC: {test_metrics.get('auroc', 0.0):.4f}\")\n",
        "print(f\"   AUPRC: {test_metrics.get('auprc', 0.0):.4f}\")\n",
        "print(f\"   MCC: {test_metrics.get('mcc', 0.0):.4f}\")\n",
        "print(f\"   Balanced Accuracy: {test_metrics.get('balanced_accuracy', 0.0):.4f}\")\n",
        "\n",
        "# Performance metrics\n",
        "print(f\"\\n‚ö° Test Performance:\")\n",
        "print(f\"   Latency P50: {test_metrics.get('latency_ms_p50', 0.0):.2f} ms\")\n",
        "print(f\"   Latency P95: {test_metrics.get('latency_ms_p95', 0.0):.2f} ms\")\n",
        "print(f\"   Throughput: {test_metrics.get('throughput_items_per_s', 0.0):.2f} items/s\")\n",
        "\n",
        "# Generate visualizations\n",
        "from notebooks.training.utils.training_utils import TrainingVisualizer\n",
        "visualizer = TrainingVisualizer()\n",
        "\n",
        "print(\"\\nüìä Generating evaluation visualizations...\")\n",
        "visualizer.plot_confusion_matrix(all_targets, all_predictions)\n",
        "visualizer.plot_roc_curve(all_targets, all_scores)\n",
        "visualizer.plot_precision_recall_curve(all_targets, all_scores)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Troubleshooting and Debugging Tools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model debugging and inspection tools\n",
        "def inspect_model_predictions(model, data_loader, num_samples=5):\n",
        "    \"\"\"Inspect model predictions for debugging.\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, (data, target) in enumerate(data_loader):\n",
        "            if i >= num_samples:\n",
        "                break\n",
        "                \n",
        "            data = data.to(training_manager.device)\n",
        "            output = model(data)\n",
        "            predictions = torch.sigmoid(output)\n",
        "            \n",
        "            # Convert to numpy for visualization\n",
        "            image = data[0].cpu().numpy().squeeze()\n",
        "            target_mask = target[0].cpu().numpy().squeeze()\n",
        "            pred_mask = (predictions[0].cpu().numpy().squeeze() > config.confidence_threshold).astype(float)\n",
        "            confidence = predictions[0].cpu().numpy().squeeze()\n",
        "            \n",
        "            # Create visualization\n",
        "            fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
        "            \n",
        "            axes[0].imshow(image, cmap='gray')\n",
        "            axes[0].set_title('Input Image')\n",
        "            axes[0].axis('off')\n",
        "            \n",
        "            axes[1].imshow(target_mask, cmap='hot')\n",
        "            axes[1].set_title('Ground Truth')\n",
        "            axes[1].axis('off')\n",
        "            \n",
        "            axes[2].imshow(pred_mask, cmap='hot')\n",
        "            axes[2].set_title('Prediction')\n",
        "            axes[2].axis('off')\n",
        "            \n",
        "            im = axes[3].imshow(confidence, cmap='viridis')\n",
        "            axes[3].set_title('Confidence Map')\n",
        "            axes[3].axis('off')\n",
        "            plt.colorbar(im, ax=axes[3])\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            \n",
        "            # Print statistics\n",
        "            print(f\"Sample {i+1}:\")\n",
        "            print(f\"  Target pixels: {np.sum(target_mask):.0f}\")\n",
        "            print(f\"  Predicted pixels: {np.sum(pred_mask):.0f}\")\n",
        "            print(f\"  Confidence range: [{np.min(confidence):.3f}, {np.max(confidence):.3f}]\")\n",
        "            print(f\"  IoU: {np.sum((target_mask > 0) & (pred_mask > 0)) / np.sum((target_mask > 0) | (pred_mask > 0)):.3f}\")\n",
        "            print()\n",
        "\n",
        "def analyze_training_issues():\n",
        "    \"\"\"Analyze potential training issues.\"\"\"\n",
        "    print(\"üîç Training Analysis:\")\n",
        "    \n",
        "    # Check for overfitting\n",
        "    train_losses = training_summary['training_history']['train_losses']\n",
        "    val_losses = training_summary['training_history']['val_losses']\n",
        "    \n",
        "    if len(train_losses) > 5 and len(val_losses) > 5:\n",
        "        train_trend = np.mean(train_losses[-5:]) - np.mean(train_losses[:5])\n",
        "        val_trend = np.mean(val_losses[-5:]) - np.mean(val_losses[:5])\n",
        "        \n",
        "        if val_trend > train_trend * 1.5:\n",
        "            print(\"‚ö†Ô∏è  Potential overfitting detected - validation loss increasing while training loss decreasing\")\n",
        "        elif val_trend < -0.1:\n",
        "            print(\"‚úÖ Good training progress - both losses decreasing\")\n",
        "        else:\n",
        "            print(\"‚ÑπÔ∏è  Training appears stable\")\n",
        "    \n",
        "    # Check learning rate\n",
        "    lr_history = training_summary['training_history']['learning_rates']\n",
        "    if len(lr_history) > 1:\n",
        "        lr_change = (lr_history[-1] - lr_history[0]) / lr_history[0]\n",
        "        if lr_change < -0.5:\n",
        "            print(\"‚ÑπÔ∏è  Learning rate significantly reduced during training\")\n",
        "        else:\n",
        "            print(\"‚ÑπÔ∏è  Learning rate relatively stable\")\n",
        "    \n",
        "    # Check convergence\n",
        "    if len(val_losses) > 10:\n",
        "        recent_val_losses = val_losses[-10:]\n",
        "        val_std = np.std(recent_val_losses)\n",
        "        if val_std < 0.01:\n",
        "            print(\"‚úÖ Model appears to have converged\")\n",
        "        else:\n",
        "            print(\"‚ÑπÔ∏è  Model may still be learning\")\n",
        "\n",
        "# Run debugging tools\n",
        "print(\"üîß Running debugging and analysis tools...\")\n",
        "inspect_model_predictions(model, test_loader, num_samples=3)\n",
        "analyze_training_issues()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Summary and Next Steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training Summary and Next Steps\n",
        "print(\"üéâ ASTR-106 Training Notebook Complete with Real Data Integration!\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\nüìä What was accomplished:\")\n",
        "print(\"‚úÖ Complete MLflow experiment tracking (ASTR-88 integration)\")\n",
        "print(\"‚úÖ GPU energy monitoring and carbon footprint tracking (ASTR-101)\")\n",
        "print(\"‚úÖ Comprehensive performance metrics (ASTR-102)\")\n",
        "print(\"‚úÖ Data preprocessing integration (ASTR-76)\")\n",
        "print(\"‚úÖ U-Net model training with PyTorch\")\n",
        "print(\"‚úÖ Model checkpointing and versioning\")\n",
        "print(\"‚úÖ Visualization and debugging tools\")\n",
        "print(\"‚úÖ Model evaluation and testing\")\n",
        "print(\"üåü REAL DATA INTEGRATION (ASTR-113) - NEW!\")\n",
        "\n",
        "print(f\"\\nüìà Training Results:\")\n",
        "print(f\"   MLflow Run ID: {run_id}\")\n",
        "print(f\"   Best validation loss: {training_summary['best_val_loss']:.4f}\")\n",
        "print(f\"   Final test accuracy: {test_metrics.get('accuracy', 0.0):.4f}\")\n",
        "print(f\"   Final test F1 score: {test_metrics.get('f1_macro', 0.0):.4f}\")\n",
        "\n",
        "# Real data specific results\n",
        "if USING_REAL_DATA and real_data_info:\n",
        "    print(f\"\\nüåü Real Data Integration Results:\")\n",
        "    print(f\"   Data source: Validated astronomical detections\")\n",
        "    print(f\"   Training samples: {real_data_info['train_samples']}\")\n",
        "    print(f\"   Validation samples: {real_data_info['val_samples']}\")\n",
        "    print(f\"   Test samples: {real_data_info['test_samples']}\")\n",
        "    print(f\"   Survey sources: {', '.join(real_data_config.survey_ids)}\")\n",
        "    print(f\"   Confidence threshold: {real_data_config.confidence_threshold}\")\n",
        "    print(\"   ‚úÖ GPU utilization should show meaningful values\")\n",
        "    print(\"   ‚úÖ Energy tracking reflects actual compute work\")\n",
        "    print(\"   ‚úÖ Model trained on real astronomical phenomena\")\n",
        "else:\n",
        "    print(f\"\\nüîÑ Synthetic Data Fallback:\")\n",
        "    print(\"   Used synthetic data generation (real data unavailable)\")\n",
        "    print(\"   Consider adding real observations to database\")\n",
        "\n",
        "if config.enable_energy_tracking:\n",
        "    print(f\"\\nüîã Energy Impact:\")\n",
        "    print(f\"   Total energy consumed: {test_metrics.get('training_energy_wh', 0.0):.3f} Wh\")\n",
        "    print(f\"   Carbon footprint: {test_metrics.get('training_carbon_footprint_kg', 0.0):.6f} kg CO2\")\n",
        "    if USING_REAL_DATA:\n",
        "        print(\"   ‚ö° Energy values reflect actual GPU compute work on real data\")\n",
        "\n",
        "print(f\"\\nüìÅ Outputs:\")\n",
        "print(f\"   Model checkpoints: {training_manager.checkpoint_manager.checkpoint_dir}\")\n",
        "print(f\"   MLflow artifacts: {config.mlflow_tracking_uri}\")\n",
        "print(f\"   Training logs: Available in MLflow UI\")\n",
        "if USING_REAL_DATA:\n",
        "    print(f\"   Real data metrics: Tagged in MLflow for identification\")\n",
        "\n",
        "print(f\"\\nüöÄ Next Steps:\")\n",
        "print(\"1. Review results in MLflow UI (check real data tags)\")\n",
        "print(\"2. Deploy best model to production\")\n",
        "print(\"3. Set up automated retraining pipeline with real data\")\n",
        "print(\"4. Monitor model performance in production\")\n",
        "if USING_REAL_DATA:\n",
        "    print(\"5. Expand real data collection from more surveys\")\n",
        "    print(\"6. Implement continuous learning with new validated detections\")\n",
        "else:\n",
        "    print(\"5. Add real observations to database for next training run\")\n",
        "    print(\"6. Investigate database connectivity issues\")\n",
        "\n",
        "print(f\"\\nüîó Useful Links:\")\n",
        "print(f\"   MLflow UI: {config.mlflow_tracking_uri}\")\n",
        "print(f\"   Model Registry: {config.mlflow_tracking_uri}/#/models\")\n",
        "print(f\"   Experiment: {config.mlflow_tracking_uri}/#/experiments/{experiment_id}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "if USING_REAL_DATA:\n",
        "    print(\"üéØ ASTR-106 + ASTR-113 Implementation Complete!\")\n",
        "    print(\"üåü Successfully integrated real astronomical data for training!\")\n",
        "else:\n",
        "    print(\"üéØ ASTR-106 Implementation Complete (with fallback data)!\")\n",
        "    print(\"üîÑ Ready for real data integration when observations are available\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
