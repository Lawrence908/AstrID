{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Real Data Ingestion for Training Pipeline\n",
        "\n",
        "This notebook ingests real astronomical data to populate the database for training.\n",
        "\n",
        "## Purpose\n",
        "- Fetch real astronomical images from SkyView\n",
        "- Create observation records in database\n",
        "- Generate mock detections for training\n",
        "- Enable real data training pipeline testing\n",
        "\n",
        "## Based on\n",
        "- ASTR-74: Survey Integration (SkyView/MAST)\n",
        "- ASTR-73: Observation Models\n",
        "- data_ingestion_exploration.ipynb examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📍 Project root: /home/chris/github/AstrID\n",
            "📁 Current working directory: /home/chris/github/AstrID/notebooks\n",
            "✅ Path setup complete\n"
          ]
        }
      ],
      "source": [
        "# Setup and imports\n",
        "import sys\n",
        "import os\n",
        "import asyncio\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timedelta\n",
        "from uuid import uuid4\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path.cwd().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "print(f\"📍 Project root: {project_root}\")\n",
        "print(f\"📁 Current working directory: {Path.cwd()}\")\n",
        "print(\"✅ Path setup complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.core.constants import TRAINING_PIPELINE_API_KEY\n",
        "\n",
        "global AUTH_HEADERS\n",
        "AUTH_HEADERS = {\n",
        "    \"X-API-Key\": TRAINING_PIPELINE_API_KEY,\n",
        "    \"Content-Type\": \"application/json\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ AstrID components imported successfully\n"
          ]
        }
      ],
      "source": [
        "# Import AstrID components\n",
        "from src.core.db.session import AsyncSessionLocal\n",
        "from src.domains.observations.models import Survey, Observation, ObservationStatus\n",
        "from src.domains.detection.models import Detection, DetectionType, DetectionStatus, Model, ModelRun, ModelType, ModelRunStatus\n",
        "from src.adapters.external.skyview import SkyViewClient\n",
        "from src.infrastructure.storage.r2_client import R2StorageClient\n",
        "from src.adapters.imaging.fits_io import FITSProcessor\n",
        "\n",
        "print(\"✅ AstrID components imported successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Database session created\n",
            "✅ External clients initialized\n"
          ]
        }
      ],
      "source": [
        "# Create database session\n",
        "db_session = AsyncSessionLocal()\n",
        "print(\"✅ Database session created\")\n",
        "\n",
        "# Initialize clients\n",
        "skyview_client = SkyViewClient(timeout=60)\n",
        "r2_client = R2StorageClient()\n",
        "fits_processor = FITSProcessor()\n",
        "\n",
        "print(\"✅ External clients initialized\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "SSLCertVerificationError",
          "evalue": "[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1000)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mSSLCertVerificationError\u001b[39m                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m survey\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Create survey\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m survey = \u001b[38;5;28;01mawait\u001b[39;00m create_survey()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mcreate_survey\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Check if survey already exists\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msqlalchemy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m select\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m db_session.execute(\n\u001b[32m      8\u001b[39m     select(Survey).where(Survey.name == \u001b[33m\"\u001b[39m\u001b[33mDSS2\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m )\n\u001b[32m     10\u001b[39m existing_survey = result.scalar_one_or_none()\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m existing_survey:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/ext/asyncio/session.py:455\u001b[39m, in \u001b[36mAsyncSession.execute\u001b[39m\u001b[34m(self, statement, params, execution_options, bind_arguments, **kw)\u001b[39m\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    453\u001b[39m     execution_options = _EXECUTE_OPTIONS\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m greenlet_spawn(\n\u001b[32m    456\u001b[39m     \u001b[38;5;28mself\u001b[39m.sync_session.execute,\n\u001b[32m    457\u001b[39m     statement,\n\u001b[32m    458\u001b[39m     params=params,\n\u001b[32m    459\u001b[39m     execution_options=execution_options,\n\u001b[32m    460\u001b[39m     bind_arguments=bind_arguments,\n\u001b[32m    461\u001b[39m     **kw,\n\u001b[32m    462\u001b[39m )\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _ensure_sync_result(result, \u001b[38;5;28mself\u001b[39m.execute)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py:190\u001b[39m, in \u001b[36mgreenlet_spawn\u001b[39m\u001b[34m(fn, _require_await, *args, **kwargs)\u001b[39m\n\u001b[32m    185\u001b[39m     value = \u001b[38;5;28;01mawait\u001b[39;00m result\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[32m    187\u001b[39m     \u001b[38;5;66;03m# this allows an exception to be raised within\u001b[39;00m\n\u001b[32m    188\u001b[39m     \u001b[38;5;66;03m# the moderated greenlet so that it can continue\u001b[39;00m\n\u001b[32m    189\u001b[39m     \u001b[38;5;66;03m# its expected flow.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     result = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    192\u001b[39m     result = context.switch(value)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py:2308\u001b[39m, in \u001b[36mSession.execute\u001b[39m\u001b[34m(self, statement, params, execution_options, bind_arguments, _parent_execute_state, _add_event)\u001b[39m\n\u001b[32m   2247\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(\n\u001b[32m   2248\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2249\u001b[39m     statement: Executable,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2255\u001b[39m     _add_event: Optional[Any] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2256\u001b[39m ) -> Result[Any]:\n\u001b[32m   2257\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Execute a SQL expression construct.\u001b[39;00m\n\u001b[32m   2258\u001b[39m \n\u001b[32m   2259\u001b[39m \u001b[33;03m    Returns a :class:`_engine.Result` object representing\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2306\u001b[39m \n\u001b[32m   2307\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2308\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2309\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2310\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbind_arguments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbind_arguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2313\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_parent_execute_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_parent_execute_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2314\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_add_event\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_add_event\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2315\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py:2180\u001b[39m, in \u001b[36mSession._execute_internal\u001b[39m\u001b[34m(self, statement, params, execution_options, bind_arguments, _parent_execute_state, _add_event, _scalar_result)\u001b[39m\n\u001b[32m   2166\u001b[39m     (\n\u001b[32m   2167\u001b[39m         statement,\n\u001b[32m   2168\u001b[39m         execution_options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2175\u001b[39m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   2176\u001b[39m     )\n\u001b[32m   2178\u001b[39m bind = \u001b[38;5;28mself\u001b[39m.get_bind(**bind_arguments)\n\u001b[32m-> \u001b[39m\u001b[32m2180\u001b[39m conn = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection_for_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _scalar_result \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m compile_state_cls:\n\u001b[32m   2183\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py:2047\u001b[39m, in \u001b[36mSession._connection_for_bind\u001b[39m\u001b[34m(self, engine, execution_options, **kw)\u001b[39m\n\u001b[32m   2045\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trans \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2046\u001b[39m     trans = \u001b[38;5;28mself\u001b[39m._autobegin_t()\n\u001b[32m-> \u001b[39m\u001b[32m2047\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrans\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_connection_for_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<string>:2\u001b[39m, in \u001b[36m_connection_for_bind\u001b[39m\u001b[34m(self, bind, execution_options)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py:139\u001b[39m, in \u001b[36m_StateChange.declare_states.<locals>._go\u001b[39m\u001b[34m(fn, self, *arg, **kw)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28mself\u001b[39m._next_state = _StateChangeStates.CHANGE_IN_PROGRESS\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     ret_value = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py:1143\u001b[39m, in \u001b[36mSessionTransaction._connection_for_bind\u001b[39m\u001b[34m(self, bind, execution_options)\u001b[39m\n\u001b[32m   1138\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m sa_exc.InvalidRequestError(\n\u001b[32m   1139\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mSession already has a Connection associated \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1140\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfor the given Connection\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms Engine\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1141\u001b[39m             )\n\u001b[32m   1142\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1143\u001b[39m         conn = \u001b[43mbind\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1144\u001b[39m         local_connect = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1146\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3268\u001b[39m, in \u001b[36mEngine.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Connection:\n\u001b[32m   3246\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a new :class:`_engine.Connection` object.\u001b[39;00m\n\u001b[32m   3247\u001b[39m \n\u001b[32m   3248\u001b[39m \u001b[33;03m    The :class:`_engine.Connection` acts as a Python context manager, so\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3265\u001b[39m \n\u001b[32m   3266\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3268\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:145\u001b[39m, in \u001b[36mConnection.__init__\u001b[39m\u001b[34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[39m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m         \u001b[38;5;28mself\u001b[39m._dbapi_connection = \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect.loaded_dbapi.Error \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    147\u001b[39m         Connection._handle_dbapi_exception_noconnection(\n\u001b[32m    148\u001b[39m             err, dialect, engine\n\u001b[32m    149\u001b[39m         )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3292\u001b[39m, in \u001b[36mEngine.raw_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3270\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraw_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> PoolProxiedConnection:\n\u001b[32m   3271\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[32m   3272\u001b[39m \n\u001b[32m   3273\u001b[39m \u001b[33;03m    The returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3290\u001b[39m \n\u001b[32m   3291\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3292\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/pool/base.py:452\u001b[39m, in \u001b[36mPool.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> PoolProxiedConnection:\n\u001b[32m    445\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[32m    446\u001b[39m \n\u001b[32m    447\u001b[39m \u001b[33;03m    The connection is instrumented such that when its\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    450\u001b[39m \n\u001b[32m    451\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/pool/base.py:1269\u001b[39m, in \u001b[36m_ConnectionFairy._checkout\u001b[39m\u001b[34m(cls, pool, threadconns, fairy)\u001b[39m\n\u001b[32m   1261\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1262\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_checkout\u001b[39m(\n\u001b[32m   1263\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1266\u001b[39m     fairy: Optional[_ConnectionFairy] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1267\u001b[39m ) -> _ConnectionFairy:\n\u001b[32m   1268\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[32m-> \u001b[39m\u001b[32m1269\u001b[39m         fairy = \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1271\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1272\u001b[39m             threadconns.current = weakref.ref(fairy)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/pool/base.py:716\u001b[39m, in \u001b[36m_ConnectionRecord.checkout\u001b[39m\u001b[34m(cls, pool)\u001b[39m\n\u001b[32m    714\u001b[39m     rec = cast(_ConnectionRecord, pool._do_get())\n\u001b[32m    715\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m716\u001b[39m     rec = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    719\u001b[39m     dbapi_connection = rec.get_connection()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/pool/impl.py:169\u001b[39m, in \u001b[36mQueuePool._do_get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_connection()\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dec_overflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py:146\u001b[39m, in \u001b[36msafe_reraise.__exit__\u001b[39m\u001b[34m(self, type_, value, traceback)\u001b[39m\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value.with_traceback(exc_tb)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    148\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/pool/impl.py:167\u001b[39m, in \u001b[36mQueuePool._do_get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inc_overflow():\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m    169\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m util.safe_reraise():\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/pool/base.py:393\u001b[39m, in \u001b[36mPool._create_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    390\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> ConnectionPoolEntry:\n\u001b[32m    391\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/pool/base.py:678\u001b[39m, in \u001b[36m_ConnectionRecord.__init__\u001b[39m\u001b[34m(self, pool, connect)\u001b[39m\n\u001b[32m    676\u001b[39m \u001b[38;5;28mself\u001b[39m.__pool = pool\n\u001b[32m    677\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[32m--> \u001b[39m\u001b[32m678\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[38;5;28mself\u001b[39m.finalize_callback = deque()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/pool/base.py:902\u001b[39m, in \u001b[36m_ConnectionRecord.__connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    900\u001b[39m     \u001b[38;5;28mself\u001b[39m.fresh = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    901\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m902\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    903\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mError on connect(): \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    905\u001b[39m     \u001b[38;5;66;03m# in SQLAlchemy 1.4 the first_connect event is not used by\u001b[39;00m\n\u001b[32m    906\u001b[39m     \u001b[38;5;66;03m# the engine, so this will usually not be set\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py:146\u001b[39m, in \u001b[36msafe_reraise.__exit__\u001b[39m\u001b[34m(self, type_, value, traceback)\u001b[39m\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value.with_traceback(exc_tb)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    148\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/pool/base.py:898\u001b[39m, in \u001b[36m_ConnectionRecord.__connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    896\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    897\u001b[39m     \u001b[38;5;28mself\u001b[39m.starttime = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m898\u001b[39m     \u001b[38;5;28mself\u001b[39m.dbapi_connection = connection = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    899\u001b[39m     pool.logger.debug(\u001b[33m\"\u001b[39m\u001b[33mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, connection)\n\u001b[32m    900\u001b[39m     \u001b[38;5;28mself\u001b[39m.fresh = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/engine/create.py:637\u001b[39m, in \u001b[36mcreate_engine.<locals>.connect\u001b[39m\u001b[34m(connection_record)\u001b[39m\n\u001b[32m    634\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    635\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[32m--> \u001b[39m\u001b[32m637\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:616\u001b[39m, in \u001b[36mDefaultDialect.connect\u001b[39m\u001b[34m(self, *cargs, **cparams)\u001b[39m\n\u001b[32m    614\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, *cargs, **cparams):\n\u001b[32m    615\u001b[39m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloaded_dbapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:936\u001b[39m, in \u001b[36mAsyncAdapt_asyncpg_dbapi.connect\u001b[39m\u001b[34m(self, *arg, **kw)\u001b[39m\n\u001b[32m    927\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m AsyncAdaptFallback_asyncpg_connection(\n\u001b[32m    928\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    929\u001b[39m         await_fallback(creator_fn(*arg, **kw)),\n\u001b[32m    930\u001b[39m         prepared_statement_cache_size=prepared_statement_cache_size,\n\u001b[32m    931\u001b[39m         prepared_statement_name_func=prepared_statement_name_func,\n\u001b[32m    932\u001b[39m     )\n\u001b[32m    933\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m AsyncAdapt_asyncpg_connection(\n\u001b[32m    935\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m936\u001b[39m         \u001b[43mawait_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreator_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    937\u001b[39m         prepared_statement_cache_size=prepared_statement_cache_size,\n\u001b[32m    938\u001b[39m         prepared_statement_name_func=prepared_statement_name_func,\n\u001b[32m    939\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py:125\u001b[39m, in \u001b[36mawait_only\u001b[39m\u001b[34m(awaitable)\u001b[39m\n\u001b[32m    116\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc.MissingGreenlet(\n\u001b[32m    117\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mgreenlet_spawn has not been called; can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt call await_only() \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    118\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhere. Was IO attempted in an unexpected place?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    119\u001b[39m     )\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# returns the control to the driver greenlet passing it\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# a coroutine to run. Once the awaitable is done, the driver greenlet\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# switches back to this greenlet with the result of awaitable that is\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# then returned to the caller (or raised as error)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcurrent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mswitch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mawaitable\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py:185\u001b[39m, in \u001b[36mgreenlet_spawn\u001b[39m\u001b[34m(fn, _require_await, *args, **kwargs)\u001b[39m\n\u001b[32m    181\u001b[39m switch_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    183\u001b[39m     \u001b[38;5;66;03m# wait for a coroutine from await_only and then return its\u001b[39;00m\n\u001b[32m    184\u001b[39m     \u001b[38;5;66;03m# result back to it.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     value = \u001b[38;5;28;01mawait\u001b[39;00m result\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[32m    187\u001b[39m     \u001b[38;5;66;03m# this allows an exception to be raised within\u001b[39;00m\n\u001b[32m    188\u001b[39m     \u001b[38;5;66;03m# the moderated greenlet so that it can continue\u001b[39;00m\n\u001b[32m    189\u001b[39m     \u001b[38;5;66;03m# its expected flow.\u001b[39;00m\n\u001b[32m    190\u001b[39m     result = context.throw(*sys.exc_info())\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/asyncpg/connection.py:2421\u001b[39m, in \u001b[36mconnect\u001b[39m\u001b[34m(dsn, host, port, user, password, passfile, database, loop, timeout, statement_cache_size, max_cached_statement_lifetime, max_cacheable_statement_size, command_timeout, ssl, direct_tls, connection_class, record_class, server_settings, target_session_attrs, krbsrvname, gsslib)\u001b[39m\n\u001b[32m   2418\u001b[39m     loop = asyncio.get_event_loop()\n\u001b[32m   2420\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m compat.timeout(timeout):\n\u001b[32m-> \u001b[39m\u001b[32m2421\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m connect_utils._connect(\n\u001b[32m   2422\u001b[39m         loop=loop,\n\u001b[32m   2423\u001b[39m         connection_class=connection_class,\n\u001b[32m   2424\u001b[39m         record_class=record_class,\n\u001b[32m   2425\u001b[39m         dsn=dsn,\n\u001b[32m   2426\u001b[39m         host=host,\n\u001b[32m   2427\u001b[39m         port=port,\n\u001b[32m   2428\u001b[39m         user=user,\n\u001b[32m   2429\u001b[39m         password=password,\n\u001b[32m   2430\u001b[39m         passfile=passfile,\n\u001b[32m   2431\u001b[39m         ssl=ssl,\n\u001b[32m   2432\u001b[39m         direct_tls=direct_tls,\n\u001b[32m   2433\u001b[39m         database=database,\n\u001b[32m   2434\u001b[39m         server_settings=server_settings,\n\u001b[32m   2435\u001b[39m         command_timeout=command_timeout,\n\u001b[32m   2436\u001b[39m         statement_cache_size=statement_cache_size,\n\u001b[32m   2437\u001b[39m         max_cached_statement_lifetime=max_cached_statement_lifetime,\n\u001b[32m   2438\u001b[39m         max_cacheable_statement_size=max_cacheable_statement_size,\n\u001b[32m   2439\u001b[39m         target_session_attrs=target_session_attrs,\n\u001b[32m   2440\u001b[39m         krbsrvname=krbsrvname,\n\u001b[32m   2441\u001b[39m         gsslib=gsslib,\n\u001b[32m   2442\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/asyncpg/connect_utils.py:1075\u001b[39m, in \u001b[36m_connect\u001b[39m\u001b[34m(loop, connection_class, record_class, **kwargs)\u001b[39m\n\u001b[32m   1072\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chosen_connection:\n\u001b[32m   1073\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m chosen_connection\n\u001b[32m-> \u001b[39m\u001b[32m1075\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m last_error \u001b[38;5;129;01mor\u001b[39;00m exceptions.TargetServerAttributeNotMatched(\n\u001b[32m   1076\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mNone of the hosts match the target attribute requirement \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1077\u001b[39m     \u001b[33m'\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[33m'\u001b[39m.format(target_attr)\n\u001b[32m   1078\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/asyncpg/connect_utils.py:1049\u001b[39m, in \u001b[36m_connect\u001b[39m\u001b[34m(loop, connection_class, record_class, **kwargs)\u001b[39m\n\u001b[32m   1047\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m addr \u001b[38;5;129;01min\u001b[39;00m addrs:\n\u001b[32m   1048\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m         conn = \u001b[38;5;28;01mawait\u001b[39;00m _connect_addr(\n\u001b[32m   1050\u001b[39m             addr=addr,\n\u001b[32m   1051\u001b[39m             loop=loop,\n\u001b[32m   1052\u001b[39m             params=params,\n\u001b[32m   1053\u001b[39m             config=config,\n\u001b[32m   1054\u001b[39m             connection_class=connection_class,\n\u001b[32m   1055\u001b[39m             record_class=record_class,\n\u001b[32m   1056\u001b[39m         )\n\u001b[32m   1057\u001b[39m         candidates.append(conn)\n\u001b[32m   1058\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _can_use_connection(conn, target_attr):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/asyncpg/connect_utils.py:882\u001b[39m, in \u001b[36m_connect_addr\u001b[39m\u001b[34m(addr, loop, params, config, connection_class, record_class)\u001b[39m\n\u001b[32m    879\u001b[39m     params_retry = params._replace(ssl=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    880\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m     \u001b[38;5;66;03m# skip retry if we don't have to\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m __connect_addr(params, \u001b[38;5;28;01mFalse\u001b[39;00m, *args)\n\u001b[32m    884\u001b[39m \u001b[38;5;66;03m# first attempt\u001b[39;00m\n\u001b[32m    885\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/asyncpg/connect_utils.py:931\u001b[39m, in \u001b[36m__connect_addr\u001b[39m\u001b[34m(params, retry, addr, loop, config, connection_class, record_class, params_input)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    929\u001b[39m     connector = loop.create_connection(proto_factory, *addr)\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m tr, pr = \u001b[38;5;28;01mawait\u001b[39;00m connector\n\u001b[32m    933\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m connected\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/AstrID/.venv/lib/python3.12/site-packages/asyncpg/connect_utils.py:818\u001b[39m, in \u001b[36m_create_ssl_connection\u001b[39m\u001b[34m(protocol_factory, host, port, loop, ssl_context, ssl_is_advisory)\u001b[39m\n\u001b[32m    816\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m do_ssl_upgrade:\n\u001b[32m    817\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m818\u001b[39m         new_tr = \u001b[38;5;28;01mawait\u001b[39;00m loop.start_tls(\n\u001b[32m    819\u001b[39m             tr, pr, ssl_context, server_hostname=host)\n\u001b[32m    820\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, asyncio.CancelledError):\n\u001b[32m    821\u001b[39m         tr.close()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/asyncio/base_events.py:1304\u001b[39m, in \u001b[36mBaseEventLoop.start_tls\u001b[39m\u001b[34m(self, transport, protocol, sslcontext, server_side, server_hostname, ssl_handshake_timeout, ssl_shutdown_timeout)\u001b[39m\n\u001b[32m   1301\u001b[39m resume_cb = \u001b[38;5;28mself\u001b[39m.call_soon(transport.resume_reading)\n\u001b[32m   1303\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m waiter\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     transport.close()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/asyncio/sslproto.py:578\u001b[39m, in \u001b[36mSSLProtocol._on_handshake_complete\u001b[39m\u001b[34m(self, handshake_exc)\u001b[39m\n\u001b[32m    576\u001b[39m         \u001b[38;5;28mself\u001b[39m._set_state(SSLProtocolState.WRAPPED)\n\u001b[32m    577\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m578\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m handshake_exc\n\u001b[32m    580\u001b[39m     peercert = sslobj.getpeercert()\n\u001b[32m    581\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/asyncio/sslproto.py:560\u001b[39m, in \u001b[36mSSLProtocol._do_handshake\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    558\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_do_handshake\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    559\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    561\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m SSLAgainErrors:\n\u001b[32m    562\u001b[39m         \u001b[38;5;28mself\u001b[39m._process_outgoing()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ssl.py:917\u001b[39m, in \u001b[36mSSLObject.do_handshake\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    915\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_handshake\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    916\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Start the SSL/TLS handshake.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m917\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mSSLCertVerificationError\u001b[39m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1000)"
          ]
        }
      ],
      "source": [
        "# Step 1: Create a survey record\n",
        "async def create_survey():\n",
        "    \"\"\"Create a survey record in the database.\"\"\"\n",
        "    \n",
        "    # Check if survey already exists\n",
        "    from sqlalchemy import select\n",
        "    result = await db_session.execute(\n",
        "        select(Survey).where(Survey.name == \"DSS2\")\n",
        "    )\n",
        "    existing_survey = result.scalar_one_or_none()\n",
        "    \n",
        "    if existing_survey:\n",
        "        print(f\"✅ Survey 'DSS2' already exists: {existing_survey.id}\")\n",
        "        return existing_survey\n",
        "    \n",
        "    # Create new survey\n",
        "    survey = Survey(\n",
        "        name=\"DSS2\",\n",
        "        description=\"Digitized Sky Survey 2 - Wide field astronomical images\",\n",
        "        base_url=\"https://skyview.gsfc.nasa.gov\",\n",
        "        api_endpoint=\"https://skyview.gsfc.nasa.gov/current/cgi\",\n",
        "        is_active=True\n",
        "    )\n",
        "    \n",
        "    db_session.add(survey)\n",
        "    await db_session.commit()\n",
        "    \n",
        "    print(f\"✅ Created survey 'DSS2': {survey.id}\")\n",
        "    return survey\n",
        "\n",
        "# Create survey\n",
        "survey = await create_survey()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Ingest real observations from SkyView\n",
        "async def ingest_real_observations(survey, num_observations=10):\n",
        "    \"\"\"Ingest real astronomical observations from SkyView.\"\"\"\n",
        "    \n",
        "    observations = []\n",
        "    \n",
        "    # Famous astronomical coordinates for interesting objects\n",
        "    target_coordinates = [\n",
        "        (83.633, 22.0145, \"M1_Crab_Nebula\"),        # Crab Nebula\n",
        "        (84.053, -5.391, \"M42_Orion_Nebula\"),      # Orion Nebula  \n",
        "        (186.265, 12.717, \"M104_Sombrero_Galaxy\"),  # Sombrero Galaxy\n",
        "        (194.046, 54.349, \"M51_Whirlpool_Galaxy\"),  # Whirlpool Galaxy\n",
        "        (187.706, 12.391, \"M87_Giant_Galaxy\"),      # M87 Galaxy\n",
        "        (279.234, 38.784, \"Ring_Nebula\"),           # Ring Nebula region\n",
        "        (310.358, 40.257, \"Vega_region\"),           # Vega region\n",
        "        (201.365, -11.161, \"Spica_region\"),         # Spica region\n",
        "        (68.980, 16.509, \"Aldebaran_region\"),       # Aldebaran region\n",
        "        (150.789, 12.176, \"Regulus_region\"),        # Regulus region\n",
        "    ]\n",
        "    \n",
        "    for i, (ra, dec, name) in enumerate(target_coordinates[:num_observations]):\n",
        "        try:\n",
        "            print(f\"\\\\n🔍 Ingesting observation {i+1}/{num_observations}: {name}\")\n",
        "            print(f\"   Coordinates: RA={ra:.3f}°, Dec={dec:.3f}°\")\n",
        "            \n",
        "            # Fetch image from SkyView\n",
        "            print(f\"   📡 Fetching from SkyView...\")\n",
        "            img, info = skyview_client.fetch_reference_image(\n",
        "                ra_deg=ra,\n",
        "                dec_deg=dec,\n",
        "                size_pixels=512,\n",
        "                fov_deg=0.1,  # 0.1 degree field of view\n",
        "                survey=\"DSS2 Red\",\n",
        "            )\n",
        "            \n",
        "            if img is None:\n",
        "                print(f\"   ❌ Failed to fetch image: {info.get('error', 'Unknown error')}\")\n",
        "                continue\n",
        "            \n",
        "            print(f\"   ✅ Image fetched: {img.shape} pixels\")\n",
        "            \n",
        "            # Save FITS file to temporary location (would be R2 in production)\n",
        "            fits_filename = f\"temp_{name}_{i}.fits\"\n",
        "            fits_path = f\"/tmp/{fits_filename}\"\n",
        "            \n",
        "            # Create observation record\n",
        "            observation = Observation(\n",
        "                survey_id=survey.id,\n",
        "                observation_id=f\"skyview_dss2_{i}_{int(ra)}_{int(dec)}\",\n",
        "                ra=ra,\n",
        "                dec=dec,\n",
        "                observation_time=datetime.now() - timedelta(days=np.random.randint(1, 365)),\n",
        "                filter_band=\"R\",  # DSS2 Red\n",
        "                exposure_time=300.0,  # Typical exposure\n",
        "                fits_url=f\"https://skyview.gsfc.nasa.gov/tempspace/fits/{fits_filename}\",\n",
        "                fits_file_path=fits_path,\n",
        "                pixel_scale=1.7,  # arcsec/pixel for DSS\n",
        "                image_width=img.shape[1] if len(img.shape) > 1 else img.shape[0],\n",
        "                image_height=img.shape[0],\n",
        "                status=ObservationStatus.PREPROCESSED,  # Mark as ready for detection\n",
        "            )\n",
        "            \n",
        "            db_session.add(observation)\n",
        "            await db_session.flush()  # Get the ID\n",
        "            \n",
        "            observations.append((observation, img))\n",
        "            print(f\"   ✅ Created observation record: {observation.id}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"   ❌ Error ingesting {name}: {e}\")\n",
        "            continue\n",
        "    \n",
        "    await db_session.commit()\n",
        "    print(f\"\\\\n🎉 Successfully ingested {len(observations)} observations!\")\n",
        "    return observations\n",
        "\n",
        "# Ingest observations\n",
        "observations_data = await ingest_real_observations(survey, num_observations=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Create a mock ML model record\n",
        "async def create_mock_model():\n",
        "    \"\"\"Create a mock ML model for generating detections.\"\"\"\n",
        "    \n",
        "    from sqlalchemy import select\n",
        "    result = await db_session.execute(\n",
        "        select(Model).where(Model.name == \"mock_unet_v1\")\n",
        "    )\n",
        "    existing_model = result.scalar_one_or_none()\n",
        "    \n",
        "    if existing_model:\n",
        "        print(f\"✅ Model 'mock_unet_v1' already exists: {existing_model.id}\")\n",
        "        return existing_model\n",
        "    \n",
        "    model = Model(\n",
        "        name=\"mock_unet_v1\",\n",
        "        version=\"1.0.0\",\n",
        "        model_type=ModelType.UNET,\n",
        "        architecture={\n",
        "            \"input_channels\": 1,\n",
        "            \"output_channels\": 1,\n",
        "            \"depth\": 4,\n",
        "            \"initial_filters\": 64\n",
        "        },\n",
        "        hyperparameters={\n",
        "            \"learning_rate\": 0.001,\n",
        "            \"batch_size\": 2\n",
        "        },\n",
        "        training_dataset=\"real_skyview_data\",\n",
        "        precision=0.85,\n",
        "        recall=0.78,\n",
        "        f1_score=0.81,\n",
        "        accuracy=0.89,\n",
        "        is_active=True\n",
        "    )\n",
        "    \n",
        "    db_session.add(model)\n",
        "    await db_session.commit()\n",
        "    \n",
        "    print(f\"✅ Created mock model: {model.id}\")\n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = await create_mock_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Generate mock detections with realistic coordinates\n",
        "async def create_mock_detections(observations_data, model):\n",
        "    \"\"\"Create mock detections for the ingested observations.\"\"\"\n",
        "    \n",
        "    detections = []\n",
        "    \n",
        "    for observation, img in observations_data:\n",
        "        # Create a model run record\n",
        "        model_run = ModelRun(\n",
        "            model_id=model.id,\n",
        "            observation_id=observation.id,\n",
        "            input_image_path=observation.fits_file_path,\n",
        "            inference_time_ms=np.random.randint(50, 200),\n",
        "            memory_usage_mb=np.random.randint(1000, 2000),\n",
        "            total_predictions=np.random.randint(1, 5),\n",
        "            high_confidence_predictions=np.random.randint(0, 3),\n",
        "            status=ModelRunStatus.COMPLETED,\n",
        "            started_at=datetime.now() - timedelta(minutes=np.random.randint(1, 60)),\n",
        "            completed_at=datetime.now() - timedelta(minutes=np.random.randint(0, 30))\n",
        "        )\n",
        "        \n",
        "        db_session.add(model_run)\n",
        "        await db_session.flush()  # Get the ID\n",
        "        \n",
        "        # Generate 1-3 detections per observation\n",
        "        num_detections = np.random.randint(1, 4)\n",
        "        \n",
        "        for j in range(num_detections):\n",
        "            # Generate realistic pixel coordinates within image bounds\n",
        "            img_height, img_width = img.shape[:2] if len(img.shape) > 1 else (img.shape[0], img.shape[0])\n",
        "            \n",
        "            pixel_x = np.random.randint(50, img_width - 50)   # Avoid edges\n",
        "            pixel_y = np.random.randint(50, img_height - 50)  # Avoid edges\n",
        "            \n",
        "            # Convert pixel to sky coordinates (simplified)\n",
        "            pixel_scale = observation.pixel_scale or 1.7  # arcsec/pixel\n",
        "            ra_offset = (pixel_x - img_width/2) * pixel_scale / 3600.0  # degrees\n",
        "            dec_offset = (pixel_y - img_height/2) * pixel_scale / 3600.0  # degrees\n",
        "            \n",
        "            det_ra = observation.ra + ra_offset\n",
        "            det_dec = observation.dec + dec_offset\n",
        "            \n",
        "            # Create detection with varying confidence and types\n",
        "            detection_types = [DetectionType.TRANSIENT, DetectionType.VARIABLE, DetectionType.SUPERNOVA, DetectionType.UNKNOWN]\n",
        "            anomaly_types = [\"supernova\", \"variable_star\", \"transient\", \"asteroid\", \"unknown\"]\n",
        "            \n",
        "            detection = Detection(\n",
        "                model_run_id=model_run.id,\n",
        "                observation_id=observation.id,\n",
        "                ra=det_ra,\n",
        "                dec=det_dec,\n",
        "                pixel_x=pixel_x,\n",
        "                pixel_y=pixel_y,\n",
        "                confidence_score=np.random.uniform(0.65, 0.95),  # High confidence\n",
        "                detection_type=np.random.choice(detection_types),\n",
        "                model_version=\"1.0.0\",\n",
        "                inference_time_ms=np.random.randint(10, 50),\n",
        "                status=DetectionStatus.VALIDATED,  # Mark as validated for training\n",
        "                is_validated=True,\n",
        "                validation_confidence=np.random.uniform(0.7, 0.9),\n",
        "                human_label=np.random.choice(anomaly_types),\n",
        "                prediction_metadata={\n",
        "                    \"detection_method\": \"unet_segmentation\",\n",
        "                    \"patch_size\": [64, 64],\n",
        "                    \"preprocessing_applied\": True\n",
        "                }\n",
        "            )\n",
        "            \n",
        "            db_session.add(detection)\n",
        "            detections.append(detection)\n",
        "        \n",
        "        print(f\"   ✅ Created {num_detections} detections for {observation.observation_id}\")\n",
        "    \n",
        "    await db_session.commit()\n",
        "    print(f\"\\\\n🎉 Created {len(detections)} total detections!\")\n",
        "    return detections\n",
        "\n",
        "# Create detections\n",
        "detections = await create_mock_detections(observations_data, model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 5: Verify data ingestion\n",
        "async def verify_ingestion():\n",
        "    \"\"\"Verify that real data was ingested successfully.\"\"\"\n",
        "    \n",
        "    from sqlalchemy import select, func\n",
        "    \n",
        "    # Count observations\n",
        "    obs_count = await db_session.execute(select(func.count(Observation.id)))\n",
        "    obs_total = obs_count.scalar()\n",
        "    \n",
        "    # Count detections\n",
        "    det_count = await db_session.execute(select(func.count(Detection.id)))\n",
        "    det_total = det_count.scalar()\n",
        "    \n",
        "    # Count validated detections\n",
        "    val_det_count = await db_session.execute(\n",
        "        select(func.count(Detection.id)).where(Detection.is_validated == True)\n",
        "    )\n",
        "    val_det_total = val_det_count.scalar()\n",
        "    \n",
        "    # Count surveys\n",
        "    survey_count = await db_session.execute(select(func.count(Survey.id)))\n",
        "    survey_total = survey_count.scalar()\n",
        "    \n",
        "    print(\"📊 Database Content After Ingestion:\")\n",
        "    print(f\"   🔭 Surveys: {survey_total}\")\n",
        "    print(f\"   📊 Observations: {obs_total}\")\n",
        "    print(f\"   🎯 Detections: {det_total}\")\n",
        "    print(f\"   ✅ Validated detections: {val_det_total}\")\n",
        "    \n",
        "    # Sample some data\n",
        "    if val_det_total > 0:\n",
        "        sample_detections = await db_session.execute(\n",
        "            select(Detection).where(Detection.is_validated == True).limit(3)\n",
        "        )\n",
        "        \n",
        "        print(f\"\\\\n🔬 Sample Validated Detections:\")\n",
        "        for det in sample_detections.scalars():\n",
        "            print(f\"   • ID: {det.id}\")\n",
        "            print(f\"     Type: {det.detection_type.value}\")\n",
        "            print(f\"     Confidence: {det.confidence_score:.3f}\")\n",
        "            print(f\"     Human Label: {det.human_label}\")\n",
        "            print(f\"     Coordinates: ({det.ra:.3f}, {det.dec:.3f})\")\n",
        "    \n",
        "    return {\n",
        "        \"surveys\": survey_total,\n",
        "        \"observations\": obs_total,\n",
        "        \"detections\": det_total,\n",
        "        \"validated_detections\": val_det_total,\n",
        "    }\n",
        "\n",
        "# Verify ingestion\n",
        "verification_results = await verify_ingestion()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 6: Test real data collection for training\n",
        "async def test_real_data_collection():\n",
        "    \"\"\"Test the real data collection for training pipeline.\"\"\"\n",
        "    \n",
        "    print(\"🧪 Testing Real Data Collection for Training...\")\n",
        "    \n",
        "    try:\n",
        "        from src.domains.ml.training_data.services import (\n",
        "            TrainingDataCollector,\n",
        "            TrainingDataCollectionParams\n",
        "        )\n",
        "        from datetime import datetime, timedelta\n",
        "        \n",
        "        # Set up collection parameters\n",
        "        end_date = datetime.now()\n",
        "        start_date = end_date - timedelta(days=365)\n",
        "        \n",
        "        collection_params = TrainingDataCollectionParams(\n",
        "            survey_ids=[\"DSS2\"],\n",
        "            date_range=(start_date, end_date),\n",
        "            confidence_threshold=0.6,\n",
        "            max_samples=100,\n",
        "            validation_status=\"validated\",\n",
        "        )\n",
        "        \n",
        "        # Test data collection\n",
        "        collector = TrainingDataCollector(db_session, r2_client)\n",
        "        samples = await collector.collect_training_data(collection_params)\n",
        "        \n",
        "        print(f\"\\\\n✅ Real Data Collection Test Results:\")\n",
        "        print(f\"   📊 Samples collected: {len(samples)}\")\n",
        "        \n",
        "        if samples:\n",
        "            # Show sample details\n",
        "            for i, sample in enumerate(samples[:3]):\n",
        "                print(f\"   Sample {i+1}:\")\n",
        "                print(f\"     Labels: {sample.labels}\")\n",
        "                print(f\"     Metadata: {sample.sample_metadata}\")\n",
        "            \n",
        "            # Test quality validation\n",
        "            quality_report = collector.validate_data_quality(samples)\n",
        "            print(f\"\\\\n📈 Quality Report:\")\n",
        "            print(f\"   Total samples: {quality_report.total_samples}\")\n",
        "            print(f\"   Anomaly ratio: {quality_report.anomaly_ratio:.3f}\")\n",
        "            print(f\"   Quality score: {quality_report.quality_score:.3f}\")\n",
        "            print(f\"   Issues: {quality_report.issues}\")\n",
        "            \n",
        "            return True\n",
        "        else:\n",
        "            print(\"   ❌ No samples collected\")\n",
        "            return False\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"   ❌ Error testing data collection: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False\n",
        "\n",
        "# Test collection\n",
        "collection_success = await test_real_data_collection()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 7: Summary and next steps\n",
        "print(\"\\\\n\" + \"=\" * 60)\n",
        "print(\"🎉 REAL DATA INGESTION COMPLETE!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\\\n📊 Ingestion Summary:\")\n",
        "print(f\"   Surveys created: {verification_results['surveys']}\")\n",
        "print(f\"   Observations ingested: {verification_results['observations']}\")\n",
        "print(f\"   Detections created: {verification_results['detections']}\")\n",
        "print(f\"   Validated detections: {verification_results['validated_detections']}\")\n",
        "\n",
        "if collection_success:\n",
        "    print(f\"\\\\n✅ READY FOR REAL DATA TRAINING!\")\n",
        "    print(f\"   The training pipeline can now access real astronomical data\")\n",
        "    print(f\"   GPU utilization should show meaningful values during training\")\n",
        "    print(f\"   Energy tracking will reflect actual compute work\")\n",
        "else:\n",
        "    print(f\"\\\\n⚠️  Real data collection test failed\")\n",
        "    print(f\"   Check the data collection parameters and database connectivity\")\n",
        "\n",
        "print(f\"\\\\n🚀 Next Steps:\")\n",
        "print(f\"   1. Run the training notebook again\")\n",
        "print(f\"   2. Verify real data loading works\")\n",
        "print(f\"   3. Check GPU utilization during training\")\n",
        "print(f\"   4. Monitor energy consumption values\")\n",
        "\n",
        "print(f\"\\\\n🔗 Database Status:\")\n",
        "print(f\"   Ready for real data training: {'✅' if collection_success else '❌'}\")\n",
        "print(f\"   Synthetic fallback available: ✅\")\n",
        "\n",
        "# Clean up session\n",
        "await db_session.close()\n",
        "print(f\"\\\\n✅ Database session closed\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
