{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ASTR-113: Real Data Loading Smoke Test\n",
        "\n",
        "This notebook validates the real-data collection and loading pipeline:\n",
        "- Collect validated detections into a `TrainingDataset`\n",
        "- Persist `TrainingSample` rows\n",
        "- Load the dataset and create train/val/test splits\n",
        "\n",
        "Run this before integrating with `notebooks/training/model_training.ipynb`. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root added: /home/chris/github/AstrID\n"
          ]
        }
      ],
      "source": [
        "# Setup imports and environment\n",
        "import os, sys\n",
        "from pathlib import Path\n",
        "\n",
        "project_root = Path.cwd().parent.parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "print(f\"Project root added: {project_root}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'http://127.0.0.1:8000'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "API_BASE = os.environ.get(\"ASTRID_API_BASE\", \"http://127.0.0.1:8000\")\n",
        "API_BASE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.core.constants import TRAINING_PIPELINE_API_KEY\n",
        "\n",
        "global AUTH_HEADERS\n",
        "AUTH_HEADERS = {\n",
        "    \"X-API-Key\": TRAINING_PIPELINE_API_KEY,\n",
        "    \"Content-Type\": \"application/json\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'status': 'success',\n",
              " 'data': {'dataset_id': 'f6e72a79-0fbc-4445-8dad-e10e3d959bd9',\n",
              "  'name': 'smoketest_hst_2024',\n",
              "  'total': 0,\n",
              "  'quality': {'anomaly_ratio': 0.0, 'quality_score': 0.0}},\n",
              " 'meta': {},\n",
              " 'error': None}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Collect a small dataset via API\n",
        "import requests\n",
        "from datetime import datetime\n",
        "\n",
        "params = {\n",
        "    \"survey_ids\": [\"hst\"],\n",
        "    \"start\": \"2024-01-01T00:00:00\",\n",
        "    \"end\": \"2024-12-31T23:59:59\",\n",
        "    \"confidence_threshold\": 0.7,\n",
        "    \"max_samples\": 50,\n",
        "    \"name\": \"smoketest_hst_2024\"\n",
        "}\n",
        "\n",
        "r = requests.post(f\"{API_BASE}/training/datasets/collect\", json=params, headers=AUTH_HEADERS, timeout=60)\n",
        "r.raise_for_status()\n",
        "resp = r.json()\n",
        "resp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datasets: 12\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'id': 'f6e72a79-0fbc-4445-8dad-e10e3d959bd9',\n",
              "  'name': 'smoketest_hst_2024',\n",
              "  'total_samples': 0,\n",
              "  'quality_score': 0.0,\n",
              "  'status': 'active',\n",
              "  'created_at': '2025-09-23T06:45:17.964315+00:00'},\n",
              " {'id': '0acda9eb-a45d-448a-a434-ae1806f2bb99',\n",
              "  'name': 'test_85a67de7-709e-49d8-a04c-4e4f07c548a2_20250922_234403',\n",
              "  'total_samples': 0,\n",
              "  'quality_score': 0.0,\n",
              "  'status': 'active',\n",
              "  'created_at': '2025-09-23T06:44:04.662205+00:00'},\n",
              " {'id': '7d26d30a-3af5-4597-b5a2-3bbb5c3f1b8d',\n",
              "  'name': 'test_dad7665f-907b-4bcd-bf77-237501714edf_20250922_220709',\n",
              "  'total_samples': 0,\n",
              "  'quality_score': 0.0,\n",
              "  'status': 'active',\n",
              "  'created_at': '2025-09-23T05:07:09.989516+00:00'}]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Verify dataset is listed\n",
        "r = requests.get(f\"{API_BASE}/training/datasets\", headers=AUTH_HEADERS)\n",
        "r.raise_for_status()\n",
        "datasets = r.json()[\"data\"]\n",
        "\n",
        "print(f\"Datasets: {len(datasets)}\")\n",
        "# Show the most recent one\n",
        "sorted(datasets, key=lambda d: d.get(\"created_at\", \"\"), reverse=True)[:3]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset ID: f6e72a79-0fbc-4445-8dad-e10e3d959bd9\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'status': 'success',\n",
              " 'data': {'id': 'f6e72a79-0fbc-4445-8dad-e10e3d959bd9',\n",
              "  'name': 'smoketest_hst_2024',\n",
              "  'total_samples': 0,\n",
              "  'quality_score': 0.0,\n",
              "  'status': 'active',\n",
              "  'samples': 0},\n",
              " 'meta': {},\n",
              " 'error': None}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inspect dataset via API (no direct DB access needed in notebook)\n",
        "# Resolve dataset_id from prior response or fallback to latest dataset via API\n",
        "if isinstance(resp, dict) and \"data\" in resp and resp[\"data\"].get(\"dataset_id\"):\n",
        "    dataset_id = resp[\"data\"][\"dataset_id\"]\n",
        "else:\n",
        "    r = requests.get(f\"{API_BASE}/training/datasets\", headers=AUTH_HEADERS)\n",
        "    r.raise_for_status()\n",
        "    datasets = r.json().get(\"data\", [])\n",
        "    if not datasets:\n",
        "        raise RuntimeError(\"No training datasets available\")\n",
        "    # pick the most recent\n",
        "    datasets_sorted = sorted(datasets, key=lambda d: d.get(\"created_at\", \"\"), reverse=True)\n",
        "    dataset_id = str(datasets_sorted[0][\"id\"])  # ensure string\n",
        "\n",
        "print(\"Dataset ID:\", dataset_id)\n",
        "\n",
        "# Get dataset details\n",
        "detail = requests.get(f\"{API_BASE}/training/datasets/{dataset_id}\", headers=AUTH_HEADERS)\n",
        "detail.raise_for_status()\n",
        "detail.json()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For now, verify counts above. Integration with training notebook will consume by dataset_id.\n"
          ]
        }
      ],
      "source": [
        "# Optional: preview a few sample image paths from DB via API\n",
        "# (Future enhancement: API could return sample listings)\n",
        "print(\"For now, verify counts above. Integration with training notebook will consume by dataset_id.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
