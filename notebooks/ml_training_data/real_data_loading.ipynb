{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ASTR-113: Real Data Loading Smoke Test\n",
        "\n",
        "This notebook validates the real-data collection and loading pipeline:\n",
        "- Collect validated detections into a `TrainingDataset`\n",
        "- Persist `TrainingSample` rows\n",
        "- Load the dataset and create train/val/test splits\n",
        "\n",
        "Run this before integrating with `notebooks/training/model_training.ipynb`. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root added: /home/chris/github/AstrID\n"
          ]
        }
      ],
      "source": [
        "# Setup imports and environment\n",
        "import os, sys\n",
        "from pathlib import Path\n",
        "\n",
        "project_root = Path.cwd().parent.parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "print(f\"Project root added: {project_root}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'http://localhost:8000'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "API_BASE = os.environ.get(\"ASTRID_API_BASE\", \"http://127.0.0.1:8000\")\n",
        "API_BASE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'status': 'success',\n",
              " 'data': {'dataset_id': 'e80b18c9-8e99-4c72-86e3-84d319ff6fc3',\n",
              "  'name': 'smoketest_hst_2024',\n",
              "  'total': 0,\n",
              "  'quality': {'anomaly_ratio': 0.0, 'quality_score': 0.0}},\n",
              " 'meta': {},\n",
              " 'error': None}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Collect a small dataset via API\n",
        "import requests\n",
        "from datetime import datetime\n",
        "\n",
        "params = {\n",
        "    \"survey_ids\": [\"hst\"],\n",
        "    \"start\": \"2024-01-01T00:00:00\",\n",
        "    \"end\": \"2024-12-31T23:59:59\",\n",
        "    \"confidence_threshold\": 0.7,\n",
        "    \"max_samples\": 50,\n",
        "    \"name\": \"smoketest_hst_2024\"\n",
        "}\n",
        "\n",
        "r = requests.post(f\"{API_BASE}/training/datasets/collect\", json=params, timeout=60)\n",
        "r.raise_for_status()\n",
        "resp = r.json()\n",
        "resp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datasets: 5\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'id': 'e80b18c9-8e99-4c72-86e3-84d319ff6fc3',\n",
              "  'name': 'smoketest_hst_2024',\n",
              "  'total_samples': 0,\n",
              "  'quality_score': 0.0,\n",
              "  'status': 'active',\n",
              "  'created_at': '2025-09-22T15:31:15.966066+00:00'},\n",
              " {'id': '2dc8bef2-7f21-4e1f-8359-b79d152e16b8',\n",
              "  'name': 'smoketest_hst_2024',\n",
              "  'total_samples': 0,\n",
              "  'quality_score': 0.0,\n",
              "  'status': 'active',\n",
              "  'created_at': '2025-09-22T09:13:32.693502+00:00'},\n",
              " {'id': 'd25fdfa7-468c-4315-bcfb-5c0e69dbbf6e',\n",
              "  'name': 'smoketest_hst_2024',\n",
              "  'total_samples': 0,\n",
              "  'quality_score': 0.0,\n",
              "  'status': 'active',\n",
              "  'created_at': '2025-09-22T08:51:38.355439+00:00'}]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Verify dataset is listed\n",
        "r = requests.get(f\"{API_BASE}/training/datasets\")\n",
        "r.raise_for_status()\n",
        "datasets = r.json()[\"data\"]\n",
        "\n",
        "print(f\"Datasets: {len(datasets)}\")\n",
        "# Show the most recent one\n",
        "sorted(datasets, key=lambda d: d.get(\"created_at\", \"\"), reverse=True)[:3]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset ID: e80b18c9-8e99-4c72-86e3-84d319ff6fc3\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'status': 'success',\n",
              " 'data': {'id': 'e80b18c9-8e99-4c72-86e3-84d319ff6fc3',\n",
              "  'name': 'smoketest_hst_2024',\n",
              "  'total_samples': 0,\n",
              "  'quality_score': 0.0,\n",
              "  'status': 'active',\n",
              "  'samples': 0},\n",
              " 'meta': {},\n",
              " 'error': None}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inspect dataset via API (no direct DB access needed in notebook)\n",
        "# Resolve dataset_id from prior response or fallback to latest dataset via API\n",
        "if isinstance(resp, dict) and \"data\" in resp and resp[\"data\"].get(\"dataset_id\"):\n",
        "    dataset_id = resp[\"data\"][\"dataset_id\"]\n",
        "else:\n",
        "    r = requests.get(f\"{API_BASE}/training/datasets\")\n",
        "    r.raise_for_status()\n",
        "    datasets = r.json().get(\"data\", [])\n",
        "    if not datasets:\n",
        "        raise RuntimeError(\"No training datasets available\")\n",
        "    # pick the most recent\n",
        "    datasets_sorted = sorted(datasets, key=lambda d: d.get(\"created_at\", \"\"), reverse=True)\n",
        "    dataset_id = str(datasets_sorted[0][\"id\"])  # ensure string\n",
        "\n",
        "print(\"Dataset ID:\", dataset_id)\n",
        "\n",
        "# Get dataset details\n",
        "detail = requests.get(f\"{API_BASE}/training/datasets/{dataset_id}\")\n",
        "detail.raise_for_status()\n",
        "detail.json()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For now, verify counts above. Integration with training notebook will consume by dataset_id.\n"
          ]
        }
      ],
      "source": [
        "# Optional: preview a few sample image paths from DB via API\n",
        "# (Future enhancement: API could return sample listings)\n",
        "print(\"For now, verify counts above. Integration with training notebook will consume by dataset_id.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
