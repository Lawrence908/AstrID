"""add_all_domain_tables

Revision ID: ba3eba0bb123
Revises: 18ac04758a21
Create Date: 2025-09-08 07:35:03.580399+00:00

"""

from collections.abc import Sequence

import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

from alembic import op

# revision identifiers, used by Alembic.
revision: str = "ba3eba0bb123"
down_revision: str | None = "18ac04758a21"
branch_labels: str | Sequence[str] | None = None
depends_on: str | Sequence[str] | None = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "models",
        sa.Column("id", sa.UUID(), nullable=False),
        sa.Column("name", sa.String(length=100), nullable=False),
        sa.Column("version", sa.String(length=50), nullable=False),
        sa.Column(
            "model_type",
            sa.Enum(
                "UNET",
                "ANOMALY_DETECTOR",
                "CLASSIFIER",
                "SEGMENTATION",
                name="model_type",
            ),
            nullable=False,
        ),
        sa.Column(
            "architecture", postgresql.JSONB(astext_type=sa.Text()), nullable=True
        ),
        sa.Column(
            "hyperparameters", postgresql.JSONB(astext_type=sa.Text()), nullable=True
        ),
        sa.Column("training_dataset", sa.String(length=200), nullable=True),
        sa.Column(
            "training_metrics", postgresql.JSONB(astext_type=sa.Text()), nullable=True
        ),
        sa.Column("precision", sa.Numeric(precision=5, scale=4), nullable=True),
        sa.Column("recall", sa.Numeric(precision=5, scale=4), nullable=True),
        sa.Column("f1_score", sa.Numeric(precision=5, scale=4), nullable=True),
        sa.Column("accuracy", sa.Numeric(precision=5, scale=4), nullable=True),
        sa.Column("is_active", sa.Boolean(), nullable=False),
        sa.Column("deployment_date", sa.DateTime(timezone=True), nullable=True),
        sa.Column("model_path", sa.String(length=500), nullable=True),
        sa.Column("mlflow_run_id", sa.String(length=100), nullable=True),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("now()"),
            nullable=False,
        ),
        sa.Column(
            "updated_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("now()"),
            nullable=False,
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("models", schema=None) as batch_op:
        batch_op.create_index("idx_models_is_active", ["is_active"], unique=False)
        batch_op.create_index("idx_models_model_type", ["model_type"], unique=False)
        batch_op.create_index(
            "idx_models_name_version", ["name", "version"], unique=True
        )

    op.create_table(
        "difference_runs",
        sa.Column("id", sa.UUID(), nullable=False),
        sa.Column("observation_id", sa.UUID(), nullable=False),
        sa.Column("reference_observation_id", sa.UUID(), nullable=True),
        sa.Column(
            "status",
            sa.Enum(
                "PENDING",
                "RUNNING",
                "COMPLETED",
                "FAILED",
                name="difference_run_status",
            ),
            nullable=False,
        ),
        sa.Column("algorithm", sa.String(length=50), nullable=False),
        sa.Column("parameters", postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.Column("difference_image_path", sa.String(length=500), nullable=True),
        sa.Column("significance_map_path", sa.String(length=500), nullable=True),
        sa.Column("noise_level", sa.Numeric(precision=10, scale=6), nullable=True),
        sa.Column(
            "detection_threshold", sa.Numeric(precision=10, scale=6), nullable=True
        ),
        sa.Column("candidates_found", sa.Integer(), nullable=False),
        sa.Column("started_at", sa.DateTime(timezone=True), nullable=True),
        sa.Column("completed_at", sa.DateTime(timezone=True), nullable=True),
        sa.Column("processing_time_seconds", sa.Integer(), nullable=True),
        sa.Column("error_message", sa.Text(), nullable=True),
        sa.Column("retry_count", sa.Integer(), nullable=False),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("now()"),
            nullable=False,
        ),
        sa.Column(
            "updated_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("now()"),
            nullable=False,
        ),
        sa.ForeignKeyConstraint(
            ["observation_id"],
            ["observations.id"],
        ),
        sa.ForeignKeyConstraint(
            ["reference_observation_id"],
            ["observations.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "model_runs",
        sa.Column("id", sa.UUID(), nullable=False),
        sa.Column("model_id", sa.UUID(), nullable=False),
        sa.Column("observation_id", sa.UUID(), nullable=True),
        sa.Column("input_image_path", sa.String(length=500), nullable=True),
        sa.Column("output_mask_path", sa.String(length=500), nullable=True),
        sa.Column("confidence_map_path", sa.String(length=500), nullable=True),
        sa.Column("inference_time_ms", sa.Integer(), nullable=True),
        sa.Column("memory_usage_mb", sa.Integer(), nullable=True),
        sa.Column("total_predictions", sa.Integer(), nullable=True),
        sa.Column("high_confidence_predictions", sa.Integer(), nullable=True),
        sa.Column(
            "status",
            sa.Enum(
                "PENDING", "RUNNING", "COMPLETED", "FAILED", name="model_run_status"
            ),
            nullable=False,
        ),
        sa.Column("started_at", sa.DateTime(timezone=True), nullable=True),
        sa.Column("completed_at", sa.DateTime(timezone=True), nullable=True),
        sa.Column("error_message", sa.Text(), nullable=True),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("now()"),
            nullable=False,
        ),
        sa.Column(
            "updated_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("now()"),
            nullable=False,
        ),
        sa.ForeignKeyConstraint(
            ["model_id"],
            ["models.id"],
        ),
        sa.ForeignKeyConstraint(
            ["observation_id"],
            ["observations.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "preprocess_runs",
        sa.Column("id", sa.UUID(), nullable=False),
        sa.Column("observation_id", sa.UUID(), nullable=False),
        sa.Column("status", sa.String(length=50), nullable=False),
        sa.Column("calibration_applied", sa.Boolean(), nullable=False),
        sa.Column("wcs_aligned", sa.Boolean(), nullable=False),
        sa.Column(
            "registration_quality", sa.Numeric(precision=5, scale=3), nullable=True
        ),
        sa.Column("processed_fits_path", sa.String(length=500), nullable=True),
        sa.Column("wcs_info", postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.Column("started_at", sa.DateTime(timezone=True), nullable=True),
        sa.Column("completed_at", sa.DateTime(timezone=True), nullable=True),
        sa.Column("processing_time_seconds", sa.Integer(), nullable=True),
        sa.Column("error_message", sa.Text(), nullable=True),
        sa.Column("retry_count", sa.Integer(), nullable=False),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("now()"),
            nullable=False,
        ),
        sa.Column(
            "updated_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("now()"),
            nullable=False,
        ),
        sa.ForeignKeyConstraint(
            ["observation_id"],
            ["observations.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "candidates",
        sa.Column("id", sa.UUID(), nullable=False),
        sa.Column("difference_run_id", sa.UUID(), nullable=False),
        sa.Column("observation_id", sa.UUID(), nullable=False),
        sa.Column("ra", sa.Numeric(precision=10, scale=7), nullable=False),
        sa.Column("dec", sa.Numeric(precision=10, scale=7), nullable=False),
        sa.Column("pixel_x", sa.Integer(), nullable=False),
        sa.Column("pixel_y", sa.Integer(), nullable=False),
        sa.Column("flux", sa.Numeric(precision=15, scale=6), nullable=True),
        sa.Column("flux_error", sa.Numeric(precision=15, scale=6), nullable=True),
        sa.Column("significance", sa.Numeric(precision=10, scale=3), nullable=True),
        sa.Column("snr", sa.Numeric(precision=8, scale=3), nullable=True),
        sa.Column("fwhm", sa.Numeric(precision=8, scale=3), nullable=True),
        sa.Column("ellipticity", sa.Numeric(precision=5, scale=3), nullable=True),
        sa.Column("position_angle", sa.Numeric(precision=6, scale=2), nullable=True),
        sa.Column("is_saturated", sa.Boolean(), nullable=False),
        sa.Column("is_blended", sa.Boolean(), nullable=False),
        sa.Column("is_edge", sa.Boolean(), nullable=False),
        sa.Column(
            "status",
            sa.Enum(
                "PENDING",
                "PROCESSING",
                "DETECTED",
                "REJECTED",
                "DUPLICATE",
                name="candidate_status",
            ),
            nullable=False,
        ),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("now()"),
            nullable=False,
        ),
        sa.Column(
            "updated_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("now()"),
            nullable=False,
        ),
        sa.ForeignKeyConstraint(
            ["difference_run_id"],
            ["difference_runs.id"],
        ),
        sa.ForeignKeyConstraint(
            ["observation_id"],
            ["observations.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "detections",
        sa.Column("id", sa.UUID(), nullable=False),
        sa.Column("model_run_id", sa.UUID(), nullable=False),
        sa.Column("observation_id", sa.UUID(), nullable=False),
        sa.Column("ra", sa.Numeric(precision=10, scale=7), nullable=False),
        sa.Column("dec", sa.Numeric(precision=10, scale=7), nullable=False),
        sa.Column("pixel_x", sa.Integer(), nullable=False),
        sa.Column("pixel_y", sa.Integer(), nullable=False),
        sa.Column("confidence_score", sa.Numeric(precision=5, scale=4), nullable=False),
        sa.Column(
            "detection_type",
            sa.Enum(
                "SUPERNOVA",
                "VARIABLE",
                "TRANSIENT",
                "UNKNOWN",
                "ARTIFACT",
                name="detection_type",
            ),
            nullable=False,
        ),
        sa.Column("model_version", sa.String(length=50), nullable=False),
        sa.Column("inference_time_ms", sa.Integer(), nullable=True),
        sa.Column(
            "prediction_metadata",
            postgresql.JSONB(astext_type=sa.Text()),
            nullable=True,
        ),
        sa.Column(
            "status",
            sa.Enum(
                "PENDING",
                "VALIDATING",
                "VALIDATED",
                "REJECTED",
                "CONFIRMED",
                "ARCHIVED",
                name="detection_status",
            ),
            nullable=False,
        ),
        sa.Column("is_validated", sa.Boolean(), nullable=False),
        sa.Column(
            "validation_confidence", sa.Numeric(precision=5, scale=4), nullable=True
        ),
        sa.Column("human_label", sa.String(length=50), nullable=True),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("now()"),
            nullable=False,
        ),
        sa.Column(
            "updated_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("now()"),
            nullable=False,
        ),
        sa.CheckConstraint("confidence_score >= 0 AND confidence_score <= 1"),
        sa.ForeignKeyConstraint(
            ["model_run_id"],
            ["model_runs.id"],
        ),
        sa.ForeignKeyConstraint(
            ["observation_id"],
            ["observations.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("detections", schema=None) as batch_op:
        batch_op.create_index(
            "idx_detections_confidence_score", ["confidence_score"], unique=False
        )
        batch_op.create_index(
            "idx_detections_detection_type", ["detection_type"], unique=False
        )
        batch_op.create_index(
            "idx_detections_observation_id", ["observation_id"], unique=False
        )
        batch_op.create_index("idx_detections_ra_dec", ["ra", "dec"], unique=False)
        batch_op.create_index("idx_detections_status", ["status"], unique=False)

    op.create_table(
        "alerts",
        sa.Column("id", sa.UUID(), nullable=False),
        sa.Column("detection_id", sa.UUID(), nullable=False),
        sa.Column("alert_type", sa.String(length=50), nullable=False),
        sa.Column(
            "priority",
            sa.Enum("LOW", "MEDIUM", "HIGH", "CRITICAL", name="alert_priority"),
            nullable=False,
        ),
        sa.Column("title", sa.String(length=200), nullable=False),
        sa.Column("message", sa.Text(), nullable=False),
        sa.Column(
            "alert_metadata", postgresql.JSONB(astext_type=sa.Text()), nullable=True
        ),
        sa.Column(
            "status",
            sa.Enum(
                "PENDING",
                "SENT",
                "DELIVERED",
                "FAILED",
                "CANCELLED",
                name="alert_status",
            ),
            nullable=False,
        ),
        sa.Column("sent_at", sa.DateTime(timezone=True), nullable=True),
        sa.Column("delivery_attempts", sa.Integer(), nullable=False),
        sa.Column("error_message", sa.Text(), nullable=True),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("now()"),
            nullable=False,
        ),
        sa.Column(
            "updated_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("now()"),
            nullable=False,
        ),
        sa.ForeignKeyConstraint(
            ["detection_id"],
            ["detections.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "validation_events",
        sa.Column("id", sa.UUID(), nullable=False),
        sa.Column("detection_id", sa.UUID(), nullable=False),
        sa.Column("validator_id", sa.String(length=100), nullable=False),
        sa.Column("is_valid", sa.Boolean(), nullable=False),
        sa.Column("label", sa.String(length=50), nullable=True),
        sa.Column(
            "confidence_level",
            sa.Enum("LOW", "MEDIUM", "HIGH", "EXPERT", name="confidence_level"),
            nullable=True,
        ),
        sa.Column("notes", sa.Text(), nullable=True),
        sa.Column("tags", postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.Column(
            "image_quality",
            sa.Enum("EXCELLENT", "GOOD", "FAIR", "POOR", name="image_quality"),
            nullable=True,
        ),
        sa.Column(
            "detection_quality",
            sa.Enum("EXCELLENT", "GOOD", "FAIR", "POOR", name="detection_quality"),
            nullable=True,
        ),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("now()"),
            nullable=False,
        ),
        sa.Column(
            "updated_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("now()"),
            nullable=False,
        ),
        sa.ForeignKeyConstraint(
            ["detection_id"],
            ["detections.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###

    # Drop tables in reverse dependency order
    op.drop_table("validation_events")
    op.drop_table("alerts")

    # Drop indexes first
    with op.batch_alter_table("detections", schema=None) as batch_op:
        batch_op.drop_index("idx_detections_status")
        batch_op.drop_index("idx_detections_ra_dec")
        batch_op.drop_index("idx_detections_observation_id")
        batch_op.drop_index("idx_detections_detection_type")
        batch_op.drop_index("idx_detections_confidence_score")

    op.drop_table("detections")
    op.drop_table("candidates")
    op.drop_table("preprocess_runs")
    op.drop_table("model_runs")
    op.drop_table("difference_runs")

    # Drop indexes first
    with op.batch_alter_table("models", schema=None) as batch_op:
        batch_op.drop_index("idx_models_name_version")
        batch_op.drop_index("idx_models_model_type")
        batch_op.drop_index("idx_models_is_active")

    op.drop_table("models")

    # Drop enums last (after all tables using them are dropped)
    op.execute("DROP TYPE IF EXISTS alert_status")
    op.execute("DROP TYPE IF EXISTS alert_priority")
    op.execute("DROP TYPE IF EXISTS detection_quality")
    op.execute("DROP TYPE IF EXISTS image_quality")
    op.execute("DROP TYPE IF EXISTS confidence_level")
    op.execute("DROP TYPE IF EXISTS candidate_status")
    op.execute("DROP TYPE IF EXISTS difference_run_status")
    op.execute("DROP TYPE IF EXISTS detection_type")
    op.execute("DROP TYPE IF EXISTS detection_status")
    op.execute("DROP TYPE IF EXISTS model_run_status")
    op.execute("DROP TYPE IF EXISTS model_type")
    # ### end Alembic commands ###
