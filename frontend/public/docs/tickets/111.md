## **ASTR-111: Expert Review Process for Anomaly Confirmation (P2) - Curation Domain**

### **Context & Current State**
Anomaly detection pipeline is complete (ASTR-81 ) and human validation system is planned (ASTR-82), providing the foundation for expert review workflows. This ticket implements a comprehensive expert review process that allows designated experts to validate detected anomalies, rate their scientific importance, and elevate confirmed discoveries to high-priority status.

### **Technical Requirements**

**Dependencies**: ASTR-81 (Anomaly Detection Pipeline)  Complete, ASTR-82 (Human Validation System) - Planned
**Domain**: Curation Domain (Expert Review)
**Estimated Time**: 5 days

### **Implementation Tasks**

1. **Set Up Expert Notification System and Alerts**
   - Create `src/domains/curation/services/expert_notification_service.py`:
     - Implement expert notification triggers based on anomaly confidence and quality scores
     - Add configurable notification thresholds and criteria
     - Integrate with existing email notification system from ASTR-108
     - Support for different notification channels (email, dashboard, webhook)
   - Create `src/domains/curation/models/expert_review.py`:
     - Expert user model with credentials and permissions
     - Review assignment model for tracking expert workload
     - Notification preferences and scheduling
   - Add expert notification configuration to environment variables:
     - `EXPERT_REVIEW_ENABLED` (default: true)
     - `EXPERT_NOTIFICATION_THRESHOLD` (default: 0.8)
     - `EXPERT_REVIEW_TIMEOUT_HOURS` (default: 72)

2. **Create Expert Review Interface and Dashboard**
   - Create `frontend/app/dashboard/expert-review/page.tsx`:
     - Expert review dashboard with assigned anomalies
     - Filtering and sorting by priority, confidence, and age
     - Batch review capabilities for efficiency
     - Progress tracking and statistics
   - Create `frontend/components/ExpertReviewCard.tsx`:
     - Individual anomaly review interface
     - Image viewer with zoom and annotation tools
     - Scientific importance rating system
     - Comment and feedback collection
   - Create `frontend/components/ExpertReviewQueue.tsx`:
     - Queue management for pending reviews
     - Priority-based sorting and assignment
     - Expert workload balancing
     - Review deadline tracking

3. **Implement Anomaly Rating and Confirmation System**
   - Create `src/domains/curation/services/expert_rating_service.py`:
     - Scientific importance rating (1-5 scale)
     - Confidence validation and adjustment
     - False positive flagging and correction
     - Expert consensus and conflict resolution
   - Create `src/domains/curation/models/expert_rating.py`:
     - Rating model with detailed feedback
     - Consensus tracking for multiple expert reviews
     - Rating history and expert performance metrics
   - Add rating validation and business rules:
     - Minimum expert credentials for different rating levels
     - Consensus requirements for high-importance ratings
     - Escalation procedures for conflicting reviews

4. **Add High-Priority Discovery Tracking and Management**
   - Create `src/domains/curation/services/discovery_service.py`:
     - High-priority discovery identification and tracking
     - Scientific significance scoring and ranking
     - Discovery notification and publication workflows
     - Integration with external astronomical databases
   - Create `frontend/app/dashboard/discoveries/page.tsx`:
     - High-priority discoveries showcase
     - Discovery timeline and progress tracking
     - Publication and sharing capabilities
     - Expert attribution and recognition
   - Add discovery management features:
     - Automated discovery candidate identification
     - Expert validation workflows
     - Public announcement and notification systems
     - Integration with scientific publication pipelines

### **Integration Points**

- **Detection Pipeline**: Connect to ASTR-81 anomaly detection services
- **Human Validation**: Build on ASTR-82 validation system
- **Email Notifications**: Use ASTR-108 notification infrastructure
- **Authentication**: Integrate with Supabase user management
- **Database**: Extend existing curation domain models

### **Expert Review Workflow**
```python
# src/domains/curation/services/expert_review_service.py
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
from enum import Enum

class ScientificImportance(Enum):
    NONE = 1
    LOW = 2
    MODERATE = 3
    HIGH = 4
    CRITICAL = 5

class ReviewStatus(Enum):
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    ESCALATED = "escalated"
    EXPIRED = "expired"

class ExpertReviewService:
    """Service for managing expert review workflows."""
    
    def __init__(
        self,
        notification_service: ExpertNotificationService,
        rating_service: ExpertRatingService,
        discovery_service: DiscoveryService
    ):
        self.notification_service = notification_service
        self.rating_service = rating_service
        self.discovery_service = discovery_service
        self.logger = logging.getLogger(__name__)
    
    async def trigger_expert_review(
        self, 
        anomaly_id: str, 
        confidence_score: float,
        quality_score: float
    ) -> Dict[str, Any]:
        """Trigger expert review for high-confidence anomalies."""
        
        # Check if anomaly meets expert review criteria
        if not await self._should_trigger_expert_review(confidence_score, quality_score):
            return {"triggered": False, "reason": "Criteria not met"}
        
        # Get available experts
        experts = await self._get_available_experts()
        if not experts:
            return {"triggered": False, "reason": "No experts available"}
        
        # Create review assignment
        review_assignment = await self._create_review_assignment(
            anomaly_id, experts
        )
        
        # Send notifications to experts
        await self.notification_service.notify_experts(
            anomaly_id, review_assignment, experts
        )
        
        return {
            "triggered": True,
            "review_id": review_assignment.id,
            "experts_notified": len(experts),
            "deadline": review_assignment.deadline
        }
    
    async def submit_expert_review(
        self,
        review_id: str,
        expert_id: str,
        rating: ScientificImportance,
        confidence_adjustment: Optional[float],
        comments: str,
        is_false_positive: bool = False
    ) -> Dict[str, Any]:
        """Submit expert review for an anomaly."""
        
        # Validate expert credentials
        if not await self._validate_expert_credentials(expert_id, rating):
            raise ValueError("Insufficient expert credentials for this rating level")
        
        # Create rating record
        rating_record = await self.rating_service.create_rating(
            review_id=review_id,
            expert_id=expert_id,
            scientific_importance=rating,
            confidence_adjustment=confidence_adjustment,
            comments=comments,
            is_false_positive=is_false_positive
        )
        
        # Check for consensus
        consensus_result = await self._check_expert_consensus(review_id)
        
        # Update anomaly status based on consensus
        if consensus_result["consensus_reached"]:
            await self._update_anomaly_status(
                review_id, consensus_result["final_rating"]
            )
            
            # Check if this qualifies as a high-priority discovery
            if consensus_result["final_rating"] >= ScientificImportance.HIGH:
                await self.discovery_service.add_high_priority_discovery(
                    review_id, consensus_result
                )
        
        return {
            "rating_submitted": True,
            "rating_id": rating_record.id,
            "consensus_reached": consensus_result["consensus_reached"],
            "final_rating": consensus_result.get("final_rating")
        }
    
    async def _should_trigger_expert_review(
        self, 
        confidence_score: float, 
        quality_score: float
    ) -> bool:
        """Determine if anomaly should trigger expert review."""
        
        # Load configuration
        threshold = float(os.getenv("EXPERT_NOTIFICATION_THRESHOLD", "0.8"))
        
        # Check confidence and quality thresholds
        if confidence_score < threshold:
            return False
        
        if quality_score < 0.7:  # Minimum quality threshold
            return False
        
        # Additional criteria could include:
        # - Novelty score
        # - Survey coverage
        # - Time since last similar detection
        # - Expert workload balancing
        
        return True
    
    async def _check_expert_consensus(self, review_id: str) -> Dict[str, Any]:
        """Check if expert consensus has been reached."""
        
        ratings = await self.rating_service.get_ratings_for_review(review_id)
        
        if len(ratings) < 2:  # Need at least 2 expert opinions
            return {"consensus_reached": False}
        
        # Calculate consensus based on rating distribution
        importance_scores = [r.scientific_importance.value for r in ratings]
        avg_importance = sum(importance_scores) / len(importance_scores)
        
        # Check for agreement (within 1 point)
        max_diff = max(importance_scores) - min(importance_scores)
        consensus_reached = max_diff <= 1
        
        if consensus_reached:
            final_rating = ScientificImportance(int(round(avg_importance)))
        else:
            final_rating = None
        
        return {
            "consensus_reached": consensus_reached,
            "final_rating": final_rating,
            "average_rating": avg_importance,
            "rating_count": len(ratings)
        }
```

### **Expert Review Interface**
```tsx
// frontend/app/dashboard/expert-review/page.tsx
'use client'

import React, { useState, useEffect } from 'react'
import { ExpertReviewCard } from '@/components/ExpertReviewCard'
import { ExpertReviewQueue } from '@/components/ExpertReviewQueue'
import { ExpertStatsPanel } from '@/components/ExpertStatsPanel'
import { FilterBar } from '@/components/FilterBar'

interface ExpertReviewData {
  id: string
  anomaly_id: string
  confidence_score: number
  quality_score: number
  detection_time: string
  survey_name: string
  priority: 'low' | 'medium' | 'high' | 'critical'
  status: 'pending' | 'in_progress' | 'completed'
  assigned_experts: string[]
  deadline: string
  image_urls: string[]
}

export default function ExpertReviewPage() {
  const [reviews, setReviews] = useState<ExpertReviewData[]>([])
  const [loading, setLoading] = useState(true)
  const [filters, setFilters] = useState({
    status: 'all',
    priority: 'all',
    survey: 'all',
    timeRange: '7d'
  })
  const [selectedReview, setSelectedReview] = useState<ExpertReviewData | null>(null)

  useEffect(() => {
    fetchExpertReviews()
  }, [filters])

  const fetchExpertReviews = async () => {
    setLoading(true)
    try {
      const params = new URLSearchParams(filters)
      const response = await fetch(`/api/expert-reviews?${params}`)
      const data = await response.json()
      setReviews(data.reviews)
    } catch (error) {
      console.error('Failed to fetch expert reviews:', error)
    } finally {
      setLoading(false)
    }
  }

  const handleReviewSubmit = async (reviewId: string, rating: any) => {
    try {
      const response = await fetch(`/api/expert-reviews/${reviewId}`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(rating)
      })
      
      if (response.ok) {
        await fetchExpertReviews() // Refresh the list
        setSelectedReview(null)
      }
    } catch (error) {
      console.error('Failed to submit review:', error)
    }
  }

  return (
    <div className="expert-review-page">
      <div className="page-header">
        <h1 className="text-3xl font-bold text-white">Expert Review Dashboard</h1>
        <p className="text-gray-400">Review and validate detected anomalies</p>
      </div>

      <div className="review-layout">
        <div className="review-sidebar">
          <ExpertStatsPanel reviews={reviews} />
          <FilterBar filters={filters} onFiltersChange={setFilters} />
        </div>

        <div className="review-main">
          <ExpertReviewQueue
            reviews={reviews}
            loading={loading}
            onReviewSelect={setSelectedReview}
            selectedReview={selectedReview}
          />
        </div>

        {selectedReview && (
          <div className="review-detail">
            <ExpertReviewCard
              review={selectedReview}
              onSubmit={(rating) => handleReviewSubmit(selectedReview.id, rating)}
              onClose={() => setSelectedReview(null)}
            />
          </div>
        )}
      </div>
    </div>
  )
}
```

### **Expert Review Card Component**
```tsx
// frontend/components/ExpertReviewCard.tsx
import React, { useState } from 'react'
import { Star, Flag, MessageSquare, CheckCircle, XCircle } from 'lucide-react'

interface ExpertReviewCardProps {
  review: ExpertReviewData
  onSubmit: (rating: ExpertRating) => void
  onClose: () => void
}

interface ExpertRating {
  scientific_importance: number
  confidence_adjustment?: number
  comments: string
  is_false_positive: boolean
}

export const ExpertReviewCard: React.FC<ExpertReviewCardProps> = ({
  review,
  onSubmit,
  onClose
}) => {
  const [rating, setRating] = useState<ExpertRating>({
    scientific_importance: 0,
    comments: '',
    is_false_positive: false
  })
  const [submitting, setSubmitting] = useState(false)

  const handleSubmit = async () => {
    setSubmitting(true)
    try {
      await onSubmit(rating)
    } finally {
      setSubmitting(false)
    }
  }

  const importanceLevels = [
    { value: 1, label: 'None', description: 'No scientific significance' },
    { value: 2, label: 'Low', description: 'Minor scientific interest' },
    { value: 3, label: 'Moderate', description: 'Moderate scientific value' },
    { value: 4, label: 'High', description: 'High scientific importance' },
    { value: 5, label: 'Critical', description: 'Breakthrough discovery' }
  ]

  return (
    <div className="expert-review-card">
      <div className="card-header">
        <h3 className="card-title">Review Anomaly {review.anomaly_id.slice(0, 8)}</h3>
        <button onClick={onClose} className="close-button">
          <XCircle className="w-5 h-5" />
        </button>
      </div>

      <div className="card-content">
        {/* Anomaly Images */}
        <div className="image-gallery">
          {review.image_urls.map((url, index) => (
            <div key={index} className="image-container">
              <img 
                src={url} 
                alt={`Detection ${index + 1}`}
                className="detection-image"
              />
            </div>
          ))}
        </div>

        {/* Anomaly Details */}
        <div className="anomaly-details">
          <div className="detail-grid">
            <div className="detail-item">
              <label>Confidence Score:</label>
              <span className="score-value">
                {(review.confidence_score * 100).toFixed(1)}%
              </span>
            </div>
            <div className="detail-item">
              <label>Quality Score:</label>
              <span className="score-value">
                {(review.quality_score * 100).toFixed(1)}%
              </span>
            </div>
            <div className="detail-item">
              <label>Survey:</label>
              <span>{review.survey_name}</span>
            </div>
            <div className="detail-item">
              <label>Detection Time:</label>
              <span>{new Date(review.detection_time).toLocaleString()}</span>
            </div>
          </div>
        </div>

        {/* Scientific Importance Rating */}
        <div className="rating-section">
          <h4 className="section-title">Scientific Importance</h4>
          <div className="rating-options">
            {importanceLevels.map((level) => (
              <label key={level.value} className="rating-option">
                <input
                  type="radio"
                  name="scientific_importance"
                  value={level.value}
                  checked={rating.scientific_importance === level.value}
                  onChange={(e) => setRating({
                    ...rating,
                    scientific_importance: parseInt(e.target.value)
                  })}
                />
                <div className="option-content">
                  <div className="option-label">{level.label}</div>
                  <div className="option-description">{level.description}</div>
                </div>
              </label>
            ))}
          </div>
        </div>

        {/* Confidence Adjustment */}
        <div className="confidence-section">
          <h4 className="section-title">Confidence Adjustment</h4>
          <div className="confidence-controls">
            <label>
              <input
                type="checkbox"
                checked={rating.confidence_adjustment !== undefined}
                onChange={(e) => setRating({
                  ...rating,
                  confidence_adjustment: e.target.checked ? 0 : undefined
                })}
              />
              Adjust confidence score
            </label>
            {rating.confidence_adjustment !== undefined && (
              <input
                type="range"
                min="-0.5"
                max="0.5"
                step="0.1"
                value={rating.confidence_adjustment}
                onChange={(e) => setRating({
                  ...rating,
                  confidence_adjustment: parseFloat(e.target.value)
                })}
                className="confidence-slider"
              />
            )}
          </div>
        </div>

        {/* False Positive Flag */}
        <div className="false-positive-section">
          <label className="checkbox-label">
            <input
              type="checkbox"
              checked={rating.is_false_positive}
              onChange={(e) => setRating({
                ...rating,
                is_false_positive: e.target.checked
              })}
            />
            <Flag className="w-4 h-4" />
            Flag as false positive
          </label>
        </div>

        {/* Comments */}
        <div className="comments-section">
          <h4 className="section-title">Comments</h4>
          <textarea
            value={rating.comments}
            onChange={(e) => setRating({
              ...rating,
              comments: e.target.value
            })}
            placeholder="Add your expert analysis and comments..."
            className="comments-textarea"
            rows={4}
          />
        </div>
      </div>

      <div className="card-footer">
        <button
          onClick={handleSubmit}
          disabled={submitting || rating.scientific_importance === 0}
          className="submit-button"
        >
          {submitting ? 'Submitting...' : 'Submit Review'}
        </button>
      </div>
    </div>
  )
}
```

### **High-Priority Discovery Management**
```python
# src/domains/curation/services/discovery_service.py
class DiscoveryService:
    """Service for managing high-priority discoveries."""
    
    def __init__(self, database: Database, notification_service: NotificationService):
        self.db = database
        self.notification_service = notification_service
        self.logger = logging.getLogger(__name__)
    
    async def add_high_priority_discovery(
        self, 
        review_id: str, 
        consensus_result: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Add a confirmed high-priority discovery."""
        
        # Get anomaly details
        anomaly = await self._get_anomaly_by_review_id(review_id)
        
        # Create discovery record
        discovery = await self._create_discovery_record(
            anomaly_id=anomaly.id,
            review_id=review_id,
            scientific_importance=consensus_result["final_rating"],
            expert_consensus=consensus_result["rating_count"],
            discovery_date=datetime.utcnow()
        )
        
        # Trigger discovery notifications
        await self._notify_discovery_stakeholders(discovery)
        
        # Add to public discoveries list
        await self._add_to_public_discoveries(discovery)
        
        return {
            "discovery_id": discovery.id,
            "status": "created",
            "public_url": f"/discoveries/{discovery.id}"
        }
    
    async def get_high_priority_discoveries(
        self, 
        limit: int = 50,
        include_unpublished: bool = False
    ) -> List[Dict[str, Any]]:
        """Get list of high-priority discoveries."""
        
        query = """
        SELECT d.*, a.ra, a.dec, a.survey_name, a.detection_time
        FROM discoveries d
        JOIN anomalies a ON d.anomaly_id = a.id
        WHERE d.scientific_importance >= 4
        """
        
        if not include_unpublished:
            query += " AND d.published = true"
        
        query += " ORDER BY d.discovery_date DESC LIMIT $1"
        
        results = await self.db.fetch_all(query, [limit])
        return [dict(row) for row in results]
```

### **API Endpoints**
```python
# Add to existing API
@router.get("/expert-reviews")
async def get_expert_reviews(
    status: str = "all",
    priority: str = "all",
    survey: str = "all",
    time_range: str = "7d",
    current_user: User = Depends(get_current_expert_user)
):
    """Get expert review assignments."""
    # Implementation for fetching expert reviews
    pass

@router.post("/expert-reviews/{review_id}")
async def submit_expert_review(
    review_id: str,
    rating: ExpertRatingRequest,
    current_user: User = Depends(get_current_expert_user)
):
    """Submit expert review for an anomaly."""
    # Implementation for submitting expert reviews
    pass

@router.get("/discoveries")
async def get_high_priority_discoveries(
    include_unpublished: bool = False,
    limit: int = 50
):
    """Get high-priority discoveries."""
    # Implementation for fetching discoveries
    pass

@router.post("/discoveries/{discovery_id}/publish")
async def publish_discovery(
    discovery_id: str,
    current_user: User = Depends(get_current_admin_user)
):
    """Publish a high-priority discovery."""
    # Implementation for publishing discoveries
    pass
```

### **Database Schema Extensions**
```sql
-- Expert review tables
CREATE TABLE expert_users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES auth.users(id),
    expertise_level INTEGER NOT NULL DEFAULT 1,
    specializations TEXT[],
    max_rating_level INTEGER NOT NULL DEFAULT 3,
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE TABLE review_assignments (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    anomaly_id UUID REFERENCES detections(id),
    assigned_experts UUID[] NOT NULL,
    priority VARCHAR(20) DEFAULT 'medium',
    deadline TIMESTAMP WITH TIME ZONE NOT NULL,
    status VARCHAR(20) DEFAULT 'pending',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE TABLE expert_ratings (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    review_id UUID REFERENCES review_assignments(id),
    expert_id UUID REFERENCES expert_users(id),
    scientific_importance INTEGER NOT NULL CHECK (scientific_importance BETWEEN 1 AND 5),
    confidence_adjustment DECIMAL(3,2),
    comments TEXT,
    is_false_positive BOOLEAN DEFAULT false,
    submitted_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE TABLE discoveries (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    anomaly_id UUID REFERENCES detections(id),
    review_id UUID REFERENCES review_assignments(id),
    scientific_importance INTEGER NOT NULL,
    expert_consensus INTEGER NOT NULL,
    discovery_date TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    published BOOLEAN DEFAULT false,
    published_at TIMESTAMP WITH TIME ZONE,
    public_description TEXT,
    discovery_metadata JSONB
);
```

### **Error Handling and Validation**
- Expert credential validation for different rating levels
- Review deadline enforcement and escalation
- Consensus conflict resolution procedures
- Data integrity validation for ratings and discoveries
- Comprehensive audit logging for expert actions

### **Testing Strategy**
- Unit tests for expert review workflows
- Integration tests for consensus calculation
- End-to-end tests for complete review process
- Performance tests for high-volume review scenarios
- User acceptance tests with real expert users

### **Performance Considerations**
- Efficient querying for expert review queues
- Caching for frequently accessed discovery data
- Batch processing for notification delivery
- Database indexing for review and discovery queries
- Real-time updates for review status changes

### **Expected Deliverables**
1. **Expert Review Service** - Complete workflow management system
2. **Review Interface** - React components for expert review dashboard
3. **Discovery Management** - High-priority discovery tracking and publication
4. **API Endpoints** - REST API for expert review operations
5. **Database Schema** - Extended models for expert review and discoveries
6. **Notification System** - Expert alerts and discovery announcements
7. **Documentation** - Expert user guides and workflow documentation

### **Success Criteria**
- Experts can efficiently review and rate detected anomalies
- Consensus system accurately identifies high-priority discoveries
- High-priority discoveries are properly tracked and published
- Expert review process integrates seamlessly with existing workflow
- System scales to handle multiple experts and high review volumes
- Expert feedback improves overall anomaly detection quality

This feature will significantly enhance the scientific value of AstrID by incorporating human expertise into the anomaly validation process, ensuring that truly significant astronomical discoveries receive proper attention and validation.
