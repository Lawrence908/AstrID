## **ASTR-92: Dramatiq Workers (P2) - Background Processing**

### **Context & Current State**
Workflow orchestration is set up (ASTR-91 ), providing the foundation for background processing. This ticket implements Dramatiq workers for high-performance background processing of observations, preprocessing, differencing, and detection tasks.

### **Technical Requirements**

**Dependencies**: ASTR-91 (Workflow Orchestration) -  Complete
**Domain**: Background Processing
**Estimated Time**: 4 days

### **Implementation Tasks**

1. **Implement Observation Ingestion Workers**
   - Create `src/workers/ingestion/observation_workers.py`
   - Implement `ObservationIngestionWorker` with methods:
     - `ingest_observation(observation_data: dict) -> dict`
     - `validate_observation_data(observation_data: dict) -> bool`
     - `process_observation_metadata(observation_data: dict) -> dict`
     - `store_observation_files(observation_data: dict) -> dict`
     - `trigger_preprocessing(observation_id: UUID) -> None`
   - Add worker configuration and resource management
   - Implement worker health checks and monitoring
   - Add error handling and retry logic

2. **Add Preprocessing Workers**
   - Create `src/workers/preprocessing/preprocessing_workers.py`
   - Implement `PreprocessingWorker` with methods:
     - `preprocess_observation(observation_id: UUID) -> dict`
     - `apply_calibration(observation_id: UUID, calibration_frames: dict) -> dict`
     - `align_observation(observation_id: UUID, reference_id: UUID) -> dict`
     - `assess_quality(observation_id: UUID) -> dict`
     - `trigger_differencing(observation_id: UUID) -> None`
   - Add preprocessing pipeline orchestration
   - Implement resource-intensive processing optimization
   - Add preprocessing result validation

3. **Create Differencing Workers**
   - Create `src/workers/differencing/differencing_workers.py`
   - Implement `DifferencingWorker` with methods:
     - `create_difference_image(observation_id: UUID, reference_id: UUID) -> dict`
     - `apply_differencing_algorithm(observation_id: UUID, algorithm: str) -> dict`
     - `validate_difference_image(difference_id: UUID) -> dict`
     - `extract_sources(difference_id: UUID) -> dict`
     - `trigger_detection(difference_id: UUID) -> None`
   - Add differencing algorithm selection and optimization
   - Implement memory-efficient image processing
   - Add differencing quality assessment

4. **Implement Detection Workers**
   - Create `src/workers/detection/detection_workers.py`
   - Implement `DetectionWorker` with methods:
     - `detect_anomalies(difference_id: UUID, model_id: str) -> dict`
     - `validate_detections(detection_id: UUID) -> dict`
     - `calculate_detection_metrics(detection_id: UUID) -> dict`
     - `store_detection_results(detection_id: UUID) -> dict`
     - `trigger_curation(detection_id: UUID) -> None`
   - Add ML model inference optimization
   - Implement detection result validation
   - Add detection performance monitoring

### **Integration Points**

- **Workflow Orchestration**: Execute flows via Dramatiq workers
- **Domain Services**: Use domain services for business logic
- **Storage**: Store processing results in cloud storage
- **Events**: Emit worker completion and failure events
- **Monitoring**: Integrate with system monitoring and alerting

### **Worker Configuration**
```python
@dataclass
class WorkerConfig:
    broker_url: str
    result_backend: str
    max_retries: int
    retry_delay: int
    worker_timeout: int
    max_memory: int
    max_cpu: int
    concurrency: int
    prefetch_multiplier: int
```

### **Worker Types**
```python
class WorkerType(Enum):
    OBSERVATION_INGESTION = "observation_ingestion"
    PREPROCESSING = "preprocessing"
    DIFFERENCING = "differencing"
    DETECTION = "detection"
    CURATION = "curation"
    NOTIFICATION = "notification"
```

### **Task Queue Management**
```python
@dataclass
class TaskQueue:
    queue_name: str
    worker_type: WorkerType
    priority: int
    max_retries: int
    timeout: int
    concurrency: int
    enabled: bool
```

### **API Endpoints to Add**
```python
GET /workers/status
POST /workers/{worker_type}/start
POST /workers/{worker_type}/stop
GET /workers/{worker_type}/metrics
POST /workers/{worker_type}/scale
GET /workers/queues
POST /workers/queues/{queue_name}/clear
```

### **Worker Monitoring**
```python
@dataclass
class WorkerMetrics:
    worker_id: str
    worker_type: WorkerType
    status: str  # IDLE, BUSY, ERROR, STOPPED
    tasks_processed: int
    tasks_failed: int
    average_processing_time: float
    memory_usage: float
    cpu_usage: float
    last_heartbeat: datetime
```

### **Error Handling**
- Worker failure detection and recovery
- Task retry logic and exponential backoff
- Resource exhaustion handling
- Dead letter queue for failed tasks
- Comprehensive logging for debugging

### **Testing Strategy**
- Unit tests for all worker functions
- Integration tests with Dramatiq broker
- Worker performance and load tests
- Error handling and recovery tests
- Concurrent worker execution tests

### **Performance Considerations**
- Worker scaling and load balancing
- Task batching for efficiency
- Memory management for large data processing
- CPU and memory resource monitoring
- Queue prioritization and scheduling
